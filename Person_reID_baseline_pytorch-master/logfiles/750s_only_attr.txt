750s_erasing_jitter_attr.txt
750s_erasing_jitter.txt
750s_only_attr.txt
adam_freeze_75.txt
adam_output.txt
all_epochs_mix_erasing.txt
all_epochs_multi_erasing.txt
all_epochs.txt
attribute_data.npy
attribute_data_preprocessing.ipynb
Attributes verification.ipynb
collect_results.py
correct_attr_color.txt
correct_attr.txt
demo.py
dense_attr_color_erasing_70e.txt
dense_attr_color_erasing.txt
dense_attr_color.txt
dense_attr_full_set.txt
dense_attr_no_color.txt
dense_attr.txt
dense_erasing_all_epochs.txt
downcolor.npy
duke_attribute_data.npy
duke_attribute.mat
duke_downcolor.npy
duke_labels.npy
duke_out.txt
duke_upcolor.npy
Ensembling experimentation.ipynb
erasing_data_augmentation_checking.ipynb
evaluate_ensemble.py
evaluate_gpu.py
evaluate_int.py
evaluate.py
evaluate_rerank.py
extract.py
extract_tta.py
feeze_learning.ipynb
image_net_erasing.txt
image_net_erasing_wde3.txt
image_net_freeze.txt
image_net_wde3.txt
image_net_wde5.txt
images_collection.ipynb
labels.npy
LICENSE
load_mat_file.py
market_attribute.mat
mkt_0.4g_freeze.txt
model
model.py
multi_random_erasing.py
multi_step_LR_3
multi_step_LR_3.txt
multi_step_LR.txt
no_attr.txt
only_attr_train.txt
output_pcb_attr.txt
output_sat_color.txt
output_sat_erasing.txt
output_sat.txt
prepare.py
prepare_static.py
__pycache__
random_erasing.py
README.md
re_ranking.py
results_collection.ipynb
sample_model
step_attr.txt
test.py
train_attr_dl.py
train_attr.py
train_duke.py
train.jpg
train_no_attr.py
train_pcb_attr.py
train.py
tta_expermimenation.ipynb
tutorial
untitled
untitled1
Untitled1.ipynb
Untitled.ipynb
upcolor.npy
use_info.md
visualization
visualize.py
net output size:
torch.Size([8, 1024])
0
[Resize(size=(288, 144), interpolation=PIL.Image.BICUBIC), RandomCrop(size=(256, 128), padding=0), RandomHorizontalFlip(p=0.5), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]
ft_attr_net_dense(
  (model): DenseNet(
    (features): Sequential(
      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu0): ReLU(inplace)
      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (denseblock1): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (transition1): _Transition(
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
      (denseblock2): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer7): _DenseLayer(
          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer8): _DenseLayer(
          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer9): _DenseLayer(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer10): _DenseLayer(
          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer11): _DenseLayer(
          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer12): _DenseLayer(
          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (transition2): _Transition(
        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
      (denseblock3): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer7): _DenseLayer(
          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer8): _DenseLayer(
          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer9): _DenseLayer(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer10): _DenseLayer(
          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer11): _DenseLayer(
          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer12): _DenseLayer(
          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer13): _DenseLayer(
          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer14): _DenseLayer(
          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer15): _DenseLayer(
          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer16): _DenseLayer(
          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer17): _DenseLayer(
          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer18): _DenseLayer(
          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer19): _DenseLayer(
          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer20): _DenseLayer(
          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer21): _DenseLayer(
          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer22): _DenseLayer(
          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer23): _DenseLayer(
          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer24): _DenseLayer(
          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (transition3): _Transition(
        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
      (denseblock4): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer7): _DenseLayer(
          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer8): _DenseLayer(
          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer9): _DenseLayer(
          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer10): _DenseLayer(
          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer11): _DenseLayer(
          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer12): _DenseLayer(
          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer13): _DenseLayer(
          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer14): _DenseLayer(
          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer15): _DenseLayer(
          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer16): _DenseLayer(
          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Linear(in_features=1024, out_features=1000, bias=True)
    (fc): Sequential()
  )
  (classifier): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=751, bias=True)
    )
  )
  (classifierage): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=4, bias=True)
    )
  )
  (classifierbackpack): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierbag): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierhandbag): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierdowncolor): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=9, bias=True)
    )
  )
  (classifierupcolor): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=8, bias=True)
    )
  )
  (classifierclothes): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierdown): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierup): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierhair): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierhat): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifiergender): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
)
/opt/anaconda3/lib/python3.7/site-packages/torchvision-0.2.1-py3.7.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:14: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
  init.kaiming_normal(m.weight.data, a=0, mode='fan_out')
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:15: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(m.bias.data, 0.0)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:17: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.
  init.normal(m.weight.data, 1.0, 0.02)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:18: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(m.bias.data, 0.0)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:23: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.
  init.normal(m.weight.data, std=0.001)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:24: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(m.bias.data, 0.0)
0.9304180145263672
shape (1501, 12)
[1 1 1 ... 1 1 1]
attr_data.shape
torch.Size([1501, 12])
checking model folder------------------- ./model/750s_only_attr
False
creating model folder-------------------
No. of Attributes selected
12
Epoch 0/69
----------
train Loss: 4.1110 Attr Loss: 8.0607 Acc: 0.2567
attribute accuracies
[0.78317604 0.75642183 0.75757078 0.87574887 0.56569553 0.577103
 0.86516208 0.8172343  0.94665572 0.74813295 0.97398441 0.73081658]
val Loss: 2.4510 Attr Loss: 6.1227 Acc: 0.4141
attribute accuracies
[0.72703063 0.76298269 0.71371505 0.82822903 0.6391478  0.6644474
 0.83754993 0.83355526 0.88948069 0.74434088 0.91344874 0.77363515]
Epoch 1/69
----------
train Loss: 1.4474 Attr Loss: 5.9648 Acc: 0.6507
attribute accuracies
[0.80082068 0.81945014 0.7716865  0.87829298 0.71497743 0.74181371
 0.90652442 0.89593763 0.94854329 0.82306114 0.9755437  0.83093968]
val Loss: 1.3179 Attr Loss: 5.4960 Acc: 0.6152
attribute accuracies
[0.74434088 0.76431425 0.72037284 0.83355526 0.6644474  0.72436751
 0.86284953 0.83888149 0.88814913 0.75765646 0.91211718 0.80559254]
Epoch 2/69
----------
train Loss: 0.7731 Attr Loss: 5.3775 Acc: 0.7981
attribute accuracies
[0.81050472 0.83159622 0.77833402 0.87911366 0.75330324 0.77423061
 0.91908084 0.90274928 0.94846122 0.84218301 0.9755437  0.85490357]
val Loss: 0.8357 Attr Loss: 5.2170 Acc: 0.7204
attribute accuracies
[0.75898802 0.78961385 0.73901465 0.83488682 0.70439414 0.72170439
 0.86018642 0.8482024  0.88681758 0.77629827 0.91344874 0.79227696]
Epoch 3/69
----------
train Loss: 0.5062 Attr Loss: 5.0375 Acc: 0.8704
attribute accuracies
[0.81772671 0.84595815 0.79261387 0.88059089 0.77119409 0.78572015
 0.92909315 0.91169471 0.9487895  0.85375462 0.9755437  0.87205581]
val Loss: 0.6388 Attr Loss: 4.8738 Acc: 0.7856
attribute accuracies
[0.76165113 0.78695073 0.74833555 0.82956059 0.71105193 0.74833555
 0.86684421 0.86284953 0.88948069 0.78961385 0.91478029 0.82023968]
Epoch 4/69
----------
train Loss: 0.3652 Attr Loss: 4.7284 Acc: 0.9050
attribute accuracies
[0.82544112 0.85818629 0.80090275 0.88190398 0.79351662 0.79901518
 0.93598687 0.91637259 0.94944604 0.86663931 0.9755437  0.88124744]
val Loss: 0.5216 Attr Loss: 4.7385 Acc: 0.8029
attribute accuracies
[0.75898802 0.78961385 0.73368842 0.82956059 0.71105193 0.76298269
 0.87217044 0.87217044 0.88681758 0.80292943 0.91078562 0.81091877]
Epoch 5/69
----------
train Loss: 0.2465 Attr Loss: 4.4329 Acc: 0.9417
attribute accuracies
[0.83405827 0.86286418 0.8133771  0.88395568 0.8151826  0.81386951
 0.9413213  0.92310217 0.95059499 0.87993435 0.97562577 0.89798933]
val Loss: 0.4652 Attr Loss: 4.4422 Acc: 0.8189
attribute accuracies
[0.76431425 0.81358189 0.76031957 0.82689747 0.72969374 0.76564581
 0.88814913 0.86151798 0.88814913 0.81091877 0.91211718 0.82689747]
Epoch 6/69
----------
train Loss: 0.1992 Attr Loss: 4.2382 Acc: 0.9528
attribute accuracies
[0.83873615 0.87353303 0.8205991  0.88510464 0.82527698 0.82421009
 0.94599918 0.92868281 0.95133361 0.88362741 0.9755437  0.90644235]
val Loss: 0.5144 Attr Loss: 4.3988 Acc: 0.8162
attribute accuracies
[0.77496671 0.81091877 0.7563249  0.83355526 0.73235686 0.76697736
 0.89081225 0.88015979 0.89214381 0.81491345 0.91344874 0.83621838]
Epoch 7/69
----------
train Loss: 0.1492 Attr Loss: 4.0483 Acc: 0.9680
attribute accuracies
[0.84571194 0.883135   0.83044727 0.88625359 0.83373    0.82938039
 0.95166188 0.93130899 0.95174395 0.8926549  0.97562577 0.91604432]
val Loss: 0.3719 Attr Loss: 4.2233 Acc: 0.8509
attribute accuracies
[0.77363515 0.81225033 0.76830892 0.8322237  0.76165113 0.77629827
 0.88548602 0.86817577 0.88948069 0.8229028  0.91211718 0.84420772]
Epoch 8/69
----------
train Loss: 0.1327 Attr Loss: 3.8852 Acc: 0.9745
attribute accuracies
[0.85244153 0.88830529 0.83414034 0.89117768 0.85711941 0.8378334
 0.95437013 0.93475585 0.95387772 0.89585556 0.97562577 0.91842429]
val Loss: 0.3718 Attr Loss: 4.0593 Acc: 0.8495
attribute accuracies
[0.78961385 0.81358189 0.78029294 0.83754993 0.76564581 0.77629827
 0.89480692 0.87483356 0.88681758 0.82023968 0.91478029 0.8482024 ]
Epoch 9/69
----------
train Loss: 0.1103 Attr Loss: 3.7261 Acc: 0.9799
attribute accuracies
[0.85752975 0.8962659  0.84029545 0.8924087  0.86581863 0.84677883
 0.95551908 0.93680755 0.95584735 0.90291342 0.9755437  0.92868281]
val Loss: 0.3506 Attr Loss: 3.9618 Acc: 0.8668
attribute accuracies
[0.76964048 0.82822903 0.78561917 0.83621838 0.77629827 0.78961385
 0.89214381 0.8828229  0.88948069 0.82689747 0.91211718 0.85486019]
Epoch 10/69
----------
train Loss: 0.1085 Attr Loss: 3.5863 Acc: 0.9814
attribute accuracies
[0.86343865 0.90299549 0.8507181  0.8960197  0.87435371 0.85605252
 0.96077144 0.94714813 0.95461633 0.90947887 0.9755437  0.93393517]
val Loss: 0.3750 Attr Loss: 3.8913 Acc: 0.8642
attribute accuracies
[0.78828229 0.82956059 0.78828229 0.84287617 0.77629827 0.78561917
 0.89480692 0.88149134 0.88948069 0.83621838 0.91211718 0.86817577]
Epoch 11/69
----------
train Loss: 0.0878 Attr Loss: 3.4562 Acc: 0.9865
attribute accuracies
[0.87123513 0.90849405 0.86056627 0.8983176  0.88100123 0.86294625
 0.96306935 0.95002052 0.95724251 0.91194091 0.9755437  0.93861305]
val Loss: 0.3160 Attr Loss: 3.7832 Acc: 0.8615
attribute accuracies
[0.78961385 0.83888149 0.80159787 0.84021305 0.78295606 0.79360852
 0.89347537 0.88415446 0.89347537 0.83754993 0.91344874 0.86018642]
Epoch 12/69
----------
train Loss: 0.0696 Attr Loss: 3.2993 Acc: 0.9921
attribute accuracies
[0.87509233 0.91760361 0.87041444 0.90332376 0.89355765 0.87107099
 0.96561346 0.95215429 0.95781699 0.9186705  0.9755437  0.94394748]
val Loss: 0.2592 Attr Loss: 3.6333 Acc: 0.8828
attribute accuracies
[0.78428762 0.84420772 0.80292943 0.83621838 0.7976032  0.80559254
 0.89347537 0.87882823 0.8988016  0.83754993 0.91344874 0.86418109]
Epoch 13/69
----------
train Loss: 0.0671 Attr Loss: 3.1923 Acc: 0.9915
attribute accuracies
[0.87919573 0.92178908 0.87780057 0.90627821 0.90151826 0.87574887
 0.96889618 0.95502667 0.95913008 0.92195322 0.97562577 0.94919984]
val Loss: 0.3044 Attr Loss: 3.5814 Acc: 0.8802
attribute accuracies
[0.79494008 0.84287617 0.79893475 0.84287617 0.79227696 0.80559254
 0.8988016  0.88415446 0.90013316 0.85219707 0.91344874 0.86151798]
Epoch 14/69
----------
train Loss: 0.0649 Attr Loss: 3.1063 Acc: 0.9935
attribute accuracies
[0.8885515  0.92408699 0.88641773 0.91194091 0.90480098 0.88157571
 0.96897825 0.95633976 0.96142799 0.92605663 0.97562577 0.95149774]
val Loss: 0.3336 Attr Loss: 3.6260 Acc: 0.8628
attribute accuracies
[0.79494008 0.84287617 0.79494008 0.84287617 0.79094541 0.79893475
 0.89214381 0.89347537 0.89480692 0.84687084 0.91478029 0.88415446]
Epoch 15/69
----------
train Loss: 0.0667 Attr Loss: 3.0312 Acc: 0.9924
attribute accuracies
[0.88896184 0.92884694 0.88822323 0.91440295 0.91153057 0.88608945
 0.97102995 0.95716044 0.96159212 0.92974969 0.9755437  0.95354945]
val Loss: 0.2850 Attr Loss: 3.4425 Acc: 0.8802
attribute accuracies
[0.80026631 0.85219707 0.81624501 0.85486019 0.81358189 0.81624501
 0.89747004 0.89214381 0.89214381 0.83888149 0.91211718 0.87217044]
Epoch 16/69
----------
train Loss: 0.0603 Attr Loss: 2.9410 Acc: 0.9943
attribute accuracies
[0.89224456 0.93418137 0.89954863 0.91637259 0.91949118 0.89076734
 0.9737382  0.95904801 0.9621666  0.93491998 0.9755437  0.9567501 ]
val Loss: 0.2889 Attr Loss: 3.4094 Acc: 0.8802
attribute accuracies
[0.8069241  0.83888149 0.82822903 0.84953395 0.80292943 0.80825566
 0.90279627 0.89480692 0.89480692 0.8575233  0.91211718 0.8828229 ]
Epoch 17/69
----------
train Loss: 0.0617 Attr Loss: 2.8883 Acc: 0.9947
attribute accuracies
[0.89405006 0.93631514 0.90274928 0.92088634 0.92236356 0.89249077
 0.9737382  0.96052524 0.96290521 0.9377103  0.9755437  0.95871974]
val Loss: 0.3097 Attr Loss: 3.3675 Acc: 0.8802
attribute accuracies
[0.80958722 0.84953395 0.81890812 0.85619174 0.81890812 0.81091877
 0.90146471 0.88948069 0.8988016  0.85486019 0.91211718 0.88948069]
Epoch 18/69
----------
train Loss: 0.0603 Attr Loss: 2.7995 Acc: 0.9949
attribute accuracies
[0.90077965 0.94222405 0.91013541 0.92310217 0.92769799 0.89823554
 0.9755437  0.96503898 0.96331555 0.94255232 0.9755437  0.96175626]
val Loss: 0.3234 Attr Loss: 3.4090 Acc: 0.8775
attribute accuracies
[0.80159787 0.85219707 0.82822903 0.85086551 0.80825566 0.81624501
 0.89747004 0.89214381 0.89747004 0.85885486 0.91344874 0.87882823]
Epoch 19/69
----------
train Loss: 0.0619 Attr Loss: 2.7544 Acc: 0.9936
attribute accuracies
[0.90471892 0.9451785  0.916865   0.92860074 0.93221174 0.90315962
 0.97792368 0.96405416 0.96430037 0.94443989 0.97562577 0.96364382]
val Loss: 0.3145 Attr Loss: 3.3194 Acc: 0.8722
attribute accuracies
[0.81358189 0.85885486 0.81890812 0.84953395 0.82023968 0.8229028
 0.90013316 0.89214381 0.89613848 0.85352863 0.91211718 0.87749667]
Epoch 20/69
----------
train Loss: 0.0552 Attr Loss: 2.6926 Acc: 0.9956
attribute accuracies
[0.90529339 0.94993845 0.91924497 0.93163726 0.93697169 0.90463685
 0.97956504 0.96536725 0.96462864 0.94632745 0.9755437  0.96454657]
val Loss: 0.3064 Attr Loss: 3.2101 Acc: 0.8775
attribute accuracies
[0.81890812 0.85486019 0.83089214 0.85219707 0.82689747 0.82423435
 0.90146471 0.89214381 0.89747004 0.86551265 0.91344874 0.88015979]
Epoch 21/69
----------
train Loss: 0.0496 Attr Loss: 2.5995 Acc: 0.9964
attribute accuracies
[0.91103816 0.95330324 0.9261387  0.93524826 0.94263439 0.91169471
 0.97997538 0.96503898 0.96454657 0.94731227 0.9755437  0.96668034]
val Loss: 0.2761 Attr Loss: 3.1581 Acc: 0.8748
attribute accuracies
[0.82556591 0.86551265 0.8322237  0.85619174 0.82423435 0.82689747
 0.90146471 0.8988016  0.89347537 0.87083888 0.91078562 0.89480692]
Epoch 22/69
----------
train Loss: 0.0459 Attr Loss: 2.5319 Acc: 0.9974
attribute accuracies
[0.91350021 0.95642183 0.92942142 0.93680755 0.9472302  0.91489536
 0.97816988 0.97078375 0.96528519 0.95223636 0.9755437  0.96864998]
val Loss: 0.2662 Attr Loss: 3.0479 Acc: 0.8788
attribute accuracies
[0.82423435 0.87083888 0.83888149 0.8575233  0.83621838 0.84154461
 0.90013316 0.8988016  0.89480692 0.86284953 0.91344874 0.88948069]
Epoch 23/69
----------
train Loss: 0.0533 Attr Loss: 2.4689 Acc: 0.9962
attribute accuracies
[0.91752154 0.95929421 0.93106278 0.94050062 0.95519081 0.92039393
 0.98137054 0.96881412 0.96503898 0.95395979 0.9755437  0.97045548]
val Loss: 0.2704 Attr Loss: 3.0103 Acc: 0.8842
attribute accuracies
[0.82556591 0.86684421 0.83089214 0.86551265 0.82956059 0.83888149
 0.90545939 0.90013316 0.89747004 0.873502   0.91344874 0.89214381]
Epoch 24/69
----------
train Loss: 0.0558 Attr Loss: 2.4150 Acc: 0.9961
attribute accuracies
[0.92170702 0.96077144 0.94099302 0.94066475 0.9526467  0.92293804
 0.9812064  0.97234304 0.96561346 0.95847353 0.9755437  0.9716865 ]
val Loss: 0.3052 Attr Loss: 3.0645 Acc: 0.8762
attribute accuracies
[0.82689747 0.86684421 0.81890812 0.85352863 0.82689747 0.83621838
 0.90412783 0.8988016  0.89747004 0.87217044 0.91744341 0.88415446]
Epoch 25/69
----------
train Loss: 0.0536 Attr Loss: 2.3726 Acc: 0.9957
attribute accuracies
[0.92203529 0.96159212 0.93853098 0.9436192  0.9544522  0.92745178
 0.98342224 0.97201477 0.96643414 0.96027903 0.9755437  0.97250718]
val Loss: 0.3023 Attr Loss: 2.9914 Acc: 0.8788
attribute accuracies
[0.82956059 0.87083888 0.83355526 0.86817577 0.83488682 0.83888149
 0.90412783 0.8988016  0.89347537 0.86018642 0.91078562 0.89214381]
Epoch 26/69
----------
train Loss: 0.0502 Attr Loss: 2.3068 Acc: 0.9964
attribute accuracies
[0.92507181 0.96315142 0.94526057 0.94862536 0.95904801 0.93450964
 0.98169881 0.97308166 0.96676241 0.95896594 0.9755437  0.97275339]
val Loss: 0.3510 Attr Loss: 3.0389 Acc: 0.8682
attribute accuracies
[0.81624501 0.86950732 0.84687084 0.86551265 0.83754993 0.82556591
 0.90412783 0.90679095 0.89347537 0.87882823 0.91211718 0.90146471]
Epoch 27/69
----------
train Loss: 0.0499 Attr Loss: 2.2672 Acc: 0.9964
attribute accuracies
[0.92720558 0.96528519 0.94821502 0.94665572 0.95880181 0.93311449
 0.98358638 0.97258925 0.96585966 0.96323348 0.9755437  0.97578991]
val Loss: 0.2826 Attr Loss: 2.8249 Acc: 0.8868
attribute accuracies
[0.83621838 0.88415446 0.85219707 0.86284953 0.83888149 0.84420772
 0.90412783 0.8988016  0.89613848 0.87749667 0.91078562 0.89747004]
Epoch 28/69
----------
train Loss: 0.0415 Attr Loss: 2.1810 Acc: 0.9972
attribute accuracies
[0.93311449 0.9678293  0.94911777 0.95248256 0.96430037 0.94000821
 0.9850636  0.97595404 0.96815757 0.96405416 0.9755437  0.97365613]
val Loss: 0.2739 Attr Loss: 2.8064 Acc: 0.8855
attribute accuracies
[0.83089214 0.873502   0.83754993 0.87083888 0.85086551 0.8482024
 0.90945406 0.90545939 0.8988016  0.87749667 0.91078562 0.89214381]
Epoch 29/69
----------
train Loss: 0.0423 Attr Loss: 2.1179 Acc: 0.9973
attribute accuracies
[0.93524826 0.96856791 0.95379565 0.9544522  0.9678293  0.94074682
 0.98604842 0.97767747 0.97127616 0.96700862 0.9755437  0.97964711]
val Loss: 0.2690 Attr Loss: 2.7568 Acc: 0.8881
attribute accuracies
[0.83089214 0.88149134 0.84420772 0.87483356 0.84553928 0.85885486
 0.90545939 0.90146471 0.89613848 0.87882823 0.91211718 0.90412783]
Epoch 30/69
----------
train Loss: 0.0330 Attr Loss: 2.0155 Acc: 0.9975
attribute accuracies
[0.93869512 0.97176857 0.95904801 0.96183833 0.97611818 0.95002052
 0.98596635 0.97792368 0.97037341 0.96930652 0.9755437  0.98030365]
val Loss: 0.2456 Attr Loss: 2.6846 Acc: 0.8895
attribute accuracies
[0.84154461 0.88149134 0.84154461 0.88149134 0.85219707 0.86284953
 0.90545939 0.90412783 0.89747004 0.88681758 0.91344874 0.90279627]
Epoch 31/69
----------
train Loss: 0.0275 Attr Loss: 1.9784 Acc: 0.9979
attribute accuracies
[0.93992614 0.97324579 0.96142799 0.9642183  0.97743127 0.95231842
 0.98637669 0.98038572 0.96971686 0.97176857 0.9755437  0.98079606]
val Loss: 0.2412 Attr Loss: 2.6759 Acc: 0.8961
attribute accuracies
[0.83754993 0.88015979 0.84021305 0.88415446 0.84953395 0.85619174
 0.9081225  0.90679095 0.89747004 0.88015979 0.91078562 0.9081225 ]
Epoch 32/69
----------
train Loss: 0.0266 Attr Loss: 1.9510 Acc: 0.9979
attribute accuracies
[0.94123923 0.97455888 0.96405416 0.96438244 0.97923677 0.95363151
 0.98900287 0.97997538 0.97102995 0.9737382  0.97562577 0.98137054]
val Loss: 0.2428 Attr Loss: 2.6445 Acc: 0.8975
attribute accuracies
[0.84287617 0.87749667 0.84154461 0.87749667 0.85352863 0.86684421
 0.90412783 0.90412783 0.89747004 0.8828229  0.91211718 0.90545939]
Epoch 33/69
----------
train Loss: 0.0262 Attr Loss: 1.9303 Acc: 0.9979
attribute accuracies
[0.94066475 0.97702093 0.96610587 0.96569553 0.97923677 0.95486254
 0.98793599 0.97972918 0.97250718 0.97390234 0.97562577 0.98153467]
val Loss: 0.2291 Attr Loss: 2.6409 Acc: 0.8961
attribute accuracies
[0.83888149 0.88149134 0.84420772 0.8828229  0.85086551 0.86817577
 0.9081225  0.91078562 0.90146471 0.88681758 0.91211718 0.90412783]
Epoch 34/69
----------
train Loss: 0.0258 Attr Loss: 1.9308 Acc: 0.9979
attribute accuracies
[0.94148543 0.97595404 0.96585966 0.96356176 0.97661059 0.95551908
 0.98768978 0.98038572 0.9719327  0.97455888 0.9755437  0.98030365]
val Loss: 0.2416 Attr Loss: 2.6085 Acc: 0.8948
attribute accuracies
[0.84420772 0.8828229  0.84687084 0.88548602 0.85086551 0.86817577
 0.90679095 0.90412783 0.8988016  0.88814913 0.91211718 0.90679095]
Epoch 35/69
----------
train Loss: 0.0268 Attr Loss: 1.9113 Acc: 0.9979
attribute accuracies
[0.94263439 0.97636438 0.96709069 0.9657776  0.97784161 0.95740665
 0.98768978 0.98046779 0.97283545 0.97382027 0.97562577 0.98128847]
val Loss: 0.2385 Attr Loss: 2.6120 Acc: 0.8948
attribute accuracies
[0.83621838 0.88681758 0.84021305 0.88948069 0.86551265 0.86418109
 0.90679095 0.90679095 0.89747004 0.88415446 0.91078562 0.8988016 ]
Epoch 36/69
----------
train Loss: 0.0267 Attr Loss: 1.9036 Acc: 0.9979
attribute accuracies
[0.94238818 0.97496922 0.96635207 0.96536725 0.97882643 0.95404185
 0.98818219 0.97964711 0.97185064 0.973492   0.9755437  0.98399672]
val Loss: 0.2349 Attr Loss: 2.5771 Acc: 0.8988
attribute accuracies
[0.84154461 0.88548602 0.85086551 0.88415446 0.86018642 0.86551265
 0.90945406 0.91211718 0.8988016  0.8828229  0.91211718 0.9081225 ]
Epoch 37/69
----------
train Loss: 0.0266 Attr Loss: 1.8912 Acc: 0.9979
attribute accuracies
[0.94378334 0.97743127 0.96733689 0.96618794 0.9791547  0.95658597
 0.98727944 0.98071399 0.97291752 0.97382027 0.97562577 0.98128847]
val Loss: 0.2369 Attr Loss: 2.5569 Acc: 0.8948
attribute accuracies
[0.83754993 0.8828229  0.84553928 0.88948069 0.86284953 0.86284953
 0.9081225  0.90945406 0.8988016  0.88681758 0.91211718 0.90412783]
Epoch 38/69
----------
train Loss: 0.0273 Attr Loss: 1.8700 Acc: 0.9979
attribute accuracies
[0.94476816 0.97644645 0.96823964 0.96856791 0.98169881 0.95781699
 0.98752565 0.98030365 0.97382027 0.97431268 0.9755437  0.98432499]
val Loss: 0.2561 Attr Loss: 2.6024 Acc: 0.8895
attribute accuracies
[0.84420772 0.88149134 0.84553928 0.88814913 0.8575233  0.86817577
 0.9081225  0.9081225  0.89480692 0.88548602 0.91344874 0.89480692]
Epoch 39/69
----------
train Loss: 0.0277 Attr Loss: 1.8666 Acc: 0.9979
attribute accuracies
[0.94599918 0.97743127 0.96832171 0.96815757 0.98054986 0.95699631
 0.98924908 0.98161674 0.97226098 0.97488716 0.9755437  0.98342224]
val Loss: 0.2373 Attr Loss: 2.5413 Acc: 0.8961
attribute accuracies
[0.84021305 0.8828229  0.84687084 0.89081225 0.85619174 0.86551265
 0.91078562 0.90945406 0.90013316 0.8828229  0.91344874 0.90545939]
Epoch 40/69
----------
train Loss: 0.0276 Attr Loss: 1.8657 Acc: 0.9979
attribute accuracies
[0.94468609 0.97636438 0.9696348  0.96659828 0.98022158 0.95748872
 0.98998769 0.98054986 0.97455888 0.97513336 0.97578991 0.98260156]
val Loss: 0.2402 Attr Loss: 2.5591 Acc: 0.8948
attribute accuracies
[0.84021305 0.88149134 0.84420772 0.88948069 0.85486019 0.86418109
 0.91211718 0.90679095 0.89747004 0.88149134 0.91344874 0.90412783]
Epoch 41/69
----------
train Loss: 0.0284 Attr Loss: 1.8556 Acc: 0.9979
attribute accuracies
[0.94443989 0.97923677 0.97029134 0.96594173 0.97989331 0.95937628
 0.98916701 0.97948297 0.97275339 0.97488716 0.9755437  0.98424292]
val Loss: 0.2407 Attr Loss: 2.5294 Acc: 0.8948
attribute accuracies
[0.84154461 0.88015979 0.83888149 0.88948069 0.85352863 0.873502
 0.90679095 0.91344874 0.90146471 0.88149134 0.91078562 0.90279627]
Epoch 42/69
----------
train Loss: 0.0278 Attr Loss: 1.8353 Acc: 0.9979
attribute accuracies
[0.9451785  0.97948297 0.97029134 0.96684448 0.9827657  0.95880181
 0.98834633 0.98112433 0.97299959 0.97464095 0.97562577 0.98440706]
val Loss: 0.2310 Attr Loss: 2.5066 Acc: 0.8961
attribute accuracies
[0.8482024  0.88015979 0.84687084 0.89081225 0.86418109 0.86950732
 0.90679095 0.91211718 0.90279627 0.88681758 0.91344874 0.90545939]
Epoch 43/69
----------
train Loss: 0.0287 Attr Loss: 1.8335 Acc: 0.9979
attribute accuracies
[0.94591711 0.97849815 0.96922446 0.96873205 0.98292983 0.95937628
 0.98744358 0.98046779 0.97324579 0.97652852 0.9755437  0.98424292]
val Loss: 0.2585 Attr Loss: 2.5790 Acc: 0.8921
attribute accuracies
[0.83754993 0.88415446 0.84021305 0.88681758 0.8575233  0.86418109
 0.9081225  0.90679095 0.90013316 0.88415446 0.91478029 0.90412783]
Epoch 44/69
----------
train Loss: 0.0294 Attr Loss: 1.8218 Acc: 0.9979
attribute accuracies
[0.94575297 0.97972918 0.97127616 0.96906032 0.98334017 0.96142799
 0.98793599 0.98161674 0.97439475 0.97652852 0.9755437  0.98292983]
val Loss: 0.2504 Attr Loss: 2.5525 Acc: 0.8948
attribute accuracies
[0.83754993 0.88548602 0.84021305 0.88681758 0.86018642 0.87217044
 0.9081225  0.90679095 0.90013316 0.8828229  0.91078562 0.9081225 ]
Epoch 45/69
----------
train Loss: 0.0295 Attr Loss: 1.8142 Acc: 0.9979
attribute accuracies
[0.94509643 0.97989331 0.97078375 0.96922446 0.98284776 0.96224867
 0.98768978 0.98334017 0.97480509 0.97587197 0.9755437  0.9848174 ]
val Loss: 0.2475 Attr Loss: 2.5247 Acc: 0.8988
attribute accuracies
[0.84687084 0.88415446 0.84021305 0.88681758 0.86284953 0.86817577
 0.9081225  0.90679095 0.90279627 0.88415446 0.91078562 0.90279627]
Epoch 46/69
----------
train Loss: 0.0303 Attr Loss: 1.8229 Acc: 0.9979
attribute accuracies
[0.9472302  0.97841609 0.97234304 0.97037341 0.98235535 0.96052524
 0.98875667 0.98210915 0.97382027 0.97578991 0.9755437  0.98317604]
val Loss: 0.2576 Attr Loss: 2.5192 Acc: 0.8975
attribute accuracies
[0.84420772 0.8828229  0.84021305 0.88548602 0.8575233  0.87083888
 0.91078562 0.90945406 0.8988016  0.88681758 0.91211718 0.90679095]
Epoch 47/69
----------
train Loss: 0.0304 Attr Loss: 1.8007 Acc: 0.9979
attribute accuracies
[0.94509643 0.97931883 0.97275339 0.97078375 0.98383258 0.96331555
 0.9884284  0.98161674 0.97234304 0.97792368 0.9755437  0.98391465]
val Loss: 0.2555 Attr Loss: 2.5411 Acc: 0.8948
attribute accuracies
[0.84021305 0.87882823 0.8482024  0.88814913 0.85352863 0.85486019
 0.90679095 0.90679095 0.90146471 0.8828229  0.91211718 0.90146471]
Epoch 48/69
----------
train Loss: 0.0298 Attr Loss: 1.7989 Acc: 0.9979
attribute accuracies
[0.94608125 0.98128847 0.97135823 0.97094789 0.98334017 0.9621666
 0.98965942 0.98260156 0.97472302 0.97858022 0.9755437  0.98440706]
val Loss: 0.2647 Attr Loss: 2.5253 Acc: 0.8908
attribute accuracies
[0.84687084 0.88681758 0.84287617 0.88948069 0.86817577 0.86418109
 0.9081225  0.90945406 0.8988016  0.88149134 0.91211718 0.90412783]
Epoch 49/69
----------
train Loss: 0.0311 Attr Loss: 1.7917 Acc: 0.9979
attribute accuracies
[0.94624538 0.98054986 0.9719327  0.97045548 0.98399672 0.96249487
 0.98924908 0.98071399 0.97488716 0.97513336 0.9755437  0.98424292]
val Loss: 0.2552 Attr Loss: 2.4905 Acc: 0.8921
attribute accuracies
[0.84287617 0.88015979 0.84287617 0.89480692 0.86151798 0.86817577
 0.90945406 0.90545939 0.90013316 0.88814913 0.91478029 0.91211718]
Epoch 50/69
----------
train Loss: 0.0303 Attr Loss: 1.7852 Acc: 0.9979
attribute accuracies
[0.94706606 0.97972918 0.97291752 0.97045548 0.98169881 0.96052524
 0.98990562 0.98358638 0.97447682 0.97866229 0.97562577 0.98358638]
val Loss: 0.2530 Attr Loss: 2.5110 Acc: 0.8975
attribute accuracies
[0.83888149 0.88149134 0.84287617 0.88681758 0.86018642 0.87083888
 0.90945406 0.91078562 0.8988016  0.88948069 0.91211718 0.90146471]
Epoch 51/69
----------
train Loss: 0.0315 Attr Loss: 1.7746 Acc: 0.9979
attribute accuracies
[0.94821502 0.97956504 0.97365613 0.97160443 0.98563808 0.96265901
 0.99015183 0.9827657  0.97423061 0.97767747 0.9755437  0.98424292]
val Loss: 0.2632 Attr Loss: 2.4679 Acc: 0.8908
attribute accuracies
[0.85086551 0.8828229  0.84420772 0.89214381 0.86817577 0.87217044
 0.9081225  0.91078562 0.89613848 0.8828229  0.91211718 0.90945406]
Epoch 52/69
----------
train Loss: 0.0319 Attr Loss: 1.7731 Acc: 0.9979
attribute accuracies
[0.94813295 0.97874436 0.97316373 0.97201477 0.98424292 0.96019696
 0.98949528 0.98448913 0.97496922 0.97718506 0.9755437  0.98555601]
val Loss: 0.2471 Attr Loss: 2.4557 Acc: 0.8988
attribute accuracies
[0.84287617 0.88149134 0.84553928 0.89214381 0.86684421 0.86817577
 0.90945406 0.90679095 0.90146471 0.88548602 0.91211718 0.90679095]
Epoch 53/69
----------
train Loss: 0.0310 Attr Loss: 1.7636 Acc: 0.9979
attribute accuracies
[0.94854329 0.98013952 0.97234304 0.97357407 0.98407879 0.96610587
 0.98982355 0.98260156 0.97537957 0.97841609 0.97562577 0.98678703]
val Loss: 0.2521 Attr Loss: 2.4601 Acc: 0.8935
attribute accuracies
[0.84953395 0.88015979 0.8482024  0.89480692 0.86018642 0.87083888
 0.9081225  0.90945406 0.90013316 0.8828229  0.91478029 0.90412783]
Epoch 54/69
----------
train Loss: 0.0313 Attr Loss: 1.7619 Acc: 0.9979
attribute accuracies
[0.94862536 0.97972918 0.97472302 0.9714403  0.98317604 0.96668034
 0.98941321 0.98202708 0.97423061 0.98071399 0.9755437  0.98489947]
val Loss: 0.2575 Attr Loss: 2.4750 Acc: 0.8935
attribute accuracies
[0.84287617 0.8828229  0.85086551 0.89081225 0.86018642 0.87882823
 0.91078562 0.91211718 0.90545939 0.88548602 0.91211718 0.91344874]
Epoch 55/69
----------
train Loss: 0.0307 Attr Loss: 1.7455 Acc: 0.9979
attribute accuracies
[0.94911777 0.97907263 0.97365613 0.97185064 0.98555601 0.96585966
 0.98982355 0.98243742 0.97505129 0.9773492  0.9755437  0.98539188]
val Loss: 0.2572 Attr Loss: 2.4973 Acc: 0.8948
attribute accuracies
[0.85086551 0.88681758 0.84553928 0.89081225 0.86551265 0.86950732
 0.90945406 0.90679095 0.90146471 0.88415446 0.91078562 0.91078562]
Epoch 56/69
----------
train Loss: 0.0313 Attr Loss: 1.7452 Acc: 0.9979
attribute accuracies
[0.94772261 0.97997538 0.97439475 0.97496922 0.98522774 0.96446451
 0.98974149 0.98178088 0.97595404 0.9791547  0.9755437  0.9866229 ]
val Loss: 0.2451 Attr Loss: 2.4186 Acc: 0.8988
attribute accuracies
[0.85352863 0.88814913 0.85352863 0.88948069 0.86151798 0.87083888
 0.91211718 0.91344874 0.90412783 0.88948069 0.91211718 0.90545939]
Epoch 57/69
----------
train Loss: 0.0309 Attr Loss: 1.7315 Acc: 0.9979
attribute accuracies
[0.94813295 0.98268363 0.97595404 0.97365613 0.98530981 0.96438244
 0.98982355 0.98416085 0.97628231 0.97923677 0.9755437  0.98596635]
val Loss: 0.2418 Attr Loss: 2.4391 Acc: 0.9028
attribute accuracies
[0.84953395 0.88548602 0.85486019 0.88948069 0.86418109 0.86817577
 0.91478029 0.91078562 0.90013316 0.88814913 0.91344874 0.91211718]
Epoch 58/69
----------
train Loss: 0.0317 Attr Loss: 1.7351 Acc: 0.9979
attribute accuracies
[0.94714813 0.98128847 0.97332786 0.97201477 0.98514567 0.96709069
 0.99105458 0.98309397 0.9755437  0.97956504 0.97570784 0.98703324]
val Loss: 0.2587 Attr Loss: 2.4316 Acc: 0.8935
attribute accuracies
[0.85486019 0.88548602 0.8482024  0.88814913 0.86950732 0.87483356
 0.9081225  0.91211718 0.90013316 0.8828229  0.91344874 0.9081225 ]
Epoch 59/69
----------
train Loss: 0.0317 Attr Loss: 1.7252 Acc: 0.9979
attribute accuracies
[0.95043086 0.97964711 0.97365613 0.97332786 0.98514567 0.96643414
 0.98974149 0.98407879 0.9755437  0.97899056 0.9755437  0.98580222]
val Loss: 0.2657 Attr Loss: 2.4846 Acc: 0.8908
attribute accuracies
[0.85086551 0.8828229  0.84953395 0.88814913 0.86018642 0.86684421
 0.9081225  0.90679095 0.90013316 0.88814913 0.91211718 0.91078562]
Epoch 60/69
----------
train Loss: 0.0309 Attr Loss: 1.7223 Acc: 0.9979
attribute accuracies
[0.95207222 0.98137054 0.97636438 0.97488716 0.98522774 0.96553139
 0.98957735 0.9832581  0.97652852 0.97972918 0.9755437  0.9868691 ]
val Loss: 0.2550 Attr Loss: 2.4639 Acc: 0.8961
attribute accuracies
[0.84687084 0.8828229  0.84687084 0.89347537 0.86151798 0.87217044
 0.9081225  0.9081225  0.90279627 0.8828229  0.91478029 0.90679095]
Epoch 61/69
----------
train Loss: 0.0305 Attr Loss: 1.7106 Acc: 0.9979
attribute accuracies
[0.95018465 0.98309397 0.97447682 0.97537957 0.98670497 0.96462864
 0.99121871 0.98391465 0.97578991 0.98054986 0.97562577 0.98555601]
val Loss: 0.2590 Attr Loss: 2.4760 Acc: 0.8948
attribute accuracies
[0.84687084 0.88415446 0.85619174 0.88814913 0.86284953 0.86950732
 0.90945406 0.91078562 0.8988016  0.88948069 0.91078562 0.90945406]
Epoch 62/69
----------
train Loss: 0.0310 Attr Loss: 1.7116 Acc: 0.9979
attribute accuracies
[0.95026672 0.98169881 0.97677472 0.97291752 0.98530981 0.96741896
 0.99064423 0.98522774 0.97620025 0.98038572 0.9755437  0.98580222]
val Loss: 0.2532 Attr Loss: 2.4381 Acc: 0.8948
attribute accuracies
[0.84553928 0.88415446 0.84420772 0.89081225 0.86950732 0.87083888
 0.91344874 0.9081225  0.90146471 0.88548602 0.91078562 0.90945406]
Epoch 63/69
----------
train Loss: 0.0310 Attr Loss: 1.7062 Acc: 0.9979
attribute accuracies
[0.94911777 0.98292983 0.9773492  0.97340993 0.98629462 0.96791137
 0.99105458 0.98539188 0.97423061 0.98219122 0.9755437  0.98621256]
val Loss: 0.2567 Attr Loss: 2.4543 Acc: 0.8948
attribute accuracies
[0.8482024  0.88149134 0.84687084 0.89613848 0.86284953 0.87483356
 0.90945406 0.90679095 0.90279627 0.89347537 0.91211718 0.90545939]
Epoch 64/69
----------
train Loss: 0.0310 Attr Loss: 1.7141 Acc: 0.9979
attribute accuracies
[0.95166188 0.98202708 0.97620025 0.97505129 0.98416085 0.96528519
 0.99023389 0.98440706 0.97644645 0.98071399 0.97570784 0.98629462]
val Loss: 0.2590 Attr Loss: 2.4441 Acc: 0.8948
attribute accuracies
[0.8482024  0.8828229  0.84687084 0.88814913 0.86551265 0.87217044
 0.91344874 0.90945406 0.90146471 0.88814913 0.91344874 0.90679095]
Epoch 65/69
----------
train Loss: 0.0302 Attr Loss: 1.7145 Acc: 0.9979
attribute accuracies
[0.94796881 0.98235535 0.97595404 0.973492   0.98555601 0.96700862
 0.99006976 0.98350431 0.97661059 0.98219122 0.9755437  0.98736151]
val Loss: 0.2541 Attr Loss: 2.4177 Acc: 0.8948
attribute accuracies
[0.85086551 0.88415446 0.84953395 0.89347537 0.86950732 0.86684421
 0.90945406 0.9081225  0.90146471 0.88681758 0.91078562 0.90945406]
Epoch 66/69
----------
train Loss: 0.0312 Attr Loss: 1.7162 Acc: 0.9979
attribute accuracies
[0.94911777 0.98334017 0.97693886 0.97472302 0.98457119 0.96947066
 0.99056217 0.98251949 0.97611818 0.98137054 0.9755437  0.98547394]
val Loss: 0.2605 Attr Loss: 2.4455 Acc: 0.8961
attribute accuracies
[0.8575233  0.87882823 0.85486019 0.88681758 0.86284953 0.87217044
 0.91078562 0.9081225  0.90279627 0.8828229  0.91344874 0.90945406]
Epoch 67/69
----------
train Loss: 0.0306 Attr Loss: 1.7098 Acc: 0.9979
attribute accuracies
[0.95067706 0.98194501 0.97800574 0.97464095 0.98703324 0.96594173
 0.98974149 0.98292983 0.97587197 0.98063192 0.9755437  0.9866229 ]
val Loss: 0.2572 Attr Loss: 2.4525 Acc: 0.8961
attribute accuracies
[0.8482024  0.88015979 0.85219707 0.88814913 0.86950732 0.87083888
 0.90945406 0.91078562 0.90412783 0.88548602 0.91211718 0.91344874]
Epoch 68/69
----------
train Loss: 0.0300 Attr Loss: 1.7053 Acc: 0.9979
attribute accuracies
[0.94993845 0.98210915 0.97595404 0.97521543 0.98645876 0.96750103
 0.98965942 0.98539188 0.97636438 0.98219122 0.97562577 0.98736151]
val Loss: 0.2645 Attr Loss: 2.4440 Acc: 0.8948
attribute accuracies
[0.85086551 0.88548602 0.85619174 0.89347537 0.86817577 0.87217044
 0.90945406 0.9081225  0.90279627 0.88814913 0.91211718 0.91211718]
Epoch 69/69
----------
train Loss: 0.0306 Attr Loss: 1.7075 Acc: 0.9979
attribute accuracies
[0.94993845 0.98334017 0.97439475 0.97447682 0.98768978 0.96733689
 0.98941321 0.98514567 0.973492   0.98079606 0.97570784 0.98596635]
val Loss: 0.2607 Attr Loss: 2.4393 Acc: 0.8935
attribute accuracies
[0.84953395 0.88149134 0.84687084 0.89347537 0.86950732 0.87616511
 0.91078562 0.90945406 0.90412783 0.88415446 0.91211718 0.90679095]
Training complete in 69m 19s
