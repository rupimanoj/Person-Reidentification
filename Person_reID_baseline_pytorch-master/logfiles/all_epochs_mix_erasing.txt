2
adam_freeze_75.txt
adam_output.txt
all_epochs_mix_erasing.txt
all_epochs_multi_erasing.txt
all_epochs.txt
attribute_data.npy
attribute_data_preprocessing.ipynb
Attributes verification.ipynb
collect_results.py
demo.py
dense_attr_color_erasing_70e.txt
dense_attr_color_erasing.txt
dense_attr_color.txt
dense_attr_full_set.txt
dense_attr_no_color.txt
dense_attr.txt
dense_erasing_all_epochs.txt
downcolor.npy
Ensembling experimentation.ipynb
erasing_data_augmentation_checking.ipynb
evaluate_ensemble.py
evaluate_gpu.py
evaluate_int.py
evaluate.py
evaluate_rerank.py
extract.py
extract_tta.py
feeze_learning.ipynb
image_net_erasing.txt
image_net_erasing_wde3.txt
image_net_freeze.txt
image_net_wde3.txt
image_net_wde5.txt
labels.npy
LICENSE
load_mat_file.py
market_attribute.mat
mkt_0.4g_freeze.txt
model
model.py
multi_random_erasing.py
multi_step_LR_3
multi_step_LR_3.txt
multi_step_LR.txt
my_0.png
my_1.png
my_2.png
my_3.png
my_4.png
my_5.png
my_6.png
my_7.png
my_8.png
my_9.png
my.png
output_pcb_attr.txt
output_sat_color.txt
output_sat_erasing.txt
output_sat.txt
prepare.py
prepare_static.py
__pycache__
random_erasing.py
README.md
re_ranking.py
results_collection.ipynb
sample_model
show.png
test.py
train_attr_dl.py
train_attr.py
train.jpg
train_pcb_attr.py
train_pcb_attr_resnet.py
train.py
tta_expermimenation.ipynb
tutorial
untitled
untitled1
Untitled1.ipynb
Untitled.ipynb
upcolor.npy
use_info.md
visualize.py
net output size:
torch.Size([8, 1024])
0
[ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0), Resize(size=(288, 144), interpolation=PIL.Image.BICUBIC), RandomCrop(size=(256, 128), padding=0), RandomHorizontalFlip(p=0.5), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), <random_erasing.RandomErasing object at 0x7fa3ad8713c8>]
ft_attr_net_dense(
  (model): DenseNet(
    (features): Sequential(
      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu0): ReLU(inplace)
      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (denseblock1): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (transition1): _Transition(
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
      (denseblock2): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer7): _DenseLayer(
          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer8): _DenseLayer(
          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer9): _DenseLayer(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer10): _DenseLayer(
          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer11): _DenseLayer(
          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer12): _DenseLayer(
          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (transition2): _Transition(
        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
      (denseblock3): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer7): _DenseLayer(
          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer8): _DenseLayer(
          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer9): _DenseLayer(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer10): _DenseLayer(
          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer11): _DenseLayer(
          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer12): _DenseLayer(
          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer13): _DenseLayer(
          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer14): _DenseLayer(
          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer15): _DenseLayer(
          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer16): _DenseLayer(
          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer17): _DenseLayer(
          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer18): _DenseLayer(
          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer19): _DenseLayer(
          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer20): _DenseLayer(
          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer21): _DenseLayer(
          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer22): _DenseLayer(
          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer23): _DenseLayer(
          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer24): _DenseLayer(
          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (transition3): _Transition(
        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
      (denseblock4): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer7): _DenseLayer(
          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer8): _DenseLayer(
          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer9): _DenseLayer(
          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer10): _DenseLayer(
          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer11): _DenseLayer(
          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer12): _DenseLayer(
          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer13): _DenseLayer(
          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer14): _DenseLayer(
          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer15): _DenseLayer(
          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer16): _DenseLayer(
          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Linear(in_features=1024, out_features=1000, bias=True)
    (fc): Sequential()
  )
  (classifier): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=1500, bias=True)
    )
  )
  (classifierage): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=4, bias=True)
    )
  )
  (classifierbackpack): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierbag): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierhandbag): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierdowncolor): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=9, bias=True)
    )
  )
  (classifierupcolor): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=8, bias=True)
    )
  )
  (classifierclothes): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierdown): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierup): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierhair): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierhat): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifiergender): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
)
/opt/anaconda3/lib/python3.7/site-packages/torchvision-0.2.1-py3.7.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:14: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
  init.kaiming_normal(m.weight.data, a=0, mode='fan_out')
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:15: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(m.bias.data, 0.0)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:17: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.
  init.normal(m.weight.data, 1.0, 0.02)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:18: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(m.bias.data, 0.0)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:23: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.
  init.normal(m.weight.data, std=0.001)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:24: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(m.bias.data, 0.0)
0.5167250633239746
attr_data.shape
torch.Size([1501, 12])
checking model folder------------------- ./model/all_epochs_mix_erasing
True
No. of Attributes selected
12
Epoch 0/69
----------
Exception ignored in: <function _DataLoaderIter.__del__ at 0x7fa3b07908c8>
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 399, in __del__
    self._shutdown_workers()
  File "/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 378, in _shutdown_workers
    self.worker_result_queue.get()
  File "/opt/anaconda3/lib/python3.7/multiprocessing/queues.py", line 354, in get
    return _ForkingPickler.loads(res)
  File "/opt/anaconda3/lib/python3.7/site-packages/torch/multiprocessing/reductions.py", line 151, in rebuild_storage_fd
    fd = df.detach()
  File "/opt/anaconda3/lib/python3.7/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/opt/anaconda3/lib/python3.7/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/opt/anaconda3/lib/python3.7/multiprocessing/connection.py", line 498, in Client
    answer_challenge(c, authkey)
  File "/opt/anaconda3/lib/python3.7/multiprocessing/connection.py", line 741, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
  File "/opt/anaconda3/lib/python3.7/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/opt/anaconda3/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/opt/anaconda3/lib/python3.7/multiprocessing/connection.py", line 383, in _recv
    raise EOFError
EOFError: 
train Loss: 4.9190 Attr Loss: 8.1800 Acc: 0.1674
attribute accuracies
[0.81079536 0.7318308  0.76478034 0.89196472 0.43638739 0.29458599
 0.87616365 0.62861342 0.94724808 0.65543851 0.97105177 0.57112527]
val Loss: 3.3901 Attr Loss: 7.9860 Acc: 0.3073
attribute accuracies
[0.79133333 0.73       0.738      0.87533333 0.42733333 0.28
 0.85133333 0.62       0.92666667 0.64333333 0.95266667 0.568     ]
Epoch 1/69
----------
train Loss: 2.2818 Attr Loss: 7.9683 Acc: 0.4793
attribute accuracies
[0.81177527 0.7329332  0.76547444 0.89302629 0.43981708 0.30875388
 0.87787849 0.63236975 0.94802384 0.65658174 0.97248081 0.58435407]
val Loss: 1.7358 Attr Loss: 7.8828 Acc: 0.5793
attribute accuracies
[0.78933333 0.72866667 0.73733333 0.87533333 0.43133333 0.30133333
 0.854      0.61333333 0.92533333 0.64466667 0.954      0.57066667]
Epoch 2/69
----------
train Loss: 1.4900 Attr Loss: 7.8923 Acc: 0.6316
attribute accuracies
[0.81173444 0.73281071 0.7655561  0.89318961 0.44136861 0.31696064
 0.87791932 0.63318635 0.94786053 0.66115466 0.97256247 0.59893026]
val Loss: 1.2677 Attr Loss: 7.8813 Acc: 0.6633
attribute accuracies
[0.78933333 0.72733333 0.73933333 0.87533333 0.42733333 0.29533333
 0.85333333 0.61866667 0.92666667 0.64133333 0.95266667 0.572     ]
Epoch 3/69
----------
train Loss: 1.1060 Attr Loss: 7.8407 Acc: 0.7194
attribute accuracies
[0.81173444 0.73285154 0.76571942 0.89314878 0.44112363 0.32071697
 0.87783766 0.63486036 0.94786053 0.66666667 0.97243998 0.60505471]
val Loss: 0.9570 Attr Loss: 7.8294 Acc: 0.7413
attribute accuracies
[0.78933333 0.72933333 0.742      0.87466667 0.42933333 0.312
 0.85666667 0.62066667 0.92666667 0.64666667 0.95266667 0.57266667]
Epoch 4/69
----------
train Loss: 0.9455 Attr Loss: 7.7982 Acc: 0.7568
attribute accuracies
[0.8118161  0.73309652 0.76543361 0.89318961 0.44222603 0.32835211
 0.87787849 0.63575862 0.94798301 0.66609505 0.97243998 0.61015842]
val Loss: 0.8009 Attr Loss: 7.8227 Acc: 0.7947
attribute accuracies
[0.79       0.73066667 0.73866667 0.87466667 0.42666667 0.30733333
 0.85266667 0.622      0.92733333 0.65066667 0.95266667 0.56733333]
Epoch 5/69
----------
train Loss: 0.8044 Attr Loss: 7.7672 Acc: 0.7933
attribute accuracies
[0.81177527 0.73313735 0.76584191 0.89314878 0.44230769 0.32827046
 0.87787849 0.63935163 0.94790136 0.66760575 0.97256247 0.61787522]
val Loss: 0.7068 Attr Loss: 7.7924 Acc: 0.8080
attribute accuracies
[0.79066667 0.72866667 0.74066667 0.876      0.43       0.324
 0.85333333 0.62666667 0.926      0.642      0.95266667 0.57666667]
Epoch 6/69
----------
train Loss: 0.7344 Attr Loss: 7.7357 Acc: 0.8150
attribute accuracies
[0.8118161  0.73354565 0.76551527 0.89318961 0.44210354 0.33231259
 0.87796015 0.63861669 0.94790136 0.67083129 0.97248081 0.62440797]
val Loss: 0.6950 Attr Loss: 7.7886 Acc: 0.7987
attribute accuracies
[0.794      0.72866667 0.738      0.87533333 0.42533333 0.31333333
 0.856      0.62666667 0.926      0.64733333 0.95333333 0.58266667]
Epoch 7/69
----------
train Loss: 0.6794 Attr Loss: 7.7069 Acc: 0.8284
attribute accuracies
[0.81193859 0.73370897 0.76576025 0.89306712 0.44320594 0.33766128
 0.87791932 0.64057651 0.94790136 0.67573085 0.97243998 0.63424792]
val Loss: 0.6336 Attr Loss: 7.7732 Acc: 0.8373
attribute accuracies
[0.78866667 0.72733333 0.74133333 0.87333333 0.426      0.32533333
 0.854      0.62333333 0.926      0.64866667 0.95333333 0.59066667]
Epoch 8/69
----------
train Loss: 0.6365 Attr Loss: 7.6807 Acc: 0.8375
attribute accuracies
[0.8118161  0.73415809 0.76584191 0.89294463 0.44345092 0.34056018
 0.877756   0.64204638 0.94790136 0.67426098 0.97243998 0.63682019]
val Loss: 0.6358 Attr Loss: 7.7800 Acc: 0.8360
attribute accuracies
[0.79       0.73133333 0.74       0.87333333 0.42466667 0.30666667
 0.85266667 0.62066667 0.92533333 0.644      0.954      0.58933333]
Epoch 9/69
----------
train Loss: 0.5911 Attr Loss: 7.6507 Acc: 0.8496
attribute accuracies
[0.81197942 0.73379063 0.76592357 0.89310795 0.44341009 0.34586804
 0.87791932 0.64396538 0.94790136 0.67683325 0.97243998 0.63918831]
val Loss: 0.5180 Attr Loss: 7.7373 Acc: 0.8587
attribute accuracies
[0.79       0.726      0.74       0.87533333 0.42133333 0.326
 0.854      0.62866667 0.92733333 0.65133333 0.95333333 0.6       ]
Epoch 10/69
----------
train Loss: 0.5678 Attr Loss: 7.6301 Acc: 0.8568
attribute accuracies
[0.81165278 0.73419892 0.76571942 0.89310795 0.44655398 0.3485628
 0.87779683 0.64870162 0.94790136 0.68107954 0.97243998 0.64641516]
val Loss: 0.5727 Attr Loss: 7.7591 Acc: 0.8413
attribute accuracies
[0.79133333 0.728      0.74       0.87666667 0.42733333 0.32533333
 0.85266667 0.62466667 0.92533333 0.658      0.95266667 0.608     ]
Epoch 11/69
----------
train Loss: 0.5674 Attr Loss: 7.6076 Acc: 0.8567
attribute accuracies
[0.81193859 0.7340356  0.7655561  0.89306712 0.44634983 0.35374816
 0.87787849 0.64919157 0.94790136 0.68332517 0.97248081 0.64992651]
val Loss: 0.5995 Attr Loss: 7.7147 Acc: 0.8427
attribute accuracies
[0.79       0.73266667 0.73866667 0.876      0.43466667 0.318
 0.856      0.62533333 0.92733333 0.66733333 0.95266667 0.60733333]
Epoch 12/69
----------
train Loss: 0.5461 Attr Loss: 7.5883 Acc: 0.8645
attribute accuracies
[0.8118161  0.73366814 0.76563776 0.89323044 0.4485138  0.35391148
 0.87787849 0.65029397 0.94786053 0.68544831 0.97248081 0.65196799]
val Loss: 0.5063 Attr Loss: 7.6730 Acc: 0.8573
attribute accuracies
[0.78933333 0.73       0.74066667 0.87666667 0.432      0.33333333
 0.85333333 0.628      0.92666667 0.656      0.95333333 0.60866667]
Epoch 13/69
----------
train Loss: 0.4992 Attr Loss: 7.5578 Acc: 0.8736
attribute accuracies
[0.81173444 0.73415809 0.76559693 0.89323044 0.45280091 0.35599379
 0.87779683 0.6540503  0.9478197  0.68748979 0.97243998 0.65739833]
val Loss: 0.5433 Attr Loss: 7.6811 Acc: 0.8567
attribute accuracies
[0.78933333 0.732      0.73733333 0.87466667 0.43333333 0.32466667
 0.85333333 0.63       0.926      0.656      0.95266667 0.614     ]
Epoch 14/69
----------
train Loss: 0.4923 Attr Loss: 7.5405 Acc: 0.8797
attribute accuracies
[0.81177527 0.73354565 0.76608689 0.89306712 0.45492406 0.36097501
 0.87796015 0.65458109 0.94798301 0.68793892 0.97248081 0.66156296]
val Loss: 0.5055 Attr Loss: 7.6513 Acc: 0.8733
attribute accuracies
[0.79       0.72666667 0.74       0.876      0.434      0.33866667
 0.854      0.63133333 0.92533333 0.66266667 0.95333333 0.62533333]
Epoch 15/69
----------
train Loss: 0.4965 Attr Loss: 7.5220 Acc: 0.8779
attribute accuracies
[0.81185693 0.73379063 0.76592357 0.89323044 0.45684305 0.36232239
 0.87808264 0.65462192 0.94794219 0.69263433 0.97243998 0.66135881]
val Loss: 0.4545 Attr Loss: 7.6616 Acc: 0.8687
attribute accuracies
[0.78866667 0.732      0.738      0.87466667 0.44866667 0.324
 0.85466667 0.63066667 0.92666667 0.67133333 0.95266667 0.62733333]
Epoch 16/69
----------
train Loss: 0.4746 Attr Loss: 7.5136 Acc: 0.8836
attribute accuracies
[0.81169361 0.73354565 0.76571942 0.89314878 0.45782296 0.36211824
 0.87779683 0.65437694 0.94786053 0.69357341 0.97256247 0.66397191]
val Loss: 0.4584 Attr Loss: 7.6190 Acc: 0.8733
attribute accuracies
[0.79       0.72866667 0.738      0.87533333 0.44333333 0.34266667
 0.85466667 0.63266667 0.92533333 0.65866667 0.95266667 0.62533333]
Epoch 17/69
----------
train Loss: 0.4441 Attr Loss: 7.4908 Acc: 0.8916
attribute accuracies
[0.81189776 0.73354565 0.76576025 0.89306712 0.46080353 0.36660951
 0.87808264 0.65662257 0.94786053 0.69287931 0.97252164 0.66429855]
val Loss: 0.5692 Attr Loss: 7.6429 Acc: 0.8520
attribute accuracies
[0.792      0.728      0.74133333 0.874      0.43266667 0.338
 0.854      0.636      0.92666667 0.654      0.95266667 0.62266667]
Epoch 18/69
----------
train Loss: 0.4307 Attr Loss: 7.4809 Acc: 0.8948
attribute accuracies
[0.81202025 0.7333415  0.76576025 0.89318961 0.45974196 0.36387392
 0.877756   0.65980728 0.94786053 0.69385922 0.97252164 0.67013719]
val Loss: 0.4715 Attr Loss: 7.5997 Acc: 0.8700
attribute accuracies
[0.79066667 0.73       0.738      0.87666667 0.45133333 0.34066667
 0.85533333 0.64666667 0.92666667 0.67333333 0.95266667 0.63533333]
Epoch 19/69
----------
train Loss: 0.4420 Attr Loss: 7.4718 Acc: 0.8946
attribute accuracies
[0.81173444 0.73342316 0.76563776 0.89310795 0.46468235 0.36693614
 0.87800098 0.65874571 0.94790136 0.69945288 0.97248081 0.66842234]
val Loss: 0.5102 Attr Loss: 7.6156 Acc: 0.8647
attribute accuracies
[0.79266667 0.728      0.73866667 0.87933333 0.44066667 0.336
 0.85533333 0.636      0.92733333 0.674      0.95266667 0.62133333]
Epoch 20/69
----------
train Loss: 0.4221 Attr Loss: 7.4700 Acc: 0.8968
attribute accuracies
[0.81193859 0.73338233 0.76580108 0.89318961 0.46496815 0.36734444
 0.87783766 0.6632778  0.9481055  0.69826882 0.97256247 0.67054548]
val Loss: 0.4795 Attr Loss: 7.6127 Acc: 0.8707
attribute accuracies
[0.79133333 0.72733333 0.74       0.87466667 0.45466667 0.34266667
 0.85466667 0.64533333 0.92666667 0.66333333 0.95466667 0.62333333]
Epoch 21/69
----------
train Loss: 0.4290 Attr Loss: 7.4644 Acc: 0.8958
attribute accuracies
[0.8118161  0.73370897 0.7655561  0.89314878 0.46566226 0.3696309
 0.87787849 0.66066471 0.94790136 0.70145354 0.97243998 0.67140291]
val Loss: 0.4755 Attr Loss: 7.6079 Acc: 0.8700
attribute accuracies
[0.79       0.728      0.74       0.874      0.44866667 0.34133333
 0.85333333 0.64266667 0.92533333 0.67466667 0.95333333 0.632     ]
Epoch 22/69
----------
train Loss: 0.4391 Attr Loss: 7.4639 Acc: 0.8932
attribute accuracies
[0.81197942 0.73342316 0.76563776 0.89306712 0.46762208 0.37101911
 0.87783766 0.66103217 0.94790136 0.70202515 0.97243998 0.67279112]
val Loss: 0.5057 Attr Loss: 7.6259 Acc: 0.8707
attribute accuracies
[0.78933333 0.73066667 0.73866667 0.876      0.43666667 0.342
 0.852      0.63133333 0.926      0.66933333 0.954      0.622     ]
Epoch 23/69
----------
train Loss: 0.4192 Attr Loss: 7.4512 Acc: 0.8985
attribute accuracies
[0.81177527 0.73289237 0.76567859 0.89310795 0.46733627 0.37310142
 0.87779683 0.66213457 0.94790136 0.70374    0.97248081 0.67401601]
val Loss: 0.4382 Attr Loss: 7.6033 Acc: 0.8747
attribute accuracies
[0.79       0.73266667 0.738      0.87533333 0.44733333 0.33933333
 0.85333333 0.64466667 0.926      0.68333333 0.95266667 0.622     ]
Epoch 24/69
----------
train Loss: 0.4106 Attr Loss: 7.4367 Acc: 0.9020
attribute accuracies
[0.81226523 0.73317818 0.76563776 0.89318961 0.46933693 0.37387718
 0.87791932 0.65956231 0.94786053 0.70806794 0.97243998 0.67368937]
val Loss: 0.4670 Attr Loss: 7.5975 Acc: 0.8733
attribute accuracies
[0.78933333 0.73       0.73933333 0.87466667 0.44933333 0.32933333
 0.85333333 0.64       0.926      0.67533333 0.95333333 0.62933333]
Epoch 25/69
----------
train Loss: 0.3955 Attr Loss: 7.4351 Acc: 0.9058
attribute accuracies
[0.81226523 0.73346399 0.76571942 0.8933121  0.4715009  0.377756
 0.87783766 0.66201209 0.9478197  0.70876204 0.97243998 0.67560836]
val Loss: 0.4536 Attr Loss: 7.5732 Acc: 0.8760
attribute accuracies
[0.79266667 0.73       0.73933333 0.87733333 0.44266667 0.32133333
 0.85533333 0.64866667 0.926      0.67533333 0.95333333 0.63133333]
Epoch 26/69
----------
train Loss: 0.3908 Attr Loss: 7.4120 Acc: 0.9056
attribute accuracies
[0.81279602 0.73354565 0.76584191 0.89306712 0.47182754 0.377756
 0.87779683 0.66515597 0.9481055  0.70986445 0.97243998 0.68063041]
val Loss: 0.4166 Attr Loss: 7.5769 Acc: 0.8887
attribute accuracies
[0.79       0.73       0.738      0.87666667 0.45133333 0.34666667
 0.85333333 0.64066667 0.92866667 0.68333333 0.95333333 0.624     ]
Epoch 27/69
----------
train Loss: 0.3644 Attr Loss: 7.4044 Acc: 0.9121
attribute accuracies
[0.81267353 0.73346399 0.76616854 0.89306712 0.4743998  0.37877674
 0.87779683 0.66813653 0.94786053 0.7129675  0.97256247 0.67977299]
val Loss: 0.4467 Attr Loss: 7.5873 Acc: 0.8793
attribute accuracies
[0.79066667 0.73133333 0.73866667 0.87533333 0.44666667 0.34
 0.85266667 0.658      0.92666667 0.674      0.95266667 0.62866667]
Epoch 28/69
----------
train Loss: 0.3697 Attr Loss: 7.3884 Acc: 0.9133
attribute accuracies
[0.81275519 0.7340356  0.76616854 0.89314878 0.47640046 0.37861342
 0.87791932 0.67095378 0.94794219 0.71243671 0.97252164 0.68246774]
val Loss: 0.4442 Attr Loss: 7.5775 Acc: 0.8813
attribute accuracies
[0.79333333 0.72866667 0.74       0.87466667 0.45666667 0.35466667
 0.852      0.642      0.92733333 0.678      0.95266667 0.63133333]
Epoch 29/69
----------
train Loss: 0.3999 Attr Loss: 7.3821 Acc: 0.9038
attribute accuracies
[0.81279602 0.73456639 0.76604606 0.89302629 0.47533889 0.38171648
 0.87791932 0.67303609 0.94790136 0.7144782  0.97243998 0.68291687]
val Loss: 0.4288 Attr Loss: 7.5486 Acc: 0.8887
attribute accuracies
[0.79       0.72933333 0.73866667 0.876      0.44666667 0.33933333
 0.854      0.65133333 0.928      0.67866667 0.95266667 0.628     ]
Epoch 30/69
----------
train Loss: 0.3759 Attr Loss: 7.3678 Acc: 0.9104
attribute accuracies
[0.8133268  0.73521966 0.76645435 0.89302629 0.47950351 0.38567696
 0.87787849 0.66997387 0.94794219 0.71852033 0.97243998 0.68312102]
val Loss: 0.5046 Attr Loss: 7.5895 Acc: 0.8667
attribute accuracies
[0.79133333 0.72933333 0.74066667 0.87533333 0.44666667 0.34933333
 0.85266667 0.64266667 0.926      0.69       0.95266667 0.64      ]
Epoch 31/69
----------
train Loss: 0.3947 Attr Loss: 7.3741 Acc: 0.9054
attribute accuracies
[0.81344929 0.735138   0.7662502  0.89323044 0.47770701 0.38318635
 0.87779683 0.67303609 0.94794219 0.71692798 0.97243998 0.68161032]
val Loss: 0.5029 Attr Loss: 7.6005 Acc: 0.8727
attribute accuracies
[0.79       0.73266667 0.74533333 0.87333333 0.45066667 0.33866667
 0.854      0.65133333 0.926      0.672      0.954      0.632     ]
Epoch 32/69
----------
train Loss: 0.3630 Attr Loss: 7.3551 Acc: 0.9143
attribute accuracies
[0.81316348 0.73546464 0.76653601 0.89306712 0.47876858 0.38653438
 0.87796015 0.67368937 0.94794219 0.72060265 0.97256247 0.68834722]
val Loss: 0.3932 Attr Loss: 7.5214 Acc: 0.8893
attribute accuracies
[0.79266667 0.73066667 0.73866667 0.874      0.446      0.34133333
 0.85466667 0.64933333 0.92666667 0.68866667 0.95266667 0.64533333]
Epoch 33/69
----------
train Loss: 0.3884 Attr Loss: 7.3473 Acc: 0.9067
attribute accuracies
[0.81344929 0.73742447 0.76645435 0.89314878 0.48138168 0.39249551
 0.87787849 0.67495509 0.94786053 0.7184795  0.97248081 0.68495835]
val Loss: 0.5227 Attr Loss: 7.5615 Acc: 0.8553
attribute accuracies
[0.792      0.73266667 0.738      0.87533333 0.44933333 0.34266667
 0.85533333 0.658      0.92666667 0.682      0.95266667 0.64      ]
Epoch 34/69
----------
train Loss: 0.3759 Attr Loss: 7.3274 Acc: 0.9088
attribute accuracies
[0.81385759 0.73640372 0.7662502  0.89310795 0.48154499 0.39245468
 0.87779683 0.67471011 0.94798301 0.71970439 0.97243998 0.69079699]
val Loss: 0.4966 Attr Loss: 7.5480 Acc: 0.8720
attribute accuracies
[0.78933333 0.73266667 0.73666667 0.87533333 0.458      0.34866667
 0.85333333 0.63466667 0.926      0.692      0.954      0.642     ]
Epoch 35/69
----------
train Loss: 0.1842 Attr Loss: 7.2121 Acc: 0.9596
attribute accuracies
[0.81500082 0.73668953 0.76604606 0.89318961 0.48975176 0.40449943
 0.87783766 0.68177364 0.94786053 0.73187163 0.97248081 0.70949698]
val Loss: 0.2066 Attr Loss: 7.4126 Acc: 0.9367
attribute accuracies
[0.792      0.732      0.73733333 0.87533333 0.46533333 0.37133333
 0.85266667 0.652      0.92533333 0.69333333 0.95333333 0.66133333]
Epoch 36/69
----------
train Loss: 0.1182 Attr Loss: 7.1297 Acc: 0.9780
attribute accuracies
[0.81532745 0.73840438 0.76661767 0.89314878 0.49701943 0.41393108
 0.87791932 0.6899804  0.9478197  0.74113996 0.97243998 0.71374326]
val Loss: 0.1665 Attr Loss: 7.3773 Acc: 0.9467
attribute accuracies
[0.79466667 0.73466667 0.738      0.87666667 0.46       0.372
 0.852      0.65733333 0.92733333 0.70133333 0.95266667 0.664     ]
Epoch 37/69
----------
train Loss: 0.1038 Attr Loss: 7.0810 Acc: 0.9810
attribute accuracies
[0.81724645 0.73979259 0.76763841 0.89323044 0.50338886 0.41854483
 0.87783766 0.6974114  0.94786053 0.74420219 0.97248081 0.72035767]
val Loss: 0.1740 Attr Loss: 7.3494 Acc: 0.9473
attribute accuracies
[0.79266667 0.73266667 0.74       0.87466667 0.46533333 0.372
 0.85333333 0.65933333 0.92666667 0.70066667 0.95266667 0.658     ]
Epoch 38/69
----------
train Loss: 0.0921 Attr Loss: 7.0417 Acc: 0.9850
attribute accuracies
[0.8188388  0.74069084 0.76825086 0.89318961 0.50783929 0.42164789
 0.87783766 0.7007186  0.94790136 0.7477952  0.97243998 0.72460395]
val Loss: 0.1700 Attr Loss: 7.3290 Acc: 0.9480
attribute accuracies
[0.79333333 0.734      0.738      0.87466667 0.46466667 0.37333333
 0.85266667 0.65866667 0.92666667 0.70133333 0.95266667 0.65933333]
Epoch 39/69
----------
train Loss: 0.0900 Attr Loss: 7.0104 Acc: 0.9844
attribute accuracies
[0.81838968 0.74232402 0.76800588 0.89302629 0.51200392 0.42242365
 0.87800098 0.70365834 0.94786053 0.75032664 0.97243998 0.72611465]
val Loss: 0.1639 Attr Loss: 7.2908 Acc: 0.9513
attribute accuracies
[0.79533333 0.73133333 0.742      0.87533333 0.468      0.378
 0.854      0.66666667 0.926      0.704      0.95266667 0.65533333]
Epoch 40/69
----------
train Loss: 0.0836 Attr Loss: 6.9902 Acc: 0.9869
attribute accuracies
[0.81916544 0.74444717 0.7692716  0.89306712 0.51302466 0.42520007
 0.87787849 0.70851707 0.94802384 0.75081659 0.97248081 0.72619631]
val Loss: 0.1479 Attr Loss: 7.2742 Acc: 0.9507
attribute accuracies
[0.794      0.73333333 0.74333333 0.87533333 0.46933333 0.38466667
 0.852      0.67666667 0.92733333 0.69933333 0.95333333 0.66133333]
Epoch 41/69
----------
train Loss: 0.0854 Attr Loss: 6.9584 Acc: 0.9877
attribute accuracies
[0.81936959 0.74481463 0.76980238 0.89314878 0.5214764  0.4274457
 0.87791932 0.70896619 0.94790136 0.75489956 0.97248081 0.72913604]
val Loss: 0.1625 Attr Loss: 7.2520 Acc: 0.9507
attribute accuracies
[0.79533333 0.73733333 0.74133333 0.874      0.46933333 0.38266667
 0.85266667 0.674      0.926      0.70533333 0.95533333 0.66733333]
Epoch 42/69
----------
train Loss: 0.0859 Attr Loss: 6.9318 Acc: 0.9871
attribute accuracies
[0.82059448 0.74710109 0.76980238 0.89310795 0.51972073 0.42875225
 0.87787849 0.7107627  0.94786053 0.75575698 0.97252164 0.73305569]
val Loss: 0.1646 Attr Loss: 7.2253 Acc: 0.9513
attribute accuracies
[0.794      0.73666667 0.74133333 0.87466667 0.47066667 0.38466667
 0.85266667 0.664      0.92866667 0.70666667 0.95333333 0.668     ]
Epoch 43/69
----------
train Loss: 0.0856 Attr Loss: 6.9059 Acc: 0.9882
attribute accuracies
[0.82149273 0.74767271 0.77110893 0.89318961 0.5251919  0.43459089
 0.87791932 0.71157929 0.94790136 0.76077903 0.97243998 0.73252491]
val Loss: 0.1621 Attr Loss: 7.2239 Acc: 0.9527
attribute accuracies
[0.798      0.73933333 0.73866667 0.87666667 0.47066667 0.38533333
 0.856      0.66733333 0.92733333 0.708      0.95266667 0.66333333]
Epoch 44/69
----------
train Loss: 0.0818 Attr Loss: 6.8875 Acc: 0.9889
attribute accuracies
[0.82243181 0.74967336 0.77074147 0.89306712 0.52653928 0.43622407
 0.87779683 0.71562143 0.94790136 0.75857423 0.97243998 0.73734281]
val Loss: 0.1637 Attr Loss: 7.2205 Acc: 0.9547
attribute accuracies
[0.79933333 0.73733333 0.74       0.87333333 0.47066667 0.388
 0.85466667 0.67066667 0.926      0.71666667 0.95266667 0.668     ]
Epoch 45/69
----------
train Loss: 0.0825 Attr Loss: 6.8682 Acc: 0.9898
attribute accuracies
[0.82353422 0.74934673 0.7714764  0.89314878 0.53029561 0.43618324
 0.87779683 0.71513147 0.94802384 0.75975829 0.97248081 0.73636289]
val Loss: 0.1718 Attr Loss: 7.1871 Acc: 0.9527
attribute accuracies
[0.80133333 0.73666667 0.742      0.87733333 0.472      0.39066667
 0.85266667 0.68133333 0.926      0.71666667 0.95266667 0.67      ]
Epoch 46/69
----------
train Loss: 0.0834 Attr Loss: 6.8434 Acc: 0.9904
attribute accuracies
[0.82349339 0.75257227 0.77208885 0.89306712 0.53168382 0.43744896
 0.87783766 0.71909195 0.94790136 0.76302466 0.97252164 0.73852687]
val Loss: 0.1736 Attr Loss: 7.1783 Acc: 0.9547
attribute accuracies
[0.804      0.73733333 0.74333333 0.87666667 0.47866667 0.38466667
 0.854      0.68333333 0.92533333 0.70933333 0.95266667 0.678     ]
Epoch 47/69
----------
train Loss: 0.0809 Attr Loss: 6.8211 Acc: 0.9901
attribute accuracies
[0.8251674  0.75383799 0.77237465 0.89318961 0.5344194  0.44194023
 0.87787849 0.71937776 0.94794219 0.76482117 0.97243998 0.74130328]
val Loss: 0.1735 Attr Loss: 7.1668 Acc: 0.9547
attribute accuracies
[0.80066667 0.74       0.74133333 0.876      0.478      0.39133333
 0.85266667 0.688      0.92733333 0.71333333 0.95266667 0.67466667]
Epoch 48/69
----------
train Loss: 0.0819 Attr Loss: 6.8032 Acc: 0.9903
attribute accuracies
[0.82618814 0.75506288 0.77380369 0.89310795 0.53327617 0.44324677
 0.87787849 0.72423649 0.94786053 0.76841418 0.9726033  0.74346725]
val Loss: 0.1698 Attr Loss: 7.1430 Acc: 0.9560
attribute accuracies
[0.8        0.738      0.74533333 0.876      0.492      0.39933333
 0.854      0.67933333 0.92666667 0.71666667 0.95333333 0.676     ]
Epoch 49/69
----------
train Loss: 0.0812 Attr Loss: 6.7826 Acc: 0.9907
attribute accuracies
[0.82647395 0.75485873 0.7762943  0.89310795 0.53478687 0.44406337
 0.87779683 0.7226033  0.94790136 0.76992487 0.97243998 0.7436714 ]
val Loss: 0.1754 Attr Loss: 7.1250 Acc: 0.9553
attribute accuracies
[0.80133333 0.73733333 0.742      0.876      0.49066667 0.39133333
 0.85466667 0.68666667 0.92666667 0.718      0.95266667 0.682     ]
Epoch 50/69
----------
train Loss: 0.0831 Attr Loss: 6.7603 Acc: 0.9909
attribute accuracies
[0.82782133 0.75710436 0.77694757 0.89306712 0.5392373  0.44500245
 0.87787849 0.72607382 0.94794219 0.77033317 0.97248081 0.74309979]
val Loss: 0.1725 Attr Loss: 7.1044 Acc: 0.9540
attribute accuracies
[0.80466667 0.74333333 0.74133333 0.87666667 0.482      0.40933333
 0.85533333 0.68466667 0.926      0.71733333 0.954      0.676     ]
Epoch 51/69
----------
train Loss: 0.0807 Attr Loss: 6.7359 Acc: 0.9913
attribute accuracies
[0.83006696 0.75718602 0.777805   0.89318961 0.54168708 0.44941205
 0.877756   0.72697207 0.94802384 0.77241548 0.97248081 0.74424302]
val Loss: 0.1799 Attr Loss: 7.0831 Acc: 0.9527
attribute accuracies
[0.80133333 0.74       0.74266667 0.87466667 0.49       0.40533333
 0.85466667 0.68133333 0.92666667 0.718      0.95466667 0.68466667]
Epoch 52/69
----------
train Loss: 0.0816 Attr Loss: 6.7195 Acc: 0.9911
attribute accuracies
[0.82908705 0.76081986 0.777805   0.89294463 0.5425445  0.44957537
 0.87787849 0.72868692 0.94790136 0.77225216 0.97248081 0.74918341]
val Loss: 0.1757 Attr Loss: 7.0834 Acc: 0.9560
attribute accuracies
[0.80066667 0.742      0.74266667 0.876      0.488      0.40133333
 0.85266667 0.686      0.92666667 0.71866667 0.95266667 0.68333333]
Epoch 53/69
----------
train Loss: 0.0803 Attr Loss: 6.6921 Acc: 0.9911
attribute accuracies
[0.83010779 0.76065654 0.77907072 0.89302629 0.5455659  0.45337253
 0.87783766 0.72897273 0.94798301 0.77384452 0.97252164 0.75293974]
val Loss: 0.1820 Attr Loss: 7.0783 Acc: 0.9553
attribute accuracies
[0.80333333 0.74066667 0.74666667 0.87333333 0.49866667 0.39733333
 0.85533333 0.684      0.92733333 0.71733333 0.95333333 0.682     ]
Epoch 54/69
----------
train Loss: 0.0827 Attr Loss: 6.6775 Acc: 0.9924
attribute accuracies
[0.83137351 0.76298383 0.78009146 0.89327127 0.54723992 0.45463825
 0.87791932 0.7292177  0.9478197  0.77711089 0.97248081 0.74955087]
val Loss: 0.1878 Attr Loss: 7.0543 Acc: 0.9513
attribute accuracies
[0.80133333 0.74666667 0.746      0.87533333 0.49533333 0.40266667
 0.856      0.69733333 0.92666667 0.72333333 0.954      0.678     ]
Epoch 55/69
----------
train Loss: 0.0841 Attr Loss: 6.6620 Acc: 0.9916
attribute accuracies
[0.83014862 0.76298383 0.78205128 0.89323044 0.54960804 0.45794545
 0.87779683 0.72905439 0.94790136 0.77829495 0.97248081 0.75289891]
val Loss: 0.1839 Attr Loss: 7.0404 Acc: 0.9533
attribute accuracies
[0.804      0.75066667 0.744      0.87533333 0.506      0.4
 0.854      0.68666667 0.926      0.72133333 0.95266667 0.68666667]
Epoch 56/69
----------
train Loss: 0.0816 Attr Loss: 6.6433 Acc: 0.9920
attribute accuracies
[0.83161849 0.76584191 0.78425608 0.89310795 0.54903642 0.45447493
 0.87779683 0.73142251 0.94794219 0.7804181  0.97248081 0.75669606]
val Loss: 0.1759 Attr Loss: 7.0215 Acc: 0.9527
attribute accuracies
[0.80733333 0.74466667 0.74333333 0.87666667 0.50733333 0.40733333
 0.852      0.694      0.92533333 0.72733333 0.95266667 0.69133333]
Epoch 57/69
----------
train Loss: 0.0814 Attr Loss: 6.6152 Acc: 0.9923
attribute accuracies
[0.83361914 0.76637269 0.78392945 0.89302629 0.5529969  0.46419239
 0.87787849 0.73395394 0.94786053 0.77964233 0.97248081 0.757431  ]
val Loss: 0.1853 Attr Loss: 7.0151 Acc: 0.9527
attribute accuracies
[0.80133333 0.74733333 0.74333333 0.874      0.50466667 0.41666667
 0.85266667 0.69       0.926      0.72466667 0.95333333 0.68466667]
Epoch 58/69
----------
train Loss: 0.0813 Attr Loss: 6.5994 Acc: 0.9931
attribute accuracies
[0.83304753 0.76780173 0.78535848 0.89318961 0.55454842 0.46243671
 0.877756   0.73379063 0.94790136 0.78090805 0.97243998 0.75947248]
val Loss: 0.1830 Attr Loss: 6.9929 Acc: 0.9520
attribute accuracies
[0.802      0.74933333 0.74666667 0.87533333 0.50666667 0.41066667
 0.852      0.68533333 0.928      0.722      0.95266667 0.68933333]
Epoch 59/69
----------
train Loss: 0.0814 Attr Loss: 6.5768 Acc: 0.9918
attribute accuracies
[0.83472154 0.76984321 0.78580761 0.89306712 0.55785563 0.46386575
 0.87804181 0.7377511  0.94790136 0.78539931 0.97243998 0.76277968]
val Loss: 0.1835 Attr Loss: 6.9686 Acc: 0.9520
attribute accuracies
[0.80266667 0.748      0.74933333 0.876      0.50133333 0.41
 0.854      0.68066667 0.92666667 0.732      0.95466667 0.69466667]
Epoch 60/69
----------
train Loss: 0.0810 Attr Loss: 6.5641 Acc: 0.9934
attribute accuracies
[0.83602809 0.76963907 0.7870325  0.89306712 0.55903969 0.46435571
 0.87787849 0.73668953 0.94786053 0.78682835 0.97256247 0.76057488]
val Loss: 0.1828 Attr Loss: 6.9719 Acc: 0.9520
attribute accuracies
[0.80266667 0.74866667 0.74666667 0.876      0.50333333 0.41866667
 0.85333333 0.68933333 0.92533333 0.72733333 0.954      0.69      ]
Epoch 61/69
----------
train Loss: 0.0811 Attr Loss: 6.5388 Acc: 0.9929
attribute accuracies
[0.8363139  0.77527356 0.79082966 0.89302629 0.56202025 0.46786706
 0.87779683 0.74171158 0.94798301 0.78760412 0.97243998 0.76437204]
val Loss: 0.1856 Attr Loss: 6.9421 Acc: 0.9520
attribute accuracies
[0.806      0.746      0.75333333 0.87666667 0.50133333 0.42133333
 0.854      0.69533333 0.926      0.726      0.95333333 0.69666667]
Epoch 62/69
----------
train Loss: 0.0816 Attr Loss: 6.5293 Acc: 0.9926
attribute accuracies
[0.8363139  0.77457945 0.78903315 0.89302629 0.56189776 0.46656051
 0.87779683 0.73881267 0.94790136 0.78944145 0.97243998 0.76384125]
val Loss: 0.1931 Attr Loss: 6.9278 Acc: 0.9507
attribute accuracies
[0.806      0.74733333 0.754      0.876      0.504      0.42133333
 0.85266667 0.68933333 0.92866667 0.726      0.95333333 0.69933333]
Epoch 63/69
----------
train Loss: 0.0807 Attr Loss: 6.4983 Acc: 0.9931
attribute accuracies
[0.83680385 0.77547771 0.7918504  0.89302629 0.56381676 0.47133758
 0.87787849 0.74269149 0.94790136 0.78952311 0.97252164 0.76563776]
val Loss: 0.1865 Attr Loss: 6.9290 Acc: 0.9527
attribute accuracies
[0.80666667 0.75466667 0.75533333 0.874      0.50933333 0.41333333
 0.85333333 0.68866667 0.926      0.73666667 0.954      0.70133333]
Epoch 64/69
----------
train Loss: 0.0816 Attr Loss: 6.4756 Acc: 0.9929
attribute accuracies
[0.83909032 0.77768251 0.79519843 0.89310795 0.56622571 0.47419566
 0.87800098 0.74469214 0.94790136 0.79311612 0.97252164 0.76923077]
val Loss: 0.1908 Attr Loss: 6.9261 Acc: 0.9507
attribute accuracies
[0.80533333 0.75066667 0.752      0.876      0.50533333 0.416
 0.85333333 0.7        0.92533333 0.73333333 0.95333333 0.69866667]
Epoch 65/69
----------
train Loss: 0.0804 Attr Loss: 6.4538 Acc: 0.9932
attribute accuracies
[0.83937612 0.77804998 0.79581088 0.89318961 0.56838968 0.4748081
 0.87804181 0.74456966 0.9478197  0.79266699 0.97248081 0.77229299]
val Loss: 0.1794 Attr Loss: 6.8902 Acc: 0.9507
attribute accuracies
[0.80866667 0.754      0.75133333 0.87466667 0.518      0.41466667
 0.85533333 0.698      0.92666667 0.73066667 0.95266667 0.70133333]
Epoch 66/69
----------
train Loss: 0.0823 Attr Loss: 6.4476 Acc: 0.9924
attribute accuracies
[0.83896783 0.77964233 0.79703577 0.89314878 0.56981872 0.47472644
 0.87787849 0.74697861 0.94786053 0.79242202 0.97248081 0.77131308]
val Loss: 0.1884 Attr Loss: 6.8957 Acc: 0.9527
attribute accuracies
[0.80866667 0.76       0.758      0.874      0.514      0.41666667
 0.852      0.70066667 0.92533333 0.73066667 0.95266667 0.70066667]
Epoch 67/69
----------
train Loss: 0.0828 Attr Loss: 6.4222 Acc: 0.9929
attribute accuracies
[0.84117263 0.78123469 0.79956721 0.89302629 0.57243181 0.47934019
 0.87800098 0.74644782 0.94786053 0.79393271 0.97248081 0.7744978 ]
val Loss: 0.1843 Attr Loss: 6.8751 Acc: 0.9513
attribute accuracies
[0.80933333 0.75466667 0.75866667 0.876      0.514      0.416
 0.85333333 0.7        0.92533333 0.73666667 0.95266667 0.70466667]
Epoch 68/69
----------
train Loss: 0.0800 Attr Loss: 6.4063 Acc: 0.9933
attribute accuracies
[0.84080516 0.78274539 0.80075127 0.89318961 0.5751674  0.47615548
 0.87783766 0.74975502 0.94790136 0.79507594 0.97248081 0.77168055]
val Loss: 0.1869 Attr Loss: 6.8633 Acc: 0.9540
attribute accuracies
[0.80666667 0.76066667 0.758      0.87466667 0.514      0.416
 0.85466667 0.7        0.92533333 0.73333333 0.95333333 0.70266667]
Epoch 69/69
----------
train Loss: 0.0784 Attr Loss: 6.3773 Acc: 0.9942
attribute accuracies
[0.84166258 0.78478687 0.79948555 0.89327127 0.58023028 0.48048342
 0.87791932 0.7522048  0.94798301 0.79977135 0.97248081 0.77576351]
val Loss: 0.1847 Attr Loss: 6.8550 Acc: 0.9520
attribute accuracies
[0.808      0.758      0.756      0.87466667 0.51266667 0.42466667
 0.85333333 0.69066667 0.926      0.73933333 0.95266667 0.70866667]
Training complete in 139m 22s
