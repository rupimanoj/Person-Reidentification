attribute_data.npy
Attributes verification.ipynb
collect_results.py
demo.py
dense_attr_color_erasing_70e.txt
dense_attr_color_erasing.txt
dense_attr_color.txt
dense_attr_no_color.txt
dense_attr.txt
downcolor.npy
Ensembling experimentation.ipynb
erasing_data_augmentation_checking.ipynb
evaluate_gpu.py
evaluate_int.py
evaluate.py
evaluate_rerank.py
extract.py
extract_tta.py
feeze_learning.ipynb
image_net_erasing.txt
image_net_erasing_wde3.txt
image_net_freeze.txt
image_net_wde3.txt
image_net_wde5.txt
labels.npy
LICENSE
mkt_0.4g_freeze.txt
model
model.py
my.png
output_pcb_attr.txt
output_sat_color.txt
output_sat_erasing.txt
output_sat.txt
prepare.py
prepare_static.py
__pycache__
random_erasing.py
README.md
re_ranking.py
results_collection.ipynb
show.png
test.py
train_attr_dl.py
train_attr.py
train.jpg
train_pcb_attr.py
train_pcb_attr_resnet.py
train.py
tta_expermimenation.ipynb
tutorial
untitled
upcolor.npy
net output size:
torch.Size([8, 1024])
0
[ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0), Resize(size=(288, 144), interpolation=PIL.Image.BICUBIC), RandomCrop(size=(256, 128), padding=0), RandomHorizontalFlip(p=0.5), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), <random_erasing.RandomErasing object at 0x7fac5f66a7f0>]
/opt/anaconda3/lib/python3.7/site-packages/torchvision-0.2.1-py3.7.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:14: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
  init.kaiming_normal(m.weight.data, a=0, mode='fan_out')
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:15: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(m.bias.data, 0.0)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:17: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.
  init.normal(m.weight.data, 1.0, 0.02)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:18: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(m.bias.data, 0.0)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:23: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.
  init.normal(m.weight.data, std=0.001)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:24: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(m.bias.data, 0.0)
0.6468305587768555
attr_data.shape
torch.Size([1501, 12])
ft_attr_net_dense(
  (model): DenseNet(
    (features): Sequential(
      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu0): ReLU(inplace)
      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (denseblock1): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (transition1): _Transition(
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
      (denseblock2): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer7): _DenseLayer(
          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer8): _DenseLayer(
          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer9): _DenseLayer(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer10): _DenseLayer(
          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer11): _DenseLayer(
          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer12): _DenseLayer(
          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (transition2): _Transition(
        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
      (denseblock3): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer7): _DenseLayer(
          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer8): _DenseLayer(
          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer9): _DenseLayer(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer10): _DenseLayer(
          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer11): _DenseLayer(
          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer12): _DenseLayer(
          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer13): _DenseLayer(
          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer14): _DenseLayer(
          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer15): _DenseLayer(
          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer16): _DenseLayer(
          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer17): _DenseLayer(
          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer18): _DenseLayer(
          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer19): _DenseLayer(
          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer20): _DenseLayer(
          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer21): _DenseLayer(
          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer22): _DenseLayer(
          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer23): _DenseLayer(
          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer24): _DenseLayer(
          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (transition3): _Transition(
        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
      (denseblock4): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer7): _DenseLayer(
          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer8): _DenseLayer(
          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer9): _DenseLayer(
          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer10): _DenseLayer(
          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer11): _DenseLayer(
          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer12): _DenseLayer(
          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer13): _DenseLayer(
          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer14): _DenseLayer(
          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer15): _DenseLayer(
          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer16): _DenseLayer(
          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Linear(in_features=1024, out_features=1000, bias=True)
    (fc): Sequential()
  )
  (classifier): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=1500, bias=True)
    )
  )
  (classifierage): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=4, bias=True)
    )
  )
  (classifierbackpack): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierbag): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierhandbag): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierdowncolor): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=9, bias=True)
    )
  )
  (classifierupcolor): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=8, bias=True)
    )
  )
  (classifierclothes): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierdown): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierup): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierhair): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierhat): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifiergender): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
)
Epoch 0/69
----------
train Loss: 6.2473 Attr Loss: 8.2441 Acc: 0.0477
attribute accuracies
[0.81055038 0.73187163 0.76490283 0.89241385 0.43671403 0.28739997
 0.87779683 0.62938919 0.94704393 0.65552017 0.97064348 0.56251021]
val Loss: 5.4578 Attr Loss: 8.0857 Acc: 0.0780
attribute accuracies
[0.79133333 0.73133333 0.73866667 0.87333333 0.426      0.28333333
 0.85133333 0.618      0.92666667 0.642      0.95333333 0.552     ]
Epoch 1/69
----------
train Loss: 4.8705 Attr Loss: 8.1453 Acc: 0.1305
attribute accuracies
[0.81189776 0.73256574 0.76576025 0.89314878 0.43802058 0.28935979
 0.87800098 0.6318798  0.94794219 0.65588764 0.97252164 0.56316348]
val Loss: 4.6231 Attr Loss: 8.0804 Acc: 0.1473
attribute accuracies
[0.78933333 0.72733333 0.74       0.87466667 0.422      0.28866667
 0.85333333 0.61533333 0.92666667 0.63866667 0.95333333 0.55666667]
Epoch 2/69
----------
train Loss: 4.3164 Attr Loss: 8.1294 Acc: 0.1790
attribute accuracies
[0.81202025 0.73285154 0.76559693 0.89298546 0.43810224 0.28784909
 0.87783766 0.63245141 0.9478197  0.65621427 0.97243998 0.56691981]
val Loss: 4.1955 Attr Loss: 8.0663 Acc: 0.1893
attribute accuracies
[0.79066667 0.72733333 0.74266667 0.87333333 0.42733333 0.28466667
 0.85466667 0.62066667 0.926      0.64333333 0.95466667 0.55466667]
Epoch 3/69
----------
train Loss: 4.0500 Attr Loss: 8.1191 Acc: 0.2092
attribute accuracies
[0.8118161  0.73268822 0.7655561  0.89323044 0.4381839  0.29462682
 0.87787849 0.63314552 0.94794219 0.6566634  0.97243998 0.56941042]
val Loss: 3.9927 Attr Loss: 8.0574 Acc: 0.1927
attribute accuracies
[0.79133333 0.728      0.742      0.876      0.42733333 0.29133333
 0.856      0.61666667 0.926      0.64266667 0.95333333 0.552     ]
Epoch 4/69
----------
train Loss: 3.8688 Attr Loss: 8.1213 Acc: 0.2311
attribute accuracies
[0.81169361 0.73285154 0.76551527 0.89302629 0.43822473 0.2959742
 0.87791932 0.63302303 0.94794219 0.65674506 0.97252164 0.57043116]
val Loss: 3.8186 Attr Loss: 8.0745 Acc: 0.2260
attribute accuracies
[0.79       0.72866667 0.74       0.87466667 0.426      0.288
 0.854      0.618      0.92666667 0.64       0.954      0.55333333]
Epoch 5/69
----------
train Loss: 3.7527 Attr Loss: 8.1214 Acc: 0.2431
attribute accuracies
[0.81185693 0.7326474  0.76571942 0.89306712 0.43806141 0.29503511
 0.87800098 0.63285971 0.94790136 0.65658174 0.97248081 0.574065  ]
val Loss: 3.7055 Attr Loss: 8.0752 Acc: 0.2360
attribute accuracies
[0.79066667 0.72866667 0.736      0.87666667 0.42533333 0.29333333
 0.85466667 0.62133333 0.92866667 0.63933333 0.95266667 0.55      ]
Epoch 6/69
----------
train Loss: 3.6931 Attr Loss: 8.1302 Acc: 0.2493
attribute accuracies
[0.81169361 0.73260657 0.76547444 0.89314878 0.43793892 0.29552507
 0.87779683 0.63302303 0.94794219 0.65662257 0.97248081 0.5725543 ]
val Loss: 3.6697 Attr Loss: 8.0918 Acc: 0.2527
attribute accuracies
[0.792      0.73066667 0.73933333 0.87333333 0.42666667 0.28933333
 0.852      0.61866667 0.92533333 0.64066667 0.95333333 0.55      ]
Epoch 7/69
----------
train Loss: 3.6164 Attr Loss: 8.1388 Acc: 0.2620
attribute accuracies
[0.81189776 0.73260657 0.76563776 0.89302629 0.43806141 0.29728074
 0.87796015 0.63314552 0.9478197  0.65662257 0.97248081 0.57243181]
val Loss: 3.6308 Attr Loss: 8.0864 Acc: 0.2653
attribute accuracies
[0.78933333 0.728      0.738      0.87666667 0.43       0.28866667
 0.85333333 0.61666667 0.92733333 0.642      0.95266667 0.55333333]
Epoch 8/69
----------
train Loss: 3.5910 Attr Loss: 8.1480 Acc: 0.2654
attribute accuracies
[0.81202025 0.73260657 0.76543361 0.89310795 0.43806141 0.29503511
 0.87779683 0.63314552 0.94802384 0.65658174 0.97256247 0.57218684]
val Loss: 3.6121 Attr Loss: 8.1075 Acc: 0.2587
attribute accuracies
[0.79       0.73       0.73733333 0.87533333 0.42666667 0.28266667
 0.854      0.61733333 0.926      0.64133333 0.95333333 0.552     ]
Epoch 9/69
----------
train Loss: 3.5783 Attr Loss: 8.1573 Acc: 0.2683
attribute accuracies
[0.81206108 0.73256574 0.76567859 0.89314878 0.43822473 0.29417769
 0.87800098 0.63318635 0.9478197  0.65662257 0.97243998 0.57218684]
val Loss: 3.5856 Attr Loss: 8.1108 Acc: 0.2593
attribute accuracies
[0.79133333 0.72866667 0.74       0.87466667 0.42933333 0.28466667
 0.85333333 0.61866667 0.926      0.64       0.95266667 0.55133333]
Epoch 10/69
----------
train Loss: 2.3755 Attr Loss: 8.1349 Acc: 0.4515
attribute accuracies
[0.8118161  0.73248408 0.76559693 0.89314878 0.43814307 0.29458599
 0.87787849 0.63294137 0.94786053 0.65682672 0.97248081 0.57243181]
val Loss: 1.5870 Attr Loss: 8.0435 Acc: 0.5980
attribute accuracies
[0.79266667 0.72533333 0.738      0.87666667 0.42733333 0.28666667
 0.854      0.61933333 0.92666667 0.642      0.95333333 0.55333333]
Epoch 11/69
----------
train Loss: 1.3164 Attr Loss: 8.0749 Acc: 0.6674
attribute accuracies
[0.81173444 0.7326474  0.76551527 0.89318961 0.43822473 0.2984648
 0.87791932 0.63302303 0.94806467 0.65686755 0.97252164 0.57230933]
val Loss: 1.1029 Attr Loss: 8.0363 Acc: 0.7113
attribute accuracies
[0.79333333 0.72866667 0.73866667 0.876      0.426      0.28933333
 0.85266667 0.62       0.92533333 0.63933333 0.95266667 0.55      ]
Epoch 12/69
----------
train Loss: 0.9776 Attr Loss: 8.0245 Acc: 0.7487
attribute accuracies
[0.81185693 0.73268822 0.76547444 0.89323044 0.43814307 0.30242528
 0.87796015 0.63294137 0.94786053 0.65678589 0.97248081 0.57541238]
val Loss: 0.8770 Attr Loss: 8.0297 Acc: 0.7720
attribute accuracies
[0.78933333 0.732      0.738      0.874      0.42866667 0.29133333
 0.85333333 0.61733333 0.926      0.64       0.95333333 0.55266667]
Epoch 13/69
----------
train Loss: 0.8301 Attr Loss: 7.9812 Acc: 0.7825
attribute accuracies
[0.81177527 0.7326474  0.76551527 0.89310795 0.4381839  0.30687571
 0.87804181 0.63302303 0.94790136 0.65694921 0.97252164 0.58112853]
val Loss: 0.8038 Attr Loss: 7.9709 Acc: 0.7900
attribute accuracies
[0.79333333 0.72933333 0.738      0.87533333 0.426      0.29733333
 0.85333333 0.622      0.928      0.64       0.95266667 0.55866667]
Epoch 14/69
----------
train Loss: 0.7305 Attr Loss: 7.9419 Acc: 0.8112
attribute accuracies
[0.81189776 0.73260657 0.76559693 0.89318961 0.43797975 0.31716479
 0.87791932 0.63322718 0.94794219 0.65662257 0.97252164 0.59194839]
val Loss: 0.7174 Attr Loss: 7.9481 Acc: 0.8133
attribute accuracies
[0.79066667 0.726      0.73933333 0.87533333 0.426      0.302
 0.854      0.61666667 0.92666667 0.644      0.95266667 0.57066667]
Epoch 15/69
----------
train Loss: 0.6427 Attr Loss: 7.9070 Acc: 0.8356
attribute accuracies
[0.81193859 0.73252491 0.76563776 0.89310795 0.43802058 0.32333007
 0.87779683 0.63314552 0.94786053 0.65682672 0.97248081 0.60358484]
val Loss: 0.6140 Attr Loss: 7.9244 Acc: 0.8267
attribute accuracies
[0.79133333 0.728      0.74066667 0.87466667 0.42733333 0.31
 0.854      0.61866667 0.926      0.64066667 0.95266667 0.56666667]
Epoch 16/69
----------
train Loss: 0.6036 Attr Loss: 7.8696 Acc: 0.8465
attribute accuracies
[0.81210191 0.73281071 0.76539278 0.89318961 0.43797975 0.32724971
 0.87791932 0.63306386 0.94798301 0.65650008 0.97248081 0.60742283]
val Loss: 0.6184 Attr Loss: 7.8630 Acc: 0.8400
attribute accuracies
[0.79266667 0.72733333 0.73733333 0.87733333 0.42866667 0.32733333
 0.858      0.61666667 0.92666667 0.644      0.95466667 0.57      ]
Epoch 17/69
----------
train Loss: 0.5767 Attr Loss: 7.8396 Acc: 0.8540
attribute accuracies
[0.81173444 0.73260657 0.7655561  0.89302629 0.43822473 0.33378246
 0.87771517 0.63302303 0.94790136 0.6566634  0.97252164 0.61489466]
val Loss: 0.5435 Attr Loss: 7.8809 Acc: 0.8580
attribute accuracies
[0.792      0.726      0.74       0.87733333 0.428      0.314
 0.85266667 0.62066667 0.92666667 0.642      0.95466667 0.57533333]
Epoch 18/69
----------
train Loss: 0.5249 Attr Loss: 7.8145 Acc: 0.8716
attribute accuracies
[0.81189776 0.73256574 0.76547444 0.89306712 0.43838805 0.33419076
 0.87787849 0.6329822  0.94790136 0.6566634  0.97243998 0.61950841]
val Loss: 0.5290 Attr Loss: 7.8608 Acc: 0.8533
attribute accuracies
[0.792      0.72733333 0.73866667 0.87533333 0.42733333 0.31533333
 0.85133333 0.61933333 0.92666667 0.64       0.95266667 0.58866667]
Epoch 19/69
----------
train Loss: 0.5206 Attr Loss: 7.7942 Acc: 0.8709
attribute accuracies
[0.81169361 0.73260657 0.76563776 0.89318961 0.43957211 0.3392128
 0.87771517 0.6329822  0.94786053 0.65650008 0.97243998 0.62983831]
val Loss: 0.5411 Attr Loss: 7.8498 Acc: 0.8507
attribute accuracies
[0.792      0.73066667 0.73933333 0.87466667 0.42733333 0.32066667
 0.854      0.62133333 0.92733333 0.64       0.95266667 0.59533333]
Epoch 20/69
----------
train Loss: 0.4928 Attr Loss: 7.7718 Acc: 0.8783
attribute accuracies
[0.81193859 0.73260657 0.76584191 0.89298546 0.44063368 0.34141761
 0.87804181 0.63302303 0.94798301 0.65682672 0.97248081 0.63249224]
val Loss: 0.5124 Attr Loss: 7.8299 Acc: 0.8547
attribute accuracies
[0.792      0.72533333 0.73933333 0.876      0.43133333 0.31733333
 0.854      0.61733333 0.926      0.64266667 0.95266667 0.59866667]
Epoch 21/69
----------
train Loss: 0.4751 Attr Loss: 7.7550 Acc: 0.8809
attribute accuracies
[0.81189776 0.73268822 0.76551527 0.89306712 0.44194023 0.34599053
 0.87783766 0.63326801 0.94790136 0.6566634  0.97252164 0.63200229]
val Loss: 0.4810 Attr Loss: 7.8215 Acc: 0.8733
attribute accuracies
[0.78866667 0.73266667 0.738      0.87466667 0.42866667 0.32266667
 0.854      0.61866667 0.92733333 0.64533333 0.95333333 0.59066667]
Epoch 22/69
----------
train Loss: 0.4659 Attr Loss: 7.7396 Acc: 0.8854
attribute accuracies
[0.81189776 0.73268822 0.7655561  0.89318961 0.44434918 0.3474604
 0.87796015 0.63306386 0.94790136 0.65678589 0.97252164 0.63661604]
val Loss: 0.5181 Attr Loss: 7.8284 Acc: 0.8640
attribute accuracies
[0.79066667 0.732      0.738      0.876      0.43066667 0.32133333
 0.85266667 0.62066667 0.926      0.642      0.95266667 0.58933333]
Epoch 23/69
----------
train Loss: 0.4346 Attr Loss: 7.7215 Acc: 0.8946
attribute accuracies
[0.81185693 0.73276988 0.7655561  0.89318961 0.44373673 0.34648048
 0.87791932 0.6329822  0.94790136 0.65674506 0.97243998 0.63824922]
val Loss: 0.4715 Attr Loss: 7.8101 Acc: 0.8773
attribute accuracies
[0.788      0.73133333 0.74066667 0.874      0.43       0.314
 0.854      0.618      0.92666667 0.642      0.954      0.58866667]
Epoch 24/69
----------
train Loss: 0.4372 Attr Loss: 7.7041 Acc: 0.8946
attribute accuracies
[0.81185693 0.73256574 0.76535195 0.89318961 0.4474114  0.35431978
 0.87796015 0.63339049 0.9478197  0.6577658  0.97252164 0.64241385]
val Loss: 0.4455 Attr Loss: 7.7860 Acc: 0.8840
attribute accuracies
[0.78933333 0.728      0.74       0.87466667 0.43866667 0.32333333
 0.85333333 0.618      0.926      0.64066667 0.95266667 0.58666667]
Epoch 25/69
----------
train Loss: 0.4055 Attr Loss: 7.6874 Acc: 0.9034
attribute accuracies
[0.81161195 0.73260657 0.76543361 0.89306712 0.44896293 0.35227829
 0.87791932 0.63343132 0.94794219 0.65764331 0.97248081 0.64604769]
val Loss: 0.4788 Attr Loss: 7.7917 Acc: 0.8827
attribute accuracies
[0.78866667 0.73       0.738      0.876      0.434      0.314
 0.854      0.61933333 0.92533333 0.64266667 0.95333333 0.59066667]
Epoch 26/69
----------
train Loss: 0.4039 Attr Loss: 7.6655 Acc: 0.9065
attribute accuracies
[0.81177527 0.73281071 0.76531112 0.89310795 0.45084109 0.35117589
 0.87779683 0.63453373 0.94798301 0.66046056 0.9726033  0.64813   ]
val Loss: 0.5092 Attr Loss: 7.7660 Acc: 0.8647
attribute accuracies
[0.79333333 0.72933333 0.74       0.874      0.44       0.32666667
 0.854      0.61866667 0.92533333 0.64333333 0.95266667 0.61333333]
Epoch 27/69
----------
train Loss: 0.3907 Attr Loss: 7.6504 Acc: 0.9065
attribute accuracies
[0.81177527 0.7326474  0.76551527 0.89310795 0.45349502 0.35652458
 0.87779683 0.63510534 0.94794219 0.6625837  0.97248081 0.65164135]
val Loss: 0.4824 Attr Loss: 7.7583 Acc: 0.8780
attribute accuracies
[0.78933333 0.72733333 0.73933333 0.87533333 0.43733333 0.32133333
 0.85266667 0.62       0.926      0.64933333 0.95333333 0.61133333]
Epoch 28/69
----------
train Loss: 0.3933 Attr Loss: 7.6393 Acc: 0.9070
attribute accuracies
[0.81206108 0.73252491 0.76527029 0.89323044 0.45337253 0.35685122
 0.87771517 0.63620774 0.94790136 0.66617671 0.97243998 0.65572432]
val Loss: 0.4565 Attr Loss: 7.7386 Acc: 0.8880
attribute accuracies
[0.78933333 0.728      0.74133333 0.87466667 0.43866667 0.32133333
 0.854      0.62       0.92733333 0.64866667 0.95266667 0.608     ]
Epoch 29/69
----------
train Loss: 0.3721 Attr Loss: 7.6157 Acc: 0.9129
attribute accuracies
[0.81177527 0.73289237 0.76551527 0.89310795 0.45716969 0.35652458
 0.87791932 0.63943328 0.94802384 0.67123959 0.97248081 0.65727585]
val Loss: 0.4469 Attr Loss: 7.7361 Acc: 0.8807
attribute accuracies
[0.78733333 0.72733333 0.73933333 0.87533333 0.43933333 0.328
 0.852      0.622      0.92666667 0.652      0.95333333 0.60666667]
Epoch 30/69
----------
train Loss: 0.3632 Attr Loss: 7.5970 Acc: 0.9125
attribute accuracies
[0.81173444 0.7326474  0.76567859 0.89310795 0.45688388 0.36134248
 0.87804181 0.64163809 0.94786053 0.67597583 0.97252164 0.66270619]
val Loss: 0.4351 Attr Loss: 7.6958 Acc: 0.8767
attribute accuracies
[0.79       0.728      0.73933333 0.87533333 0.44533333 0.33066667
 0.852      0.626      0.92666667 0.66       0.95333333 0.61666667]
Epoch 31/69
----------
train Loss: 0.3712 Attr Loss: 7.5838 Acc: 0.9123
attribute accuracies
[0.8118161  0.73272905 0.76567859 0.89306712 0.46284501 0.35868855
 0.877756   0.64429201 0.9478197  0.68308019 0.97252164 0.6651968 ]
val Loss: 0.4659 Attr Loss: 7.7122 Acc: 0.8840
attribute accuracies
[0.78866667 0.72933333 0.74133333 0.87533333 0.43733333 0.31933333
 0.85266667 0.62666667 0.92733333 0.66466667 0.95266667 0.624     ]
Epoch 32/69
----------
train Loss: 0.3556 Attr Loss: 7.5663 Acc: 0.9185
attribute accuracies
[0.81197942 0.73260657 0.76531112 0.89323044 0.46480483 0.36044423
 0.87783766 0.65160052 0.94794219 0.68532582 0.97252164 0.66576841]
val Loss: 0.4362 Attr Loss: 7.7037 Acc: 0.8920
attribute accuracies
[0.78866667 0.72866667 0.73933333 0.874      0.44666667 0.32866667
 0.85466667 0.62866667 0.92666667 0.65933333 0.95266667 0.61866667]
Epoch 33/69
----------
train Loss: 0.3702 Attr Loss: 7.5554 Acc: 0.9130
attribute accuracies
[0.81169361 0.73268822 0.76551527 0.89306712 0.4655806  0.36101584
 0.87796015 0.65278458 0.94794219 0.688878   0.97248081 0.66846317]
val Loss: 0.4253 Attr Loss: 7.7145 Acc: 0.8833
attribute accuracies
[0.78933333 0.728      0.74       0.87466667 0.43933333 0.334
 0.85266667 0.62933333 0.92533333 0.66733333 0.95333333 0.60066667]
Epoch 34/69
----------
train Loss: 0.3587 Attr Loss: 7.5316 Acc: 0.9163
attribute accuracies
[0.81185693 0.73260657 0.7655561  0.89318961 0.46541728 0.3615058
 0.87783766 0.65845991 0.94802384 0.69647232 0.97243998 0.67119876]
val Loss: 0.4725 Attr Loss: 7.6903 Acc: 0.8800
attribute accuracies
[0.78933333 0.73066667 0.738      0.87466667 0.43533333 0.336
 0.854      0.63       0.92533333 0.66333333 0.95333333 0.614     ]
Epoch 35/69
----------
train Loss: 0.1646 Attr Loss: 7.4220 Acc: 0.9676
attribute accuracies
[0.81230606 0.7329332  0.76539278 0.89310795 0.47635963 0.37734771
 0.877756   0.66621754 0.94786053 0.70602646 0.97243998 0.68581578]
val Loss: 0.2325 Attr Loss: 7.5644 Acc: 0.9373
attribute accuracies
[0.788      0.73       0.73866667 0.874      0.44933333 0.33933333
 0.85333333 0.636      0.92733333 0.678      0.95266667 0.64666667]
Epoch 36/69
----------
train Loss: 0.1127 Attr Loss: 7.3368 Acc: 0.9819
attribute accuracies
[0.81206108 0.73268822 0.76535195 0.89335293 0.48350482 0.38359464
 0.87787849 0.67021885 0.94790136 0.71382492 0.97243998 0.69749306]
val Loss: 0.2109 Attr Loss: 7.5197 Acc: 0.9413
attribute accuracies
[0.792      0.728      0.73933333 0.87333333 0.45333333 0.35333333
 0.854      0.63866667 0.92533333 0.686      0.95266667 0.64533333]
Epoch 37/69
----------
train Loss: 0.1007 Attr Loss: 7.2759 Acc: 0.9864
attribute accuracies
[0.81255104 0.73276988 0.7655561  0.89306712 0.49167075 0.38841254
 0.87796015 0.67993631 0.94794219 0.72325657 0.97243998 0.69884044]
val Loss: 0.2182 Attr Loss: 7.5072 Acc: 0.9367
attribute accuracies
[0.79       0.73       0.73866667 0.87466667 0.45866667 0.348
 0.85333333 0.64133333 0.92866667 0.696      0.95333333 0.638     ]
Epoch 38/69
----------
train Loss: 0.1010 Attr Loss: 7.2361 Acc: 0.9869
attribute accuracies
[0.81287767 0.7326474  0.76535195 0.89335293 0.49840764 0.39425118
 0.877756   0.68532582 0.94786053 0.72709456 0.97243998 0.70496489]
val Loss: 0.2027 Attr Loss: 7.4545 Acc: 0.9467
attribute accuracies
[0.79333333 0.73066667 0.73733333 0.87733333 0.456      0.34466667
 0.854      0.64866667 0.92666667 0.69466667 0.95266667 0.65266667]
Epoch 39/69
----------
train Loss: 0.1036 Attr Loss: 7.1820 Acc: 0.9871
attribute accuracies
[0.81316348 0.73260657 0.76559693 0.89323044 0.50240895 0.39710926
 0.87787849 0.68879634 0.94794219 0.73477054 0.97243998 0.71272252]
val Loss: 0.2183 Attr Loss: 7.4246 Acc: 0.9460
attribute accuracies
[0.79333333 0.73066667 0.74066667 0.87466667 0.46133333 0.348
 0.854      0.65933333 0.92733333 0.69266667 0.95333333 0.65866667]
Epoch 40/69
----------
train Loss: 0.0987 Attr Loss: 7.1371 Acc: 0.9895
attribute accuracies
[0.81418422 0.73268822 0.76539278 0.89323044 0.50730851 0.4007431
 0.87791932 0.69390005 0.94786053 0.73983341 0.97248081 0.71492732]
val Loss: 0.2148 Attr Loss: 7.3894 Acc: 0.9493
attribute accuracies
[0.79266667 0.72533333 0.74066667 0.876      0.468      0.35266667
 0.856      0.65333333 0.926      0.69266667 0.95266667 0.65533333]
Epoch 41/69
----------
train Loss: 0.0944 Attr Loss: 7.0790 Acc: 0.9906
attribute accuracies
[0.81508248 0.73260657 0.76571942 0.89306712 0.50783929 0.40588764
 0.87808264 0.70039196 0.94798301 0.74383472 0.97248081 0.72023518]
val Loss: 0.2174 Attr Loss: 7.3770 Acc: 0.9447
attribute accuracies
[0.79466667 0.72866667 0.73933333 0.876      0.472      0.36133333
 0.852      0.654      0.926      0.69666667 0.954      0.66266667]
Epoch 42/69
----------
train Loss: 0.1013 Attr Loss: 7.0318 Acc: 0.9897
attribute accuracies
[0.81671566 0.73256574 0.7655561  0.89298546 0.51571942 0.41213457
 0.87779683 0.70725135 0.94790136 0.74746856 0.97243998 0.72562469]
val Loss: 0.2214 Attr Loss: 7.3154 Acc: 0.9440
attribute accuracies
[0.79866667 0.72666667 0.74066667 0.876      0.46533333 0.35533333
 0.854      0.65733333 0.92666667 0.70533333 0.954      0.66      ]
Epoch 43/69
----------
train Loss: 0.0966 Attr Loss: 6.9819 Acc: 0.9909
attribute accuracies
[0.81892046 0.73260657 0.76571942 0.89306712 0.52225216 0.41495182
 0.87783766 0.71027274 0.94802384 0.75489956 0.97248081 0.7318308 ]
val Loss: 0.2197 Attr Loss: 7.2787 Acc: 0.9473
attribute accuracies
[0.79466667 0.72666667 0.74133333 0.87666667 0.46933333 0.37733333
 0.85466667 0.66733333 0.92666667 0.71066667 0.95266667 0.678     ]
Epoch 44/69
----------
train Loss: 0.0982 Attr Loss: 6.9306 Acc: 0.9910
attribute accuracies
[0.81969623 0.73260657 0.76535195 0.89314878 0.52539605 0.42270946
 0.87796015 0.71276335 0.9478197  0.75902335 0.97243998 0.73954761]
val Loss: 0.2075 Attr Loss: 7.2401 Acc: 0.9453
attribute accuracies
[0.798      0.73       0.74133333 0.874      0.476      0.37666667
 0.85533333 0.67       0.92666667 0.71133333 0.95266667 0.68      ]
Epoch 45/69
----------
train Loss: 0.0959 Attr Loss: 6.8773 Acc: 0.9910
attribute accuracies
[0.82194186 0.73256574 0.76559693 0.89318961 0.53315368 0.42756819
 0.87787849 0.71811204 0.94786053 0.76416789 0.97252164 0.7403642 ]
val Loss: 0.2284 Attr Loss: 7.2092 Acc: 0.9493
attribute accuracies
[0.79933333 0.72666667 0.742      0.874      0.48333333 0.38133333
 0.85533333 0.67       0.926      0.71866667 0.95266667 0.66733333]
Epoch 46/69
----------
train Loss: 0.0996 Attr Loss: 6.8168 Acc: 0.9903
attribute accuracies
[0.82508574 0.7326474  0.76543361 0.89310795 0.53731831 0.43467255
 0.87787849 0.72366487 0.94794219 0.76759758 0.97243998 0.74942838]
val Loss: 0.2217 Attr Loss: 7.1727 Acc: 0.9480
attribute accuracies
[0.79866667 0.72733333 0.742      0.874      0.48533333 0.376
 0.854      0.66733333 0.92666667 0.704      0.954      0.68      ]
Epoch 47/69
----------
train Loss: 0.0948 Attr Loss: 6.7723 Acc: 0.9914
attribute accuracies
[0.82647395 0.73268822 0.76543361 0.89318961 0.54507594 0.43826556
 0.87783766 0.72558386 0.94786053 0.77437531 0.97252164 0.7488976 ]
val Loss: 0.2201 Attr Loss: 7.1567 Acc: 0.9460
attribute accuracies
[0.796      0.72933333 0.74       0.87466667 0.488      0.38266667
 0.85266667 0.67066667 0.92666667 0.712      0.95333333 0.67933333]
Epoch 48/69
----------
train Loss: 0.0975 Attr Loss: 6.7050 Acc: 0.9906
attribute accuracies
[0.82916871 0.73281071 0.7655561  0.89302629 0.54593337 0.4470031
 0.877756   0.73370897 0.94794219 0.77804998 0.97248081 0.75649192]
val Loss: 0.2149 Attr Loss: 7.0936 Acc: 0.9467
attribute accuracies
[0.8        0.728      0.73933333 0.87466667 0.48533333 0.392
 0.85333333 0.678      0.92666667 0.71733333 0.95266667 0.68      ]
Epoch 49/69
----------
train Loss: 0.0958 Attr Loss: 6.6508 Acc: 0.9922
attribute accuracies
[0.83357831 0.73289237 0.76551527 0.89314878 0.55205781 0.4500245
 0.87779683 0.73987424 0.94794219 0.78486853 0.97243998 0.76645435]
val Loss: 0.2252 Attr Loss: 7.0790 Acc: 0.9460
attribute accuracies
[0.798      0.73266667 0.73866667 0.874      0.48533333 0.39133333
 0.85666667 0.688      0.92733333 0.72733333 0.954      0.68333333]
Epoch 50/69
----------
train Loss: 0.0941 Attr Loss: 6.6033 Acc: 0.9923
attribute accuracies
[0.83443573 0.73370897 0.76551527 0.89314878 0.55703903 0.45635309
 0.87800098 0.74379389 0.94790136 0.78458272 0.97243998 0.76845501]
val Loss: 0.2224 Attr Loss: 7.0121 Acc: 0.9473
attribute accuracies
[0.8        0.73       0.73933333 0.87466667 0.494      0.39866667
 0.85333333 0.69133333 0.926      0.72533333 0.954      0.68933333]
Epoch 51/69
----------
train Loss: 0.0932 Attr Loss: 6.5386 Acc: 0.9915
attribute accuracies
[0.83594643 0.73440307 0.76559693 0.89323044 0.56177527 0.4603544
 0.87783766 0.74175241 0.94802384 0.79344276 0.97243998 0.77184387]
val Loss: 0.2347 Attr Loss: 6.9647 Acc: 0.9400
attribute accuracies
[0.79733333 0.73133333 0.74066667 0.87333333 0.50066667 0.398
 0.854      0.68733333 0.926      0.73066667 0.954      0.69666667]
Epoch 52/69
----------
train Loss: 0.0948 Attr Loss: 6.4819 Acc: 0.9918
attribute accuracies
[0.83884534 0.73558713 0.76559693 0.89302629 0.56610322 0.46427405
 0.87791932 0.74906092 0.94798301 0.79438184 0.97252164 0.77437531]
val Loss: 0.2261 Attr Loss: 6.9492 Acc: 0.9487
attribute accuracies
[0.798      0.732      0.73733333 0.87866667 0.50533333 0.40266667
 0.854      0.69266667 0.92666667 0.72266667 0.95266667 0.69733333]
Epoch 53/69
----------
train Loss: 0.0921 Attr Loss: 6.4310 Acc: 0.9923
attribute accuracies
[0.84027438 0.74040503 0.7655561  0.89314878 0.57451413 0.46945942
 0.877756   0.74979585 0.94790136 0.80001633 0.97243998 0.78209211]
val Loss: 0.2223 Attr Loss: 6.8913 Acc: 0.9420
attribute accuracies
[0.8        0.73333333 0.73666667 0.874      0.51866667 0.41466667
 0.85333333 0.68866667 0.92533333 0.73066667 0.95333333 0.70666667]
Epoch 54/69
----------
train Loss: 0.0895 Attr Loss: 6.3629 Acc: 0.9924
attribute accuracies
[0.84321411 0.74318145 0.76567859 0.89310795 0.58023028 0.47864609
 0.87791932 0.75085742 0.94794219 0.80601829 0.97243998 0.78507268]
val Loss: 0.2195 Attr Loss: 6.8419 Acc: 0.9467
attribute accuracies
[0.80133333 0.73466667 0.74133333 0.87533333 0.52866667 0.40466667
 0.85133333 0.70666667 0.928      0.73466667 0.95333333 0.69866667]
Epoch 55/69
----------
train Loss: 0.0960 Attr Loss: 6.3009 Acc: 0.9918
attribute accuracies
[0.84692961 0.74832598 0.76551527 0.89302629 0.58145517 0.47917687
 0.87787849 0.75849257 0.94786053 0.81226523 0.97243998 0.790748  ]
val Loss: 0.2204 Attr Loss: 6.8043 Acc: 0.9500
attribute accuracies
[0.80266667 0.74       0.73866667 0.876      0.532      0.42
 0.852      0.69666667 0.92733333 0.742      0.95333333 0.71      ]
Epoch 56/69
----------
train Loss: 0.0980 Attr Loss: 6.2577 Acc: 0.9906
attribute accuracies
[0.84958354 0.7526131  0.76637269 0.89314878 0.58864119 0.48603626
 0.87787849 0.75718602 0.94794219 0.81357178 0.97248081 0.79679079]
val Loss: 0.2264 Attr Loss: 6.7801 Acc: 0.9473
attribute accuracies
[0.80733333 0.742      0.73666667 0.87733333 0.52933333 0.41466667
 0.854      0.706      0.926      0.74466667 0.95333333 0.69866667]
Epoch 57/69
----------
train Loss: 0.0884 Attr Loss: 6.1759 Acc: 0.9926
attribute accuracies
[0.85276825 0.76175894 0.76645435 0.8933121  0.59341826 0.49375306
 0.87787849 0.76825086 0.94786053 0.82055365 0.97252164 0.80099624]
val Loss: 0.2241 Attr Loss: 6.7436 Acc: 0.9473
attribute accuracies
[0.79733333 0.75066667 0.73866667 0.878      0.54133333 0.424
 0.85333333 0.70866667 0.92533333 0.748      0.95333333 0.71266667]
Epoch 58/69
----------
train Loss: 0.0890 Attr Loss: 6.1093 Acc: 0.9930
attribute accuracies
[0.85403397 0.76763841 0.7673526  0.89310795 0.60240078 0.50012249
 0.87787849 0.7714764  0.9478197  0.82475911 0.97243998 0.80683488]
val Loss: 0.2390 Attr Loss: 6.7065 Acc: 0.9393
attribute accuracies
[0.80266667 0.758      0.73866667 0.87466667 0.546      0.42266667
 0.85333333 0.70133333 0.92533333 0.74933333 0.95333333 0.71466667]
Epoch 59/69
----------
train Loss: 0.0940 Attr Loss: 6.0606 Acc: 0.9920
attribute accuracies
[0.85734117 0.77735587 0.7692716  0.89310795 0.60615711 0.50134738
 0.87787849 0.7718847  0.94786053 0.82680059 0.97248081 0.80769231]
val Loss: 0.2211 Attr Loss: 6.6649 Acc: 0.9480
attribute accuracies
[0.80866667 0.76       0.74333333 0.87733333 0.54733333 0.432
 0.854      0.722      0.92666667 0.76       0.95266667 0.72466667]
Epoch 60/69
----------
train Loss: 0.0893 Attr Loss: 5.9937 Acc: 0.9926
attribute accuracies
[0.86036257 0.7811122  0.77074147 0.89306712 0.61015842 0.50788012
 0.87791932 0.77555937 0.94802384 0.82961783 0.97248081 0.81691981]
val Loss: 0.2182 Attr Loss: 6.6504 Acc: 0.9487
attribute accuracies
[0.80466667 0.75866667 0.74133333 0.874      0.55066667 0.43066667
 0.85266667 0.71733333 0.928      0.75666667 0.95266667 0.716     ]
Epoch 61/69
----------
train Loss: 0.0895 Attr Loss: 5.9293 Acc: 0.9926
attribute accuracies
[0.86073003 0.78560346 0.77486526 0.89298546 0.61856933 0.51482117
 0.87796015 0.78307202 0.94786053 0.83745713 0.97248081 0.82463662]
val Loss: 0.2260 Attr Loss: 6.5766 Acc: 0.9447
attribute accuracies
[0.81       0.752      0.748      0.87666667 0.554      0.436
 0.85333333 0.72866667 0.92533333 0.76       0.95333333 0.734     ]
Epoch 62/69
----------
train Loss: 0.0907 Attr Loss: 5.8670 Acc: 0.9920
attribute accuracies
[0.86191409 0.79258533 0.77931569 0.89302629 0.62747019 0.51861832
 0.877756   0.78388862 0.94786053 0.84590887 0.97252164 0.82782133]
val Loss: 0.2221 Attr Loss: 6.5444 Acc: 0.9513
attribute accuracies
[0.81       0.75533333 0.74866667 0.87533333 0.55266667 0.45066667
 0.85333333 0.72133333 0.926      0.76533333 0.95333333 0.73533333]
Epoch 63/69
----------
train Loss: 0.0925 Attr Loss: 5.8108 Acc: 0.9917
attribute accuracies
[0.86652785 0.80022048 0.78388862 0.89314878 0.63130818 0.51980238
 0.87796015 0.78356198 0.94790136 0.84570472 0.97252164 0.8299853 ]
val Loss: 0.2078 Attr Loss: 6.4936 Acc: 0.9527
attribute accuracies
[0.81133333 0.764      0.752      0.87466667 0.56533333 0.44133333
 0.852      0.73066667 0.92733333 0.758      0.95333333 0.734     ]
Epoch 64/69
----------
train Loss: 0.0901 Attr Loss: 5.7498 Acc: 0.9922
attribute accuracies
[0.86861016 0.80226196 0.79066634 0.89302629 0.63951494 0.5247836
 0.87796015 0.78846154 0.94798301 0.84729708 0.97243998 0.83386412]
val Loss: 0.2146 Attr Loss: 6.4287 Acc: 0.9507
attribute accuracies
[0.80866667 0.754      0.76133333 0.874      0.568      0.44533333
 0.85333333 0.73       0.92533333 0.75866667 0.95333333 0.73866667]
Epoch 65/69
----------
train Loss: 0.0904 Attr Loss: 5.6855 Acc: 0.9913
attribute accuracies
[0.87171321 0.80769231 0.79540258 0.89335293 0.64719092 0.5304181
 0.87796015 0.79540258 0.94786053 0.85052262 0.97252164 0.83602809]
val Loss: 0.2254 Attr Loss: 6.3995 Acc: 0.9493
attribute accuracies
[0.81866667 0.758      0.76466667 0.87533333 0.568      0.45
 0.85133333 0.72666667 0.92666667 0.75933333 0.95266667 0.74666667]
Epoch 66/69
----------
train Loss: 0.0857 Attr Loss: 5.6156 Acc: 0.9935
attribute accuracies
[0.87379553 0.81038707 0.80205781 0.89318961 0.65482607 0.53731831
 0.87791932 0.80005716 0.94786053 0.8544831  0.97252164 0.83880451]
val Loss: 0.2233 Attr Loss: 6.3308 Acc: 0.9480
attribute accuracies
[0.82466667 0.768      0.76533333 0.87733333 0.57133333 0.45533333
 0.85333333 0.73733333 0.926      0.77333333 0.95333333 0.74266667]
Epoch 67/69
----------
train Loss: 0.0891 Attr Loss: 5.5648 Acc: 0.9922
attribute accuracies
[0.8762453  0.81675649 0.81042789 0.89310795 0.65613261 0.53882901
 0.87791932 0.80054712 0.94798301 0.8581986  0.97243998 0.8426425 ]
val Loss: 0.2249 Attr Loss: 6.3162 Acc: 0.9460
attribute accuracies
[0.82466667 0.768      0.76333333 0.87533333 0.57266667 0.45
 0.85466667 0.732      0.92666667 0.78466667 0.95333333 0.75466667]
Epoch 68/69
----------
train Loss: 0.0908 Attr Loss: 5.5095 Acc: 0.9922
attribute accuracies
[0.87522456 0.8214519  0.81365344 0.89323044 0.66164462 0.54360608
 0.87783766 0.80463008 0.9478197  0.86224073 0.97256247 0.84729708]
val Loss: 0.2373 Attr Loss: 6.2535 Acc: 0.9400
attribute accuracies
[0.826      0.774      0.78066667 0.874      0.586      0.46133333
 0.85333333 0.75       0.92666667 0.78266667 0.95333333 0.74933333]
Epoch 69/69
----------
train Loss: 0.0903 Attr Loss: 5.4515 Acc: 0.9918
attribute accuracies
[0.87791932 0.82463662 0.81904295 0.89314878 0.67279112 0.54797485
 0.87791932 0.80658991 0.94790136 0.86252654 0.97248081 0.85019598]
val Loss: 0.2310 Attr Loss: 6.2190 Acc: 0.9407
attribute accuracies
[0.82333333 0.77733333 0.77666667 0.87466667 0.57466667 0.46133333
 0.85333333 0.736      0.928      0.79266667 0.954      0.76066667]
Training complete in 126m 21s
