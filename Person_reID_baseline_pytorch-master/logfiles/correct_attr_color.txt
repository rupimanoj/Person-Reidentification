adam_freeze_75.txt
adam_output.txt
all_epochs_mix_erasing.txt
all_epochs_multi_erasing.txt
all_epochs.txt
attribute_data.npy
attribute_data_preprocessing.ipynb
Attributes verification.ipynb
collect_results.py
correct_attr_color.txt
correct_attr.txt
demo.py
dense_attr_color_erasing_70e.txt
dense_attr_color_erasing.txt
dense_attr_color.txt
dense_attr_full_set.txt
dense_attr_no_color.txt
dense_attr.txt
dense_erasing_all_epochs.txt
downcolor.npy
duke_attribute.mat
duke_out.txt
Ensembling experimentation.ipynb
erasing_data_augmentation_checking.ipynb
evaluate_ensemble.py
evaluate_gpu.py
evaluate_int.py
evaluate.py
evaluate_rerank.py
extract.py
extract_tta.py
feeze_learning.ipynb
image_net_erasing.txt
image_net_erasing_wde3.txt
image_net_freeze.txt
image_net_wde3.txt
image_net_wde5.txt
labels.npy
LICENSE
load_mat_file.py
market_attribute.mat
mkt_0.4g_freeze.txt
model
model.py
multi_random_erasing.py
multi_step_LR_3
multi_step_LR_3.txt
multi_step_LR.txt
only_attr_train.txt
output_pcb_attr.txt
output_sat_color.txt
output_sat_erasing.txt
output_sat.txt
prepare.py
prepare_static.py
__pycache__
random_erasing.py
README.md
re_ranking.py
results_collection.ipynb
sample_model
test.py
train_attr_dl.py
train_attr.py
train_duke.py
train.jpg
train_pcb_attr.py
train.py
tta_expermimenation.ipynb
tutorial
untitled
untitled1
Untitled1.ipynb
Untitled2.ipynb
Untitled.ipynb
upcolor.npy
use_info.md
visualization
visualize.py
class number:  751
net output size:
torch.Size([8, 1024])
0
[ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0), Resize(size=(288, 144), interpolation=PIL.Image.BICUBIC), RandomCrop(size=(256, 128), padding=0), RandomHorizontalFlip(p=0.5), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), <random_erasing.RandomErasing object at 0x7fa151bb36d8>]
ft_attr_net_dense(
  (model): DenseNet(
    (features): Sequential(
      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu0): ReLU(inplace)
      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (denseblock1): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (transition1): _Transition(
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
      (denseblock2): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer7): _DenseLayer(
          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer8): _DenseLayer(
          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer9): _DenseLayer(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer10): _DenseLayer(
          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer11): _DenseLayer(
          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer12): _DenseLayer(
          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (transition2): _Transition(
        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
      (denseblock3): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer7): _DenseLayer(
          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer8): _DenseLayer(
          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer9): _DenseLayer(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer10): _DenseLayer(
          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer11): _DenseLayer(
          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer12): _DenseLayer(
          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer13): _DenseLayer(
          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer14): _DenseLayer(
          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer15): _DenseLayer(
          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer16): _DenseLayer(
          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer17): _DenseLayer(
          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer18): _DenseLayer(
          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer19): _DenseLayer(
          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer20): _DenseLayer(
          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer21): _DenseLayer(
          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer22): _DenseLayer(
          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer23): _DenseLayer(
          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer24): _DenseLayer(
          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (transition3): _Transition(
        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
      (denseblock4): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer7): _DenseLayer(
          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer8): _DenseLayer(
          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer9): _DenseLayer(
          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer10): _DenseLayer(
          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer11): _DenseLayer(
          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer12): _DenseLayer(
          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer13): _DenseLayer(
          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer14): _DenseLayer(
          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer15): _DenseLayer(
          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer16): _DenseLayer(
          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Linear(in_features=1024, out_features=1000, bias=True)
    (fc): Sequential()
  )
  (classifier): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=1500, bias=True)
    )
  )
  (classifierage): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=4, bias=True)
    )
  )
  (classifierbackpack): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierbag): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierhandbag): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierdowncolor): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=9, bias=True)
    )
  )
  (classifierupcolor): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=8, bias=True)
    )
  )
  (classifierclothes): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierdown): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierup): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierhair): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierhat): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifiergender): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
)
/opt/anaconda3/lib/python3.7/site-packages/torchvision-0.2.1-py3.7.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:14: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
  init.kaiming_normal(m.weight.data, a=0, mode='fan_out')
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:15: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(m.bias.data, 0.0)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:17: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.
  init.normal(m.weight.data, 1.0, 0.02)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:18: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(m.bias.data, 0.0)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:23: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.
  init.normal(m.weight.data, std=0.001)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:24: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(m.bias.data, 0.0)
0.7788577079772949
shape (1501, 12)
[1. 1. 1. ... 1. 1. 1.]
attr_data.shape
torch.Size([1501, 12])
checking model folder------------------- ./model/correct_attr_color
True
No. of Attributes selected
12
Epoch 0/69
----------
train Loss: 4.9541 Attr Loss: 9.7968 Acc: 0.1605
attribute accuracies
[0.81794055 0.7230116  0.75869672 0.89939572 0.42548587 0.29621917
 0.87069247 0.64053569 0.94214437 0.63939245 0.97052099 0.55667157]
val Loss: 3.2606 Attr Loss: 9.4854 Acc: 0.3247
attribute accuracies
[0.792      0.728      0.73866667 0.876      0.42466667 0.30666667
 0.854      0.614      0.92733333 0.64133333 0.95333333 0.588     ]
Epoch 1/69
----------
train Loss: 2.3305 Attr Loss: 9.5235 Acc: 0.4673
attribute accuracies
[0.81900212 0.72337906 0.75930916 0.90017148 0.42838478 0.31467418
 0.87126409 0.64257717 0.94341009 0.64400621 0.97162339 0.57006369]
val Loss: 1.8396 Attr Loss: 9.3946 Acc: 0.5507
attribute accuracies
[0.78933333 0.72933333 0.74133333 0.87466667 0.434      0.31266667
 0.85533333 0.62133333 0.926      0.63733333 0.95333333 0.54333333]
Epoch 2/69
----------
train Loss: 1.5421 Attr Loss: 9.4077 Acc: 0.6191
attribute accuracies
[0.81920627 0.7243998  0.75943165 0.90013065 0.43095705 0.32202352
 0.8714274  0.64674179 0.94324677 0.64906908 0.97162339 0.58321084]
val Loss: 1.2577 Attr Loss: 9.3324 Acc: 0.6740
attribute accuracies
[0.78866667 0.73066667 0.74066667 0.874      0.43333333 0.32466667
 0.85333333 0.628      0.92733333 0.64       0.95333333 0.568     ]
Epoch 3/69
----------
train Loss: 1.1878 Attr Loss: 9.3207 Acc: 0.7001
attribute accuracies
[0.81896129 0.72423649 0.7592275  0.90025314 0.43744896 0.32749469
 0.87122326 0.65070227 0.9432876  0.65160052 0.97174588 0.58909032]
val Loss: 0.9753 Attr Loss: 9.2778 Acc: 0.7433
attribute accuracies
[0.79066667 0.72866667 0.74133333 0.87466667 0.432      0.32933333
 0.854      0.62333333 0.92733333 0.64666667 0.954      0.57466667]
Epoch 4/69
----------
train Loss: 0.9847 Attr Loss: 9.2519 Acc: 0.7481
attribute accuracies
[0.8192471  0.72435897 0.75906418 0.90021231 0.44320594 0.33023028
 0.87126409 0.65494855 0.94320594 0.65539768 0.97166422 0.59721542]
val Loss: 0.9362 Attr Loss: 9.2527 Acc: 0.7393
attribute accuracies
[0.79066667 0.73       0.73866667 0.87466667 0.44133333 0.316
 0.85266667 0.62133333 0.92666667 0.65066667 0.95466667 0.58      ]
Epoch 5/69
----------
train Loss: 0.8745 Attr Loss: 9.1921 Acc: 0.7777
attribute accuracies
[0.81928793 0.7243998  0.75959497 0.90017148 0.44561489 0.3343949
 0.87134575 0.65870488 0.94336926 0.65780663 0.97166422 0.60178834]
val Loss: 0.7310 Attr Loss: 9.2079 Acc: 0.8007
attribute accuracies
[0.792      0.73       0.73866667 0.87533333 0.45       0.33266667
 0.85466667 0.62933333 0.92666667 0.64666667 0.95266667 0.58066667]
Epoch 6/69
----------
train Loss: 0.7727 Attr Loss: 9.1294 Acc: 0.8026
attribute accuracies
[0.8188388  0.72537972 0.75971746 0.900049   0.45574065 0.33688551
 0.87134575 0.66082803 0.94324677 0.66025641 0.97166422 0.61154663]
val Loss: 0.6713 Attr Loss: 9.1478 Acc: 0.8113
attribute accuracies
[0.788      0.72933333 0.74       0.87733333 0.452      0.32333333
 0.854      0.62266667 0.928      0.64866667 0.954      0.582     ]
Epoch 7/69
----------
train Loss: 0.7086 Attr Loss: 9.0676 Acc: 0.8210
attribute accuracies
[0.81916544 0.72517557 0.75951331 0.90008983 0.46182427 0.34252001
 0.87130492 0.66291034 0.94324677 0.66213457 0.97162339 0.61587457]
val Loss: 0.6956 Attr Loss: 9.1569 Acc: 0.8107
attribute accuracies
[0.78866667 0.73       0.73866667 0.87466667 0.448      0.33066667
 0.854      0.628      0.926      0.65       0.95333333 0.58266667]
Epoch 8/69
----------
train Loss: 0.6781 Attr Loss: 9.0151 Acc: 0.8305
attribute accuracies
[0.81928793 0.72505308 0.76016659 0.90017148 0.46798955 0.34452066
 0.87122326 0.6669933  0.94324677 0.66642169 0.97162339 0.62367304]
val Loss: 0.6414 Attr Loss: 9.1015 Acc: 0.8227
attribute accuracies
[0.788      0.73133333 0.74133333 0.87333333 0.45866667 0.32866667
 0.854      0.63133333 0.92533333 0.64733333 0.95266667 0.598     ]
Epoch 9/69
----------
train Loss: 0.6414 Attr Loss: 8.9668 Acc: 0.8362
attribute accuracies
[0.81920627 0.72586967 0.75979912 0.90013065 0.47558386 0.34578638
 0.87138658 0.67103544 0.94324677 0.66993304 0.97166422 0.62636779]
val Loss: 0.5875 Attr Loss: 9.0735 Acc: 0.8233
attribute accuracies
[0.79066667 0.72933333 0.74266667 0.876      0.45333333 0.32066667
 0.856      0.628      0.92533333 0.656      0.95266667 0.59533333]
Epoch 10/69
----------
train Loss: 0.5939 Attr Loss: 8.9213 Acc: 0.8496
attribute accuracies
[0.81916544 0.72672709 0.75967663 0.90008983 0.47864609 0.34717459
 0.87134575 0.67397518 0.9432876  0.6696064  0.97170505 0.63502368]
val Loss: 0.5819 Attr Loss: 9.0385 Acc: 0.8400
attribute accuracies
[0.79133333 0.734      0.738      0.87733333 0.46133333 0.334
 0.85333333 0.62466667 0.92533333 0.652      0.95333333 0.59533333]
Epoch 11/69
----------
train Loss: 0.6043 Attr Loss: 8.8900 Acc: 0.8479
attribute accuracies
[0.81904295 0.72680875 0.75983995 0.90021231 0.48276988 0.35268659
 0.87118243 0.67458762 0.94324677 0.67654744 0.97170505 0.6373918 ]
val Loss: 0.5394 Attr Loss: 9.0113 Acc: 0.8453
attribute accuracies
[0.79066667 0.73066667 0.73866667 0.87666667 0.46333333 0.33333333
 0.852      0.63466667 0.926      0.66066667 0.95266667 0.60533333]
Epoch 12/69
----------
train Loss: 0.5830 Attr Loss: 8.8431 Acc: 0.8566
attribute accuracies
[0.81957374 0.72693124 0.76024824 0.90013065 0.49081333 0.3507676
 0.87138658 0.67752736 0.94324677 0.67981382 0.97170505 0.64453699]
val Loss: 0.5565 Attr Loss: 8.9697 Acc: 0.8473
attribute accuracies
[0.788      0.73466667 0.74       0.876      0.462      0.33133333
 0.85266667 0.63866667 0.926      0.66133333 0.95266667 0.60533333]
Epoch 13/69
----------
train Loss: 0.5573 Attr Loss: 8.8144 Acc: 0.8622
attribute accuracies
[0.81945125 0.72689041 0.75967663 0.90008983 0.49534542 0.35513637
 0.87134575 0.67809897 0.94320594 0.67911971 0.97166422 0.64694594]
val Loss: 0.5720 Attr Loss: 8.9930 Acc: 0.8393
attribute accuracies
[0.79066667 0.73333333 0.74133333 0.874      0.466      0.33866667
 0.85266667 0.63266667 0.926      0.66866667 0.95266667 0.60133333]
Epoch 14/69
----------
train Loss: 0.5348 Attr Loss: 8.7812 Acc: 0.8635
attribute accuracies
[0.81990038 0.72844194 0.75971746 0.90008983 0.49902009 0.35734117
 0.87126409 0.67781316 0.94316512 0.68152866 0.97170505 0.6496407 ]
val Loss: 0.5530 Attr Loss: 8.9771 Acc: 0.8493
attribute accuracies
[0.79066667 0.732      0.74066667 0.874      0.47066667 0.33266667
 0.85333333 0.628      0.92666667 0.662      0.954      0.604     ]
Epoch 15/69
----------
train Loss: 0.5151 Attr Loss: 8.7596 Acc: 0.8711
attribute accuracies
[0.81985955 0.72778867 0.75975829 0.900049   0.5033072  0.35705537
 0.87126409 0.67867059 0.9432876  0.68344766 0.97166422 0.64931406]
val Loss: 0.4969 Attr Loss: 8.9492 Acc: 0.8653
attribute accuracies
[0.79       0.73333333 0.74266667 0.876      0.47066667 0.33
 0.85466667 0.63666667 0.92666667 0.672      0.95333333 0.62066667]
Epoch 16/69
----------
train Loss: 0.5106 Attr Loss: 8.7408 Acc: 0.8724
attribute accuracies
[0.81973706 0.72787033 0.7592275  0.90017148 0.50146987 0.35934183
 0.87130492 0.68418259 0.94320594 0.68299853 0.97170505 0.65025314]
val Loss: 0.4822 Attr Loss: 8.9117 Acc: 0.8787
attribute accuracies
[0.78733333 0.73066667 0.74466667 0.874      0.47333333 0.338
 0.85733333 0.634      0.928      0.66933333 0.954      0.614     ]
Epoch 17/69
----------
train Loss: 0.4965 Attr Loss: 8.7176 Acc: 0.8771
attribute accuracies
[0.82022701 0.72831945 0.75930916 0.90017148 0.50555283 0.35570799
 0.87138658 0.6825494  0.9432876  0.68381512 0.97170505 0.65503021]
val Loss: 0.4937 Attr Loss: 8.9113 Acc: 0.8713
attribute accuracies
[0.79       0.73266667 0.74133333 0.87533333 0.47       0.34333333
 0.85533333 0.648      0.926      0.66533333 0.95333333 0.60333333]
Epoch 18/69
----------
train Loss: 0.4878 Attr Loss: 8.7074 Acc: 0.8798
attribute accuracies
[0.82059448 0.72954434 0.75955414 0.90008983 0.50710436 0.36048506
 0.87126409 0.68499918 0.94316512 0.68430508 0.97166422 0.65168218]
val Loss: 0.4789 Attr Loss: 8.8525 Acc: 0.8687
attribute accuracies
[0.78866667 0.72933333 0.73933333 0.87466667 0.47866667 0.35
 0.85533333 0.64333333 0.92666667 0.66       0.954      0.60666667]
Epoch 19/69
----------
train Loss: 0.4642 Attr Loss: 8.6740 Acc: 0.8893
attribute accuracies
[0.82079863 0.72831945 0.75918667 0.90013065 0.51090152 0.36215907
 0.87130492 0.68724481 0.94324677 0.68985791 0.97162339 0.65674506]
val Loss: 0.4622 Attr Loss: 8.8591 Acc: 0.8787
attribute accuracies
[0.792      0.73466667 0.74133333 0.87533333 0.47533333 0.34866667
 0.854      0.64133333 0.926      0.658      0.95333333 0.608     ]
Epoch 20/69
----------
train Loss: 0.4569 Attr Loss: 8.6513 Acc: 0.8854
attribute accuracies
[0.82063531 0.72995264 0.75934999 0.90013065 0.51416789 0.36060755
 0.87126409 0.68842887 0.9432876  0.69022538 0.97162339 0.65809244]
val Loss: 0.4388 Attr Loss: 8.8677 Acc: 0.8813
attribute accuracies
[0.794      0.73266667 0.73666667 0.87533333 0.464      0.338
 0.85333333 0.646      0.92666667 0.65933333 0.954      0.60866667]
Epoch 21/69
----------
train Loss: 0.4645 Attr Loss: 8.6503 Acc: 0.8880
attribute accuracies
[0.82071697 0.73081006 0.75934999 0.90017148 0.51645435 0.35950514
 0.87146823 0.68977625 0.9432876  0.69283848 0.97162339 0.65809244]
val Loss: 0.4926 Attr Loss: 8.9065 Acc: 0.8667
attribute accuracies
[0.796      0.73333333 0.73733333 0.87666667 0.47266667 0.33866667
 0.85333333 0.64       0.926      0.66333333 0.954      0.594     ]
Epoch 22/69
----------
train Loss: 0.4630 Attr Loss: 8.6248 Acc: 0.8868
attribute accuracies
[0.8211661  0.73060591 0.7592275  0.90017148 0.52221133 0.36558876
 0.8714274  0.69185857 0.94316512 0.69075617 0.97166422 0.65637759]
val Loss: 0.4879 Attr Loss: 8.8640 Acc: 0.8727
attribute accuracies
[0.79266667 0.73266667 0.73866667 0.87666667 0.46866667 0.354
 0.85333333 0.64266667 0.92533333 0.664      0.95266667 0.61733333]
Epoch 23/69
----------
train Loss: 0.4563 Attr Loss: 8.6175 Acc: 0.8880
attribute accuracies
[0.82112527 0.73150416 0.75914584 0.90013065 0.52253797 0.36203658
 0.8714274  0.68973542 0.94320594 0.69283848 0.97162339 0.65878654]
val Loss: 0.4706 Attr Loss: 8.8756 Acc: 0.8740
attribute accuracies
[0.79333333 0.738      0.738      0.87466667 0.468      0.34133333
 0.85266667 0.64466667 0.92666667 0.66733333 0.95266667 0.61466667]
Epoch 24/69
----------
train Loss: 0.4397 Attr Loss: 8.6035 Acc: 0.8951
attribute accuracies
[0.82190103 0.73154499 0.75955414 0.90021231 0.52310959 0.36354728
 0.87126409 0.69124612 0.94332843 0.69447166 0.97166422 0.65654091]
val Loss: 0.4072 Attr Loss: 8.8399 Acc: 0.8867
attribute accuracies
[0.79       0.73266667 0.74       0.87466667 0.47866667 0.34466667
 0.852      0.64666667 0.92666667 0.66066667 0.95333333 0.604     ]
Epoch 25/69
----------
train Loss: 0.4221 Attr Loss: 8.5641 Acc: 0.8980
attribute accuracies
[0.82096195 0.73170831 0.75926833 0.90008983 0.53192879 0.36281235
 0.8711416  0.69230769 0.94316512 0.69794219 0.97162339 0.66001143]
val Loss: 0.4622 Attr Loss: 8.8010 Acc: 0.8773
attribute accuracies
[0.79733333 0.73666667 0.74       0.87533333 0.47866667 0.344
 0.85666667 0.64066667 0.92533333 0.66066667 0.95266667 0.60666667]
Epoch 26/69
----------
train Loss: 0.4127 Attr Loss: 8.5558 Acc: 0.9027
attribute accuracies
[0.8218602  0.73236159 0.75959497 0.90000817 0.53078556 0.36464968
 0.87134575 0.69394088 0.94320594 0.69308346 0.97170505 0.65703087]
val Loss: 0.4428 Attr Loss: 8.8390 Acc: 0.8800
attribute accuracies
[0.79466667 0.738      0.73933333 0.87466667 0.47866667 0.348
 0.85333333 0.64533333 0.926      0.67266667 0.954      0.61866667]
Epoch 27/69
----------
train Loss: 0.4267 Attr Loss: 8.5449 Acc: 0.8980
attribute accuracies
[0.82190103 0.73411726 0.75959497 0.90021231 0.53658337 0.37187653
 0.87138658 0.69349175 0.94320594 0.69504328 0.97162339 0.66095051]
val Loss: 0.4745 Attr Loss: 8.7727 Acc: 0.8807
attribute accuracies
[0.79       0.73866667 0.74       0.87533333 0.49066667 0.34666667
 0.85533333 0.63466667 0.92666667 0.67333333 0.954      0.606     ]
Epoch 28/69
----------
train Loss: 0.4299 Attr Loss: 8.5236 Acc: 0.8943
attribute accuracies
[0.82259513 0.73550547 0.75939082 0.90041646 0.53858403 0.36865099
 0.87130492 0.69341009 0.9432876  0.69765638 0.97166422 0.66233872]
val Loss: 0.4409 Attr Loss: 8.7927 Acc: 0.8827
attribute accuracies
[0.79333333 0.734      0.74466667 0.87466667 0.492      0.34666667
 0.85333333 0.644      0.92666667 0.66733333 0.95266667 0.58933333]
Epoch 29/69
----------
train Loss: 0.4252 Attr Loss: 8.5064 Acc: 0.8974
attribute accuracies
[0.82218684 0.73726115 0.75934999 0.900049   0.53862486 0.3707333
 0.87130492 0.69422669 0.9432876  0.69798301 0.97162339 0.66197126]
val Loss: 0.4682 Attr Loss: 8.7677 Acc: 0.8667
attribute accuracies
[0.79333333 0.73733333 0.73866667 0.876      0.49666667 0.35466667
 0.85333333 0.64666667 0.92533333 0.666      0.95333333 0.602     ]
Epoch 30/69
----------
train Loss: 0.4017 Attr Loss: 8.4953 Acc: 0.9041
attribute accuracies
[0.82153356 0.73795525 0.75939082 0.90013065 0.54287114 0.37069247
 0.87130492 0.69643149 0.9432876  0.70055528 0.97166422 0.6636861 ]
val Loss: 0.4762 Attr Loss: 8.7956 Acc: 0.8740
attribute accuracies
[0.79466667 0.73866667 0.73866667 0.87466667 0.488      0.35
 0.85466667 0.65866667 0.92533333 0.66533333 0.95266667 0.60733333]
Epoch 31/69
----------
train Loss: 0.4139 Attr Loss: 8.4776 Acc: 0.8991
attribute accuracies
[0.82247264 0.73848604 0.75992161 0.90008983 0.54658664 0.37326474
 0.87118243 0.69532909 0.94316512 0.70341336 0.97166422 0.66515597]
val Loss: 0.4939 Attr Loss: 8.7801 Acc: 0.8647
attribute accuracies
[0.78866667 0.74       0.73666667 0.874      0.484      0.336
 0.852      0.64866667 0.92533333 0.66866667 0.95266667 0.60933333]
Epoch 32/69
----------
train Loss: 0.4201 Attr Loss: 8.4656 Acc: 0.9005
attribute accuracies
[0.82132941 0.7396701  0.7603299  0.90008983 0.54585171 0.3748571
 0.87130492 0.69447166 0.94336926 0.70280091 0.97162339 0.66335946]
val Loss: 0.5343 Attr Loss: 8.7804 Acc: 0.8573
attribute accuracies
[0.792      0.74       0.73933333 0.876      0.48       0.358
 0.85266667 0.63933333 0.92533333 0.67       0.95266667 0.62466667]
Epoch 33/69
----------
train Loss: 0.3908 Attr Loss: 8.4395 Acc: 0.9049
attribute accuracies
[0.82137024 0.74048669 0.76028907 0.90017148 0.55046546 0.37804181
 0.8714274  0.6981055  0.9432876  0.70741467 0.97174588 0.66899396]
val Loss: 0.4069 Attr Loss: 8.6655 Acc: 0.8940
attribute accuracies
[0.79533333 0.74466667 0.74       0.87666667 0.49666667 0.35866667
 0.85333333 0.65133333 0.926      0.66733333 0.95266667 0.60866667]
Epoch 34/69
----------
train Loss: 0.3932 Attr Loss: 8.4021 Acc: 0.9063
attribute accuracies
[0.82222767 0.73958844 0.76041156 0.90021231 0.553691   0.37710273
 0.87130492 0.69982035 0.94320594 0.70574065 0.97166422 0.66825902]
val Loss: 0.4035 Attr Loss: 8.6369 Acc: 0.8893
attribute accuracies
[0.79466667 0.73533333 0.73933333 0.87466667 0.50466667 0.36933333
 0.85333333 0.65066667 0.92666667 0.66866667 0.95333333 0.61466667]
Epoch 35/69
----------
train Loss: 0.2097 Attr Loss: 8.2060 Acc: 0.9539
attribute accuracies
[0.82418749 0.744488   0.76090152 0.90017148 0.58141434 0.39494529
 0.87126409 0.70557733 0.94320594 0.71696881 0.97174588 0.68287604]
val Loss: 0.2013 Attr Loss: 8.4461 Acc: 0.9400
attribute accuracies
[0.796      0.74       0.74       0.876      0.532      0.36333333
 0.85733333 0.66733333 0.926      0.68133333 0.95266667 0.62733333]
Epoch 36/69
----------
train Loss: 0.1293 Attr Loss: 8.0739 Acc: 0.9754
attribute accuracies
[0.82553487 0.74955087 0.76175894 0.90021231 0.59860363 0.40135554
 0.87126409 0.71533562 0.94332843 0.72407317 0.97162339 0.69402254]
val Loss: 0.1813 Attr Loss: 8.3974 Acc: 0.9447
attribute accuracies
[0.79533333 0.74866667 0.74       0.874      0.53066667 0.37
 0.852      0.67       0.92866667 0.684      0.95333333 0.63066667]
Epoch 37/69
----------
train Loss: 0.1156 Attr Loss: 7.9924 Acc: 0.9774
attribute accuracies
[0.82602482 0.75244978 0.76302466 0.90037563 0.60685122 0.40503021
 0.87126409 0.71954107 0.9432876  0.72554303 0.97174588 0.69467581]
val Loss: 0.1738 Attr Loss: 8.3529 Acc: 0.9493
attribute accuracies
[0.798      0.74333333 0.742      0.87466667 0.53333333 0.37066667
 0.85266667 0.67133333 0.92866667 0.684      0.95266667 0.63933333]
Epoch 38/69
----------
train Loss: 0.1087 Attr Loss: 7.9356 Acc: 0.9810
attribute accuracies
[0.8277805  0.75334803 0.76331047 0.90000817 0.61346562 0.40866405
 0.8714274  0.71982688 0.94320594 0.73174914 0.97166422 0.70235179]
val Loss: 0.1740 Attr Loss: 8.3219 Acc: 0.9487
attribute accuracies
[0.80133333 0.74266667 0.74266667 0.876      0.538      0.36933333
 0.85466667 0.67133333 0.92733333 0.68666667 0.95333333 0.63866667]
Epoch 39/69
----------
train Loss: 0.1006 Attr Loss: 7.8805 Acc: 0.9825
attribute accuracies
[0.83010779 0.7570227  0.76384125 0.90017148 0.61897763 0.41168545
 0.87118243 0.7210926  0.94341009 0.73530132 0.97166422 0.70488323]
val Loss: 0.1766 Attr Loss: 8.3009 Acc: 0.9480
attribute accuracies
[0.80066667 0.74933333 0.73866667 0.876      0.53933333 0.37
 0.85266667 0.66866667 0.92533333 0.68333333 0.954      0.654     ]
Epoch 40/69
----------
train Loss: 0.0987 Attr Loss: 7.8228 Acc: 0.9839
attribute accuracies
[0.82908705 0.75804344 0.76408623 0.90029397 0.62771517 0.41634003
 0.87126409 0.72419566 0.94324677 0.73464805 0.97174588 0.709252  ]
val Loss: 0.1694 Attr Loss: 8.2324 Acc: 0.9480
attribute accuracies
[0.80066667 0.74533333 0.74266667 0.87533333 0.54266667 0.38333333
 0.856      0.674      0.92666667 0.68666667 0.95333333 0.64466667]
Epoch 41/69
----------
train Loss: 0.0964 Attr Loss: 7.7857 Acc: 0.9849
attribute accuracies
[0.83027111 0.75910501 0.76612772 0.90021231 0.63192063 0.41711579
 0.87134575 0.72795198 0.9432876  0.73860853 0.97178671 0.7103544 ]
val Loss: 0.1726 Attr Loss: 8.2311 Acc: 0.9507
attribute accuracies
[0.80066667 0.74866667 0.744      0.87466667 0.54733333 0.376
 0.85533333 0.67533333 0.92533333 0.68933333 0.954      0.64466667]
Epoch 42/69
----------
train Loss: 0.0950 Attr Loss: 7.7505 Acc: 0.9855
attribute accuracies
[0.83157766 0.76041156 0.76600523 0.90021231 0.63490119 0.41838151
 0.87126409 0.72497142 0.9432876  0.73844521 0.97162339 0.7096603 ]
val Loss: 0.1683 Attr Loss: 8.1815 Acc: 0.9527
attribute accuracies
[0.80533333 0.748      0.74666667 0.87466667 0.558      0.38266667
 0.854      0.67466667 0.92666667 0.694      0.95266667 0.64133333]
Epoch 43/69
----------
train Loss: 0.0939 Attr Loss: 7.7090 Acc: 0.9855
attribute accuracies
[0.82937286 0.76159562 0.76751592 0.90017148 0.64012739 0.42144374
 0.87122326 0.72693124 0.9432876  0.74293647 0.97166422 0.7125592 ]
val Loss: 0.1739 Attr Loss: 8.1829 Acc: 0.9487
attribute accuracies
[0.80666667 0.74666667 0.74666667 0.874      0.558      0.37733333
 0.85333333 0.68       0.92666667 0.692      0.95266667 0.65133333]
Epoch 44/69
----------
train Loss: 0.0908 Attr Loss: 7.6704 Acc: 0.9863
attribute accuracies
[0.83125102 0.76359628 0.76747509 0.90021231 0.64584354 0.4226278
 0.87118243 0.73227993 0.94320594 0.74485546 0.97166422 0.71460069]
val Loss: 0.1711 Attr Loss: 8.1251 Acc: 0.9513
attribute accuracies
[0.808      0.74866667 0.74733333 0.874      0.56133333 0.38666667
 0.85533333 0.67666667 0.928      0.69933333 0.95266667 0.652     ]
Epoch 45/69
----------
train Loss: 0.0892 Attr Loss: 7.6302 Acc: 0.9877
attribute accuracies
[0.83317001 0.76739343 0.76763841 0.90029397 0.64788502 0.42699657
 0.87126409 0.73121836 0.94320594 0.74640699 0.97166422 0.71525396]
val Loss: 0.1735 Attr Loss: 8.1094 Acc: 0.9500
attribute accuracies
[0.81133333 0.75133333 0.74733333 0.87533333 0.56533333 0.38666667
 0.85133333 0.67333333 0.92666667 0.69533333 0.95333333 0.65133333]
Epoch 46/69
----------
train Loss: 0.0916 Attr Loss: 7.5927 Acc: 0.9878
attribute accuracies
[0.83484403 0.76918994 0.76759758 0.9003348  0.65429528 0.42724155
 0.87130492 0.73436224 0.94332843 0.74767271 0.97166422 0.72248081]
val Loss: 0.1748 Attr Loss: 8.0870 Acc: 0.9500
attribute accuracies
[0.81       0.75133333 0.74733333 0.878      0.57733333 0.388
 0.85333333 0.67866667 0.926      0.70866667 0.95266667 0.65066667]
Epoch 47/69
----------
train Loss: 0.0955 Attr Loss: 7.5755 Acc: 0.9877
attribute accuracies
[0.83382329 0.77131308 0.76882247 0.90017148 0.65229463 0.43005879
 0.8714274  0.73040176 0.94332843 0.75216397 0.97166422 0.72154173]
val Loss: 0.1742 Attr Loss: 8.0493 Acc: 0.9487
attribute accuracies
[0.80733333 0.75066667 0.75066667 0.87533333 0.57066667 0.394
 0.85466667 0.68       0.926      0.70733333 0.95266667 0.652     ]
Epoch 48/69
----------
train Loss: 0.0883 Attr Loss: 7.5444 Acc: 0.9887
attribute accuracies
[0.83414993 0.77119059 0.77135391 0.90008983 0.65147803 0.43271272
 0.87122326 0.73281071 0.94341009 0.75461375 0.97166422 0.72292994]
val Loss: 0.1787 Attr Loss: 8.0255 Acc: 0.9480
attribute accuracies
[0.806      0.74866667 0.75266667 0.87733333 0.58466667 0.38533333
 0.85333333 0.67266667 0.926      0.70933333 0.95333333 0.66933333]
Epoch 49/69
----------
train Loss: 0.0860 Attr Loss: 7.5144 Acc: 0.9895
attribute accuracies
[0.83570145 0.77253797 0.77249714 0.90000817 0.66021558 0.43646905
 0.87134575 0.73717949 0.9432876  0.75191899 0.97162339 0.72431814]
val Loss: 0.1771 Attr Loss: 8.0101 Acc: 0.9473
attribute accuracies
[0.80666667 0.75333333 0.75266667 0.874      0.57466667 0.394
 0.85466667 0.678      0.92533333 0.71066667 0.95333333 0.66      ]
Epoch 50/69
----------
train Loss: 0.0896 Attr Loss: 7.4752 Acc: 0.9894
attribute accuracies
[0.83582394 0.77715172 0.77351788 0.90021231 0.66242038 0.43765311
 0.8711416  0.73497469 0.94336926 0.75408297 0.97170505 0.72844194]
val Loss: 0.1827 Attr Loss: 7.9934 Acc: 0.9500
attribute accuracies
[0.80466667 0.75533333 0.74733333 0.87533333 0.57733333 0.39866667
 0.852      0.67733333 0.92533333 0.71133333 0.95266667 0.65933333]
Epoch 51/69
----------
train Loss: 0.0928 Attr Loss: 7.4446 Acc: 0.9890
attribute accuracies
[0.83770211 0.77555937 0.77466111 0.90008983 0.66576841 0.44030704
 0.87134575 0.73754695 0.94316512 0.75653275 0.97166422 0.72819696]
val Loss: 0.1794 Attr Loss: 7.9678 Acc: 0.9493
attribute accuracies
[0.80466667 0.75266667 0.754      0.87533333 0.57933333 0.39533333
 0.85466667 0.674      0.92533333 0.71733333 0.954      0.67066667]
Epoch 52/69
----------
train Loss: 0.0892 Attr Loss: 7.4143 Acc: 0.9889
attribute accuracies
[0.83802874 0.77915238 0.77543688 0.90025314 0.67083129 0.44373673
 0.87146823 0.73807774 0.9432876  0.76110567 0.97174588 0.73125919]
val Loss: 0.1699 Attr Loss: 7.9182 Acc: 0.9513
attribute accuracies
[0.80533333 0.75266667 0.75466667 0.87666667 0.582      0.38933333
 0.85333333 0.688      0.92666667 0.70866667 0.95333333 0.67266667]
Epoch 53/69
----------
train Loss: 0.0908 Attr Loss: 7.3928 Acc: 0.9900
attribute accuracies
[0.83806957 0.77972399 0.7773967  0.90017148 0.67030051 0.44451249
 0.87130492 0.7407725  0.9432876  0.75824759 0.97174588 0.73089172]
val Loss: 0.1756 Attr Loss: 7.9062 Acc: 0.9533
attribute accuracies
[0.80733333 0.75066667 0.75266667 0.87533333 0.586      0.40266667
 0.85266667 0.68733333 0.92666667 0.712      0.95266667 0.67      ]
Epoch 54/69
----------
train Loss: 0.0890 Attr Loss: 7.3518 Acc: 0.9907
attribute accuracies
[0.838927   0.78049976 0.77804998 0.900049   0.67564919 0.44761555
 0.87118243 0.74330394 0.94332843 0.76412706 0.97170505 0.73477054]
val Loss: 0.1853 Attr Loss: 7.8797 Acc: 0.9507
attribute accuracies
[0.80533333 0.75866667 0.74866667 0.876      0.59       0.40266667
 0.85333333 0.682      0.92666667 0.71133333 0.95266667 0.66933333]
Epoch 55/69
----------
train Loss: 0.0893 Attr Loss: 7.3288 Acc: 0.9898
attribute accuracies
[0.83831455 0.78131635 0.77894823 0.90013065 0.67801731 0.44867712
 0.87134575 0.74342642 0.9432876  0.75955414 0.97170505 0.73338233]
val Loss: 0.1814 Attr Loss: 7.8560 Acc: 0.9540
attribute accuracies
[0.802      0.75666667 0.754      0.87466667 0.59733333 0.40266667
 0.856      0.68266667 0.926      0.71466667 0.95333333 0.67333333]
Epoch 56/69
----------
train Loss: 0.0917 Attr Loss: 7.3065 Acc: 0.9900
attribute accuracies
[0.83978442 0.78254124 0.77833578 0.90008983 0.67973216 0.4526376
 0.8711416  0.74326311 0.94332843 0.762943   0.97162339 0.73930263]
val Loss: 0.1803 Attr Loss: 7.8528 Acc: 0.9520
attribute accuracies
[0.804      0.75733333 0.752      0.87466667 0.58466667 0.40066667
 0.856      0.67866667 0.926      0.71666667 0.95266667 0.678     ]
Epoch 57/69
----------
train Loss: 0.0896 Attr Loss: 7.2708 Acc: 0.9903
attribute accuracies
[0.8411318  0.78388862 0.78229626 0.90013065 0.68504001 0.45320921
 0.87122326 0.74546791 0.94324677 0.76612772 0.97162339 0.73893516]
val Loss: 0.1820 Attr Loss: 7.8211 Acc: 0.9513
attribute accuracies
[0.80466667 0.75333333 0.756      0.87666667 0.59466667 0.41
 0.854      0.68733333 0.926      0.712      0.95266667 0.67066667]
Epoch 58/69
----------
train Loss: 0.0895 Attr Loss: 7.2444 Acc: 0.9904
attribute accuracies
[0.83998857 0.785236   0.78237792 0.900049   0.68646905 0.45582231
 0.87126409 0.74346725 0.94316512 0.76612772 0.97162339 0.74097665]
val Loss: 0.1858 Attr Loss: 7.8053 Acc: 0.9500
attribute accuracies
[0.80733333 0.75666667 0.754      0.876      0.58933333 0.402
 0.85333333 0.68933333 0.928      0.712      0.95333333 0.67733333]
Epoch 59/69
----------
train Loss: 0.0888 Attr Loss: 7.2148 Acc: 0.9911
attribute accuracies
[0.84011106 0.78646089 0.78417442 0.90025314 0.6881839  0.45631227
 0.87122326 0.7458762  0.94324677 0.76984321 0.97162339 0.73991507]
val Loss: 0.1861 Attr Loss: 7.7936 Acc: 0.9507
attribute accuracies
[0.80866667 0.75733333 0.75533333 0.876      0.60133333 0.408
 0.85466667 0.68133333 0.926      0.71666667 0.954      0.678     ]
Epoch 60/69
----------
train Loss: 0.0916 Attr Loss: 7.1861 Acc: 0.9902
attribute accuracies
[0.84231586 0.79168708 0.78490936 0.90021231 0.6892863  0.46223257
 0.87134575 0.74644782 0.94324677 0.77041483 0.97174588 0.7414666 ]
val Loss: 0.1789 Attr Loss: 7.7575 Acc: 0.9527
attribute accuracies
[0.814      0.75733333 0.76066667 0.87466667 0.59533333 0.41066667
 0.85666667 0.686      0.926      0.722      0.95266667 0.68266667]
Epoch 61/69
----------
train Loss: 0.0879 Attr Loss: 7.1569 Acc: 0.9917
attribute accuracies
[0.84300996 0.79148293 0.78695084 0.90013065 0.69292014 0.4614568
 0.87118243 0.74767271 0.94332843 0.77286461 0.97162339 0.74505961]
val Loss: 0.1827 Attr Loss: 7.7028 Acc: 0.9507
attribute accuracies
[0.806      0.76266667 0.758      0.87466667 0.61466667 0.414
 0.85333333 0.68733333 0.926      0.722      0.95466667 0.688     ]
Epoch 62/69
----------
train Loss: 0.0856 Attr Loss: 7.1215 Acc: 0.9915
attribute accuracies
[0.84296913 0.790748   0.78907398 0.90029397 0.69867712 0.46374326
 0.87118243 0.74828515 0.94324677 0.77457945 0.97166422 0.74689695]
val Loss: 0.1845 Attr Loss: 7.6964 Acc: 0.9533
attribute accuracies
[0.81533333 0.762      0.76333333 0.87333333 0.61266667 0.41
 0.854      0.69066667 0.92666667 0.724      0.95333333 0.682     ]
Epoch 63/69
----------
train Loss: 0.0906 Attr Loss: 7.1007 Acc: 0.9903
attribute accuracies
[0.84313245 0.79119713 0.78927813 0.90017148 0.70104524 0.46419239
 0.87118243 0.74665197 0.94341009 0.7769884  0.97170505 0.75016332]
val Loss: 0.1891 Attr Loss: 7.6952 Acc: 0.9547
attribute accuracies
[0.814      0.764      0.76333333 0.876      0.608      0.418
 0.85333333 0.68866667 0.92533333 0.726      0.95333333 0.686     ]
Epoch 64/69
----------
train Loss: 0.0851 Attr Loss: 7.0719 Acc: 0.9924
attribute accuracies
[0.84305079 0.79454516 0.79270782 0.900049   0.69798301 0.46733627
 0.8714274  0.75212314 0.94324677 0.77637596 0.97174588 0.75191899]
val Loss: 0.1883 Attr Loss: 7.6492 Acc: 0.9527
attribute accuracies
[0.816      0.76466667 0.76266667 0.87666667 0.61466667 0.41866667
 0.85466667 0.69       0.926      0.724      0.95333333 0.686     ]
Epoch 65/69
----------
train Loss: 0.0898 Attr Loss: 7.0558 Acc: 0.9908
attribute accuracies
[0.8440307  0.79617834 0.79479014 0.90017148 0.70190266 0.46794872
 0.87118243 0.75146987 0.94320594 0.77751919 0.97170505 0.75232729]
val Loss: 0.1895 Attr Loss: 7.6596 Acc: 0.9520
attribute accuracies
[0.80933333 0.76666667 0.76466667 0.87733333 0.61933333 0.424
 0.85333333 0.68466667 0.92733333 0.72533333 0.954      0.68733333]
Epoch 66/69
----------
train Loss: 0.0855 Attr Loss: 7.0075 Acc: 0.9922
attribute accuracies
[0.84680712 0.79572922 0.79283031 0.90017148 0.70578148 0.47239915
 0.87118243 0.75445043 0.94341009 0.78005063 0.97166422 0.75775764]
val Loss: 0.1739 Attr Loss: 7.6050 Acc: 0.9540
attribute accuracies
[0.80933333 0.76133333 0.76933333 0.87466667 0.62       0.41666667
 0.85333333 0.68866667 0.92533333 0.73066667 0.95266667 0.696     ]
Epoch 67/69
----------
train Loss: 0.0889 Attr Loss: 6.9953 Acc: 0.9915
attribute accuracies
[0.84480647 0.79813817 0.79662747 0.900049   0.70753715 0.47174588
 0.87130492 0.75587947 0.94320594 0.7844194  0.97166422 0.75559366]
val Loss: 0.1893 Attr Loss: 7.6054 Acc: 0.9507
attribute accuracies
[0.81533333 0.75866667 0.768      0.876      0.62133333 0.412
 0.854      0.69066667 0.92666667 0.722      0.95333333 0.69066667]
Epoch 68/69
----------
train Loss: 0.0859 Attr Loss: 6.9628 Acc: 0.9920
attribute accuracies
[0.8448473  0.7970766  0.7973624  0.90013065 0.71427405 0.47623714
 0.87122326 0.75971746 0.94320594 0.78123469 0.97174588 0.75886004]
val Loss: 0.1875 Attr Loss: 7.5797 Acc: 0.9500
attribute accuracies
[0.818      0.76866667 0.76533333 0.87666667 0.624      0.42133333
 0.85533333 0.7        0.92533333 0.732      0.95333333 0.69466667]
Epoch 69/69
----------
train Loss: 0.0894 Attr Loss: 6.9371 Acc: 0.9917
attribute accuracies
[0.84615385 0.80042463 0.79870978 0.90008983 0.71521313 0.47529806
 0.87118243 0.76037073 0.9432876  0.78568512 0.97166422 0.75955414]
val Loss: 0.1885 Attr Loss: 7.5557 Acc: 0.9487
attribute accuracies
[0.818      0.76133333 0.766      0.87533333 0.63133333 0.422
 0.85466667 0.696      0.926      0.72933333 0.95333333 0.69933333]
Training complete in 139m 15s
