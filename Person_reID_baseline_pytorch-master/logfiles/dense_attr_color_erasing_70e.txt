attribute_data.npy
Attributes verification.ipynb
demo.py
dense_attr_color_erasing_70e.txt
dense_attr_color_erasing.txt
dense_attr_color.txt
dense_attr_no_color.txt
dense_attr.txt
downcolor.npy
Ensembling experimentation.ipynb
evaluate_gpu.py
evaluate_int.py
evaluate.py
evaluate_rerank.py
extract.py
extract_tta.py
labels.npy
LICENSE
model
model.py
output_pcb_attr.txt
output_sat_color.txt
output_sat_erasing.txt
output_sat.txt
prepare.py
prepare_static.py
__pycache__
random_erasing.py
README.md
re_ranking.py
show.png
test.py
train_attr.py
train.jpg
train_pcb_attr.py
train_pcb_attr_resnet.py
train.py
tta_expermimenation.ipynb
tutorial
Untitled.ipynb
upcolor.npy
net output size:
torch.Size([8, 751])
0
[ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0), Resize(size=(288, 144), interpolation=PIL.Image.BICUBIC), RandomCrop(size=(256, 128), padding=0), RandomHorizontalFlip(p=0.5), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), <random_erasing.RandomErasing object at 0x7fe8d2a0f2e8>]
/opt/anaconda3/lib/python3.7/site-packages/torchvision-0.2.1-py3.7.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:14: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
  init.kaiming_normal(m.weight.data, a=0, mode='fan_out')
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:15: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(m.bias.data, 0.0)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:17: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.
  init.normal(m.weight.data, 1.0, 0.02)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:18: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(m.bias.data, 0.0)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:23: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.
  init.normal(m.weight.data, std=0.001)
/home/janardhan/AI_Person_ReID/Person_reID_baseline_pytorch-master/model.py:24: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.
  init.constant(m.bias.data, 0.0)
0.5942518711090088
attr_data.shape
torch.Size([1501, 12])
ft_attr_net_dense(
  (model): DenseNet(
    (features): Sequential(
      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu0): ReLU(inplace)
      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (denseblock1): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (transition1): _Transition(
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
      (denseblock2): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer7): _DenseLayer(
          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer8): _DenseLayer(
          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer9): _DenseLayer(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer10): _DenseLayer(
          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer11): _DenseLayer(
          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer12): _DenseLayer(
          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (transition2): _Transition(
        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
      (denseblock3): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer7): _DenseLayer(
          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer8): _DenseLayer(
          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer9): _DenseLayer(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer10): _DenseLayer(
          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer11): _DenseLayer(
          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer12): _DenseLayer(
          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer13): _DenseLayer(
          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer14): _DenseLayer(
          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer15): _DenseLayer(
          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer16): _DenseLayer(
          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer17): _DenseLayer(
          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer18): _DenseLayer(
          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer19): _DenseLayer(
          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer20): _DenseLayer(
          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer21): _DenseLayer(
          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer22): _DenseLayer(
          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer23): _DenseLayer(
          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer24): _DenseLayer(
          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (transition3): _Transition(
        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
      )
      (denseblock4): _DenseBlock(
        (denselayer1): _DenseLayer(
          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer2): _DenseLayer(
          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer3): _DenseLayer(
          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer4): _DenseLayer(
          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer5): _DenseLayer(
          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer6): _DenseLayer(
          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer7): _DenseLayer(
          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer8): _DenseLayer(
          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer9): _DenseLayer(
          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer10): _DenseLayer(
          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer11): _DenseLayer(
          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer12): _DenseLayer(
          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer13): _DenseLayer(
          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer14): _DenseLayer(
          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer15): _DenseLayer(
          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
        (denselayer16): _DenseLayer(
          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace)
          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace)
          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    )
    (classifier): Linear(in_features=1024, out_features=1000, bias=True)
    (fc): Sequential()
  )
  (classifier): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=1500, bias=True)
    )
  )
  (classifierage): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=4, bias=True)
    )
  )
  (classifierbackpack): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierbag): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierhandbag): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierdowncolor): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=9, bias=True)
    )
  )
  (classifierupcolor): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=8, bias=True)
    )
  )
  (classifierclothes): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierdown): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierup): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierhair): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifierhat): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (classifiergender): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1024, out_features=512, bias=True)
      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): LeakyReLU(negative_slope=0.1)
      (3): Dropout(p=0.5)
    )
    (classifier): Sequential(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
)
Epoch 0/69
----------
train Loss: 4.7524 Attr Loss: 8.1669 Acc: 0.1906
attribute accuracies
[0.81030541 0.73191246 0.76408623 0.89212804 0.43748979 0.29793402
 0.87726605 0.6292667  0.94692144 0.6559693  0.97084762 0.57284011]
val Loss: 2.9394 Attr Loss: 7.9281 Acc: 0.3753
attribute accuracies
[0.79266667 0.72866667 0.74       0.87466667 0.42933333 0.296
 0.854      0.616      0.92666667 0.644      0.95333333 0.56533333]
Epoch 1/69
----------
train Loss: 2.1057 Attr Loss: 7.9469 Acc: 0.5160
attribute accuracies
[0.81177527 0.73276988 0.76522946 0.89314878 0.43985791 0.31144864
 0.87796015 0.63192063 0.94790136 0.6592765  0.97252164 0.59166258]
val Loss: 1.6312 Attr Loss: 7.8913 Acc: 0.6033
attribute accuracies
[0.79       0.73066667 0.738      0.87466667 0.42866667 0.298
 0.85333333 0.61733333 0.926      0.64733333 0.95266667 0.578     ]
Epoch 2/69
----------
train Loss: 1.3500 Attr Loss: 7.8715 Acc: 0.6634
attribute accuracies
[0.81177527 0.73297403 0.76604606 0.89314878 0.44181774 0.32022701
 0.87791932 0.63579944 0.94802384 0.66323698 0.97252164 0.6040748 ]
val Loss: 1.1461 Attr Loss: 7.8447 Acc: 0.7113
attribute accuracies
[0.792      0.72666667 0.73733333 0.87533333 0.43066667 0.296
 0.85533333 0.61866667 0.926      0.646      0.95333333 0.58466667]
Epoch 3/69
----------
train Loss: 1.0638 Attr Loss: 7.8186 Acc: 0.7292
attribute accuracies
[0.81197942 0.73309652 0.76547444 0.89318961 0.4425935  0.324065
 0.87783766 0.6369835  0.9478197  0.66646252 0.97243998 0.60676956]
val Loss: 0.8858 Attr Loss: 7.8259 Acc: 0.7587
attribute accuracies
[0.78933333 0.734      0.736      0.874      0.428      0.30933333
 0.85266667 0.622      0.92666667 0.64333333 0.95266667 0.59      ]
Epoch 4/69
----------
train Loss: 0.8485 Attr Loss: 7.7776 Acc: 0.7838
attribute accuracies
[0.8118161  0.73325984 0.76584191 0.89310795 0.44210354 0.32900539
 0.87779683 0.63506451 0.94794219 0.6674016  0.97248081 0.61620121]
val Loss: 0.7474 Attr Loss: 7.7770 Acc: 0.7993
attribute accuracies
[0.79066667 0.72733333 0.74133333 0.876      0.43133333 0.31
 0.85466667 0.62       0.92733333 0.65533333 0.95266667 0.59533333]
Epoch 5/69
----------
train Loss: 0.7385 Attr Loss: 7.7427 Acc: 0.8111
attribute accuracies
[0.81177527 0.73366814 0.76604606 0.89306712 0.44320594 0.33100604
 0.87787849 0.64082149 0.94786053 0.67156623 0.97243998 0.62163155]
val Loss: 0.8218 Attr Loss: 7.8128 Acc: 0.7700
attribute accuracies
[0.78866667 0.72933333 0.73666667 0.874      0.42733333 0.308
 0.854      0.62266667 0.92533333 0.654      0.95266667 0.588     ]
Epoch 6/69
----------
train Loss: 0.6648 Attr Loss: 7.7061 Acc: 0.8328
attribute accuracies
[0.81169361 0.73342316 0.76576025 0.89302629 0.44439    0.33745713
 0.87791932 0.64188306 0.94790136 0.67160706 0.97252164 0.62922587]
val Loss: 0.5943 Attr Loss: 7.7522 Acc: 0.8413
attribute accuracies
[0.78933333 0.72933333 0.74       0.87466667 0.42933333 0.31933333
 0.85333333 0.63066667 0.926      0.65       0.95333333 0.59733333]
Epoch 7/69
----------
train Loss: 0.6056 Attr Loss: 7.6778 Acc: 0.8462
attribute accuracies
[0.81169361 0.73305569 0.76620937 0.89298546 0.44496162 0.33623224
 0.87800098 0.64404704 0.94790136 0.67434264 0.97248081 0.63481953]
val Loss: 0.5950 Attr Loss: 7.7353 Acc: 0.8333
attribute accuracies
[0.79133333 0.72733333 0.74066667 0.876      0.42933333 0.31733333
 0.854      0.62466667 0.92666667 0.646      0.95333333 0.608     ]
Epoch 8/69
----------
train Loss: 0.5701 Attr Loss: 7.6473 Acc: 0.8585
attribute accuracies
[0.81202025 0.73362731 0.76649518 0.89310795 0.44651315 0.34447983
 0.87800098 0.64653764 0.94794219 0.67846644 0.97248081 0.64396538]
val Loss: 0.5928 Attr Loss: 7.7769 Acc: 0.8420
attribute accuracies
[0.788      0.72866667 0.74066667 0.87333333 0.42533333 0.32066667
 0.85266667 0.62       0.926      0.64866667 0.95266667 0.604     ]
Epoch 9/69
----------
train Loss: 0.5399 Attr Loss: 7.6157 Acc: 0.8653
attribute accuracies
[0.81189776 0.7340356  0.76620937 0.89306712 0.44663564 0.34897109
 0.877756   0.64649682 0.94794219 0.68079373 0.97252164 0.6522538 ]
val Loss: 0.6809 Attr Loss: 7.7265 Acc: 0.8240
attribute accuracies
[0.792      0.72866667 0.738      0.876      0.43066667 0.324
 0.85333333 0.63466667 0.92666667 0.65333333 0.954      0.60466667]
Epoch 10/69
----------
train Loss: 0.5312 Attr Loss: 7.5944 Acc: 0.8680
attribute accuracies
[0.81173444 0.73395394 0.76633186 0.89306712 0.44875878 0.35019598
 0.87787849 0.64894659 0.94786053 0.68058958 0.97243998 0.65017148]
val Loss: 0.5303 Attr Loss: 7.6933 Acc: 0.8520
attribute accuracies
[0.79       0.73266667 0.73733333 0.876      0.43533333 0.32266667
 0.85333333 0.63       0.926      0.65733333 0.95333333 0.60333333]
Epoch 11/69
----------
train Loss: 0.4938 Attr Loss: 7.5620 Acc: 0.8791
attribute accuracies
[0.81169361 0.7340356  0.76669933 0.89310795 0.45227013 0.35436061
 0.87796015 0.65123306 0.94786053 0.68475421 0.97252164 0.66050139]
val Loss: 0.5447 Attr Loss: 7.6919 Acc: 0.8453
attribute accuracies
[0.79       0.73       0.73666667 0.87466667 0.42666667 0.332
 0.854      0.64266667 0.928      0.66533333 0.954      0.606     ]
Epoch 12/69
----------
train Loss: 0.4611 Attr Loss: 7.5359 Acc: 0.8869
attribute accuracies
[0.81173444 0.7344439  0.7659644  0.89318961 0.45533235 0.35774947
 0.87779683 0.65458109 0.94794219 0.68802058 0.97243998 0.66499265]
val Loss: 0.5358 Attr Loss: 7.6619 Acc: 0.8580
attribute accuracies
[0.79133333 0.732      0.73733333 0.87466667 0.42933333 0.32666667
 0.85333333 0.63266667 0.92666667 0.65666667 0.95333333 0.61333333]
Epoch 13/69
----------
train Loss: 0.4819 Attr Loss: 7.5147 Acc: 0.8823
attribute accuracies
[0.8118161  0.73452556 0.76669933 0.89306712 0.45912951 0.36130165
 0.87791932 0.65302956 0.94806467 0.68699984 0.97248081 0.66695247]
val Loss: 0.5065 Attr Loss: 7.6348 Acc: 0.8600
attribute accuracies
[0.79133333 0.728      0.738      0.878      0.43933333 0.32466667
 0.85266667 0.62866667 0.92533333 0.66266667 0.95333333 0.626     ]
Epoch 14/69
----------
train Loss: 0.4412 Attr Loss: 7.4941 Acc: 0.8927
attribute accuracies
[0.81177527 0.73379063 0.76641352 0.89318961 0.46166095 0.36093418
 0.877756   0.65588764 0.94790136 0.69226686 0.97248081 0.66952474]
val Loss: 0.5014 Attr Loss: 7.6174 Acc: 0.8713
attribute accuracies
[0.792      0.728      0.74       0.87733333 0.44       0.33133333
 0.85333333 0.64933333 0.92666667 0.672      0.95333333 0.62866667]
Epoch 15/69
----------
train Loss: 0.4304 Attr Loss: 7.4787 Acc: 0.8966
attribute accuracies
[0.81165278 0.73366814 0.7659644  0.89310795 0.46484566 0.36624204
 0.87783766 0.65747999 0.94794219 0.69500245 0.97256247 0.67528172]
val Loss: 0.4735 Attr Loss: 7.6420 Acc: 0.8793
attribute accuracies
[0.79133333 0.72933333 0.74133333 0.876      0.44       0.33733333
 0.85333333 0.65133333 0.92666667 0.65533333 0.95333333 0.62533333]
Epoch 16/69
----------
train Loss: 0.4213 Attr Loss: 7.4573 Acc: 0.8971
attribute accuracies
[0.8118161  0.73395394 0.76608689 0.89310795 0.46647885 0.36775274
 0.87804181 0.66254287 0.94794219 0.69451249 0.97252164 0.67160706]
val Loss: 0.4628 Attr Loss: 7.5959 Acc: 0.8760
attribute accuracies
[0.78866667 0.73133333 0.73866667 0.87333333 0.44066667 0.34466667
 0.854      0.64333333 0.926      0.66533333 0.95266667 0.632     ]
Epoch 17/69
----------
train Loss: 0.4329 Attr Loss: 7.4440 Acc: 0.8954
attribute accuracies
[0.81185693 0.73313735 0.76559693 0.89310795 0.47125592 0.37122326
 0.87796015 0.66184877 0.9478197  0.69859546 0.97248081 0.67466928]
val Loss: 0.4599 Attr Loss: 7.6129 Acc: 0.8833
attribute accuracies
[0.79       0.73       0.73866667 0.87666667 0.44       0.34466667
 0.854      0.64533333 0.926      0.66533333 0.95266667 0.62066667]
Epoch 18/69
----------
train Loss: 0.4076 Attr Loss: 7.4258 Acc: 0.9034
attribute accuracies
[0.81189776 0.7337498  0.76592357 0.89306712 0.47227666 0.37747019
 0.87783766 0.66025641 0.94802384 0.70018782 0.97252164 0.67540421]
val Loss: 0.4939 Attr Loss: 7.6210 Acc: 0.8713
attribute accuracies
[0.788      0.72933333 0.73933333 0.87466667 0.45066667 0.33866667
 0.85466667 0.63866667 0.92666667 0.68       0.95333333 0.622     ]
Epoch 19/69
----------
train Loss: 0.3966 Attr Loss: 7.4207 Acc: 0.9072
attribute accuracies
[0.81189776 0.73370897 0.76567859 0.89306712 0.472195   0.37457129
 0.877756   0.66495182 0.9478197  0.70010616 0.97243998 0.67899722]
val Loss: 0.3803 Attr Loss: 7.5865 Acc: 0.9013
attribute accuracies
[0.79       0.72933333 0.73666667 0.876      0.44266667 0.34866667
 0.85266667 0.63266667 0.92666667 0.68       0.95266667 0.63866667]
Epoch 20/69
----------
train Loss: 0.3930 Attr Loss: 7.3999 Acc: 0.9061
attribute accuracies
[0.81197942 0.73330067 0.76567859 0.89318961 0.47337906 0.38024661
 0.87796015 0.66981055 0.94790136 0.70941532 0.97243998 0.67960967]
val Loss: 0.5389 Attr Loss: 7.5941 Acc: 0.8560
attribute accuracies
[0.79133333 0.73066667 0.73933333 0.876      0.442      0.34133333
 0.85333333 0.636      0.92733333 0.672      0.95266667 0.634     ]
Epoch 21/69
----------
train Loss: 0.3900 Attr Loss: 7.3895 Acc: 0.9087
attribute accuracies
[0.81197942 0.73330067 0.76580108 0.89306712 0.47517557 0.38453373
 0.8781643  0.66993304 0.94790136 0.70868039 0.97252164 0.68071207]
val Loss: 0.4317 Attr Loss: 7.5547 Acc: 0.8800
attribute accuracies
[0.78933333 0.728      0.74266667 0.876      0.45       0.34533333
 0.85533333 0.638      0.926      0.67666667 0.95333333 0.63133333]
Epoch 22/69
----------
train Loss: 0.3765 Attr Loss: 7.3792 Acc: 0.9134
attribute accuracies
[0.81230606 0.73313735 0.76563776 0.89318961 0.47599216 0.38159399
 0.87783766 0.67013719 0.94802384 0.709252   0.97252164 0.68450923]
val Loss: 0.4966 Attr Loss: 7.5745 Acc: 0.8720
attribute accuracies
[0.792      0.728      0.74       0.876      0.45266667 0.35533333
 0.85466667 0.64       0.92666667 0.67533333 0.95333333 0.63      ]
Epoch 23/69
----------
train Loss: 0.3771 Attr Loss: 7.3751 Acc: 0.9097
attribute accuracies
[0.81210191 0.73399477 0.76584191 0.89318961 0.4774212  0.38016495
 0.87796015 0.67487343 0.9478197  0.71006859 0.97243998 0.68414176]
val Loss: 0.4256 Attr Loss: 7.5328 Acc: 0.8887
attribute accuracies
[0.79       0.72933333 0.73733333 0.87466667 0.452      0.35
 0.854      0.64733333 0.92666667 0.67466667 0.95333333 0.64      ]
Epoch 24/69
----------
train Loss: 0.3581 Attr Loss: 7.3583 Acc: 0.9181
attribute accuracies
[0.8126327  0.7337498  0.76580108 0.89314878 0.47799281 0.38355381
 0.87779683 0.67520007 0.94786053 0.71231423 0.97243998 0.68704067]
val Loss: 0.4255 Attr Loss: 7.5470 Acc: 0.8880
attribute accuracies
[0.79133333 0.72866667 0.73933333 0.87533333 0.452      0.35466667
 0.85333333 0.65933333 0.926      0.67666667 0.95266667 0.64266667]
Epoch 25/69
----------
train Loss: 0.3653 Attr Loss: 7.3509 Acc: 0.9142
attribute accuracies
[0.81214274 0.73481137 0.76604606 0.89314878 0.47901356 0.38547281
 0.87791932 0.67242365 0.9478197  0.71725461 0.97252164 0.68904132]
val Loss: 0.4543 Attr Loss: 7.5644 Acc: 0.8827
attribute accuracies
[0.79       0.72933333 0.73733333 0.876      0.456      0.35533333
 0.85533333 0.636      0.92533333 0.67733333 0.954      0.62866667]
Epoch 26/69
----------
train Loss: 0.3695 Attr Loss: 7.3396 Acc: 0.9150
attribute accuracies
[0.8126327  0.73468888 0.7659644  0.89318961 0.48134085 0.3918014
 0.87787849 0.67858893 0.94794219 0.71594806 0.97243998 0.68638739]
val Loss: 0.4785 Attr Loss: 7.5485 Acc: 0.8753
attribute accuracies
[0.79       0.73266667 0.738      0.87466667 0.454      0.35533333
 0.852      0.65066667 0.926      0.68466667 0.95266667 0.63133333]
Epoch 27/69
----------
train Loss: 0.3640 Attr Loss: 7.3342 Acc: 0.9156
attribute accuracies
[0.81300016 0.73358648 0.76592357 0.89298546 0.48052425 0.38902499
 0.87791932 0.67920137 0.94794219 0.71643802 0.97248081 0.68879634]
val Loss: 0.4543 Attr Loss: 7.5188 Acc: 0.8847
attribute accuracies
[0.79       0.728      0.74066667 0.876      0.45266667 0.35066667
 0.854      0.65266667 0.92666667 0.68533333 0.95333333 0.63733333]
Epoch 28/69
----------
train Loss: 0.3682 Attr Loss: 7.3267 Acc: 0.9152
attribute accuracies
[0.81295933 0.73383146 0.76588274 0.89306712 0.48101421 0.39216887
 0.877756   0.68328434 0.9478197  0.71807121 0.97248081 0.68789809]
val Loss: 0.4295 Attr Loss: 7.5050 Acc: 0.8873
attribute accuracies
[0.79066667 0.72866667 0.73866667 0.87733333 0.452      0.344
 0.85266667 0.65       0.92666667 0.67933333 0.95333333 0.64666667]
Epoch 29/69
----------
train Loss: 0.3483 Attr Loss: 7.3070 Acc: 0.9167
attribute accuracies
[0.81369427 0.735138   0.76567859 0.8933121  0.48428058 0.3937204
 0.87787849 0.68079373 0.9478197  0.71770374 0.97248081 0.68883717]
val Loss: 0.4134 Attr Loss: 7.5174 Acc: 0.8860
attribute accuracies
[0.79333333 0.73       0.73933333 0.874      0.46133333 0.34733333
 0.852      0.64       0.926      0.67733333 0.95266667 0.644     ]
Epoch 30/69
----------
train Loss: 0.3619 Attr Loss: 7.2928 Acc: 0.9165
attribute accuracies
[0.81487833 0.73579128 0.76576025 0.89310795 0.48489303 0.39543524
 0.87787849 0.68030377 0.94786053 0.72346072 0.97256247 0.69439   ]
val Loss: 0.4240 Attr Loss: 7.5164 Acc: 0.8913
attribute accuracies
[0.79       0.73       0.74       0.87466667 0.46333333 0.352
 0.854      0.64866667 0.92666667 0.67466667 0.95266667 0.64333333]
Epoch 31/69
----------
train Loss: 0.3282 Attr Loss: 7.2728 Acc: 0.9265
attribute accuracies
[0.81393925 0.7355463  0.76612772 0.89314878 0.48905765 0.39759922
 0.87804181 0.68112037 0.94786053 0.72309325 0.97243998 0.69822799]
val Loss: 0.4399 Attr Loss: 7.5380 Acc: 0.8987
attribute accuracies
[0.79333333 0.732      0.73733333 0.876      0.448      0.35666667
 0.852      0.65733333 0.926      0.67133333 0.95266667 0.63133333]
Epoch 32/69
----------
train Loss: 0.3492 Attr Loss: 7.2572 Acc: 0.9196
attribute accuracies
[0.8144292  0.73603626 0.76714846 0.89298546 0.48852687 0.39670096
 0.87783766 0.68724481 0.94794219 0.72460395 0.97243998 0.69720725]
val Loss: 0.4293 Attr Loss: 7.5177 Acc: 0.8833
attribute accuracies
[0.78933333 0.73333333 0.73666667 0.876      0.462      0.37266667
 0.85333333 0.662      0.92666667 0.69       0.95266667 0.64666667]
Epoch 33/69
----------
train Loss: 0.3301 Attr Loss: 7.2472 Acc: 0.9257
attribute accuracies
[0.8144292  0.73607709 0.76645435 0.89306712 0.49060918 0.40421362
 0.87791932 0.69042953 0.94790136 0.72680875 0.97248081 0.69900376]
val Loss: 0.4868 Attr Loss: 7.5029 Acc: 0.8760
attribute accuracies
[0.794      0.73066667 0.74       0.87666667 0.45933333 0.34533333
 0.85466667 0.64933333 0.926      0.68266667 0.95266667 0.64266667]
Epoch 34/69
----------
train Loss: 0.3475 Attr Loss: 7.2329 Acc: 0.9197
attribute accuracies
[0.81536828 0.73681202 0.76600523 0.8933121  0.49162992 0.40241712
 0.87779683 0.68691818 0.94790136 0.73191246 0.97248081 0.70467908]
val Loss: 0.4020 Attr Loss: 7.4788 Acc: 0.8980
attribute accuracies
[0.798      0.73133333 0.73866667 0.876      0.45933333 0.35533333
 0.85266667 0.66266667 0.928      0.682      0.95333333 0.648     ]
Epoch 35/69
----------
train Loss: 0.3332 Attr Loss: 7.2149 Acc: 0.9241
attribute accuracies
[0.8155316  0.73820023 0.76698514 0.89310795 0.49350808 0.40560183
 0.87791932 0.69087865 0.94794219 0.73019762 0.97243998 0.70480157]
val Loss: 0.4784 Attr Loss: 7.5069 Acc: 0.8773
attribute accuracies
[0.79533333 0.736      0.74       0.87533333 0.442      0.352
 0.85466667 0.65466667 0.92733333 0.684      0.95266667 0.654     ]
Epoch 36/69
----------
train Loss: 0.3172 Attr Loss: 7.2123 Acc: 0.9283
attribute accuracies
[0.8159399  0.73909848 0.76792422 0.89306712 0.49285481 0.40601013
 0.87791932 0.6903887  0.94794219 0.73056508 0.97252164 0.70431161]
val Loss: 0.4033 Attr Loss: 7.4486 Acc: 0.8880
attribute accuracies
[0.796      0.736      0.73933333 0.87533333 0.45266667 0.35533333
 0.854      0.64466667 0.92533333 0.688      0.95333333 0.646     ]
Epoch 37/69
----------
train Loss: 0.3296 Attr Loss: 7.1982 Acc: 0.9239
attribute accuracies
[0.81655234 0.73942512 0.7677609  0.89323044 0.49473297 0.40731667
 0.87791932 0.69459415 0.9478197  0.73138168 0.97252164 0.70574065]
val Loss: 0.3960 Attr Loss: 7.4259 Acc: 0.8967
attribute accuracies
[0.79533333 0.73266667 0.736      0.874      0.47133333 0.35866667
 0.85266667 0.658      0.926      0.70066667 0.95333333 0.64666667]
Epoch 38/69
----------
train Loss: 0.3135 Attr Loss: 7.1648 Acc: 0.9276
attribute accuracies
[0.81581741 0.73848604 0.76751592 0.89306712 0.49697861 0.40943982
 0.87787849 0.69385922 0.9478197  0.73562796 0.97243998 0.71170178]
val Loss: 0.4232 Attr Loss: 7.4377 Acc: 0.8833
attribute accuracies
[0.80066667 0.72866667 0.74133333 0.87666667 0.45466667 0.37666667
 0.85333333 0.67333333 0.926      0.69466667 0.95333333 0.65      ]
Epoch 39/69
----------
train Loss: 0.3416 Attr Loss: 7.1569 Acc: 0.9215
attribute accuracies
[0.81724645 0.74101748 0.76796505 0.89318961 0.49636616 0.41115466
 0.87783766 0.69516577 0.94794219 0.73893516 0.97252164 0.71043606]
val Loss: 0.4027 Attr Loss: 7.4419 Acc: 0.8967
attribute accuracies
[0.794      0.732      0.744      0.874      0.46933333 0.35933333
 0.854      0.66866667 0.92666667 0.69666667 0.95266667 0.662     ]
Epoch 40/69
----------
train Loss: 0.1524 Attr Loss: 7.0174 Acc: 0.9694
attribute accuracies
[0.8192471  0.74301813 0.76918994 0.89294463 0.5122489  0.42638413
 0.87779683 0.70851707 0.94786053 0.75171485 0.97243998 0.7281153 ]
val Loss: 0.2036 Attr Loss: 7.2832 Acc: 0.9467
attribute accuracies
[0.79733333 0.73533333 0.742      0.87466667 0.48333333 0.38
 0.854      0.682      0.926      0.71133333 0.95266667 0.67933333]
Epoch 41/69
----------
train Loss: 0.0999 Attr Loss: 6.9155 Acc: 0.9824
attribute accuracies
[0.82137024 0.74469214 0.76959824 0.89302629 0.5199657  0.43434591
 0.87783766 0.71619304 0.94786053 0.75959497 0.97252164 0.73950678]
val Loss: 0.1924 Attr Loss: 7.2295 Acc: 0.9493
attribute accuracies
[0.80333333 0.738      0.74333333 0.876      0.484      0.384
 0.854      0.68       0.926      0.714      0.95333333 0.688     ]
Epoch 42/69
----------
train Loss: 0.0887 Attr Loss: 6.8554 Acc: 0.9847
attribute accuracies
[0.82275845 0.74828515 0.77070064 0.89306712 0.52413033 0.4410828
 0.87787849 0.72231749 0.94794219 0.76539278 0.97252164 0.74175241]
val Loss: 0.1811 Attr Loss: 7.1877 Acc: 0.9507
attribute accuracies
[0.79866667 0.73733333 0.74266667 0.87666667 0.50066667 0.39466667
 0.85466667 0.684      0.92666667 0.714      0.95266667 0.69066667]
Epoch 43/69
----------
train Loss: 0.0796 Attr Loss: 6.8130 Acc: 0.9879
attribute accuracies
[0.82569819 0.75044913 0.77229299 0.89314878 0.53299036 0.4403887
 0.87796015 0.72546138 0.9478197  0.76914911 0.97243998 0.74755022]
val Loss: 0.1806 Attr Loss: 7.1725 Acc: 0.9487
attribute accuracies
[0.80133333 0.73666667 0.74266667 0.874      0.49733333 0.382
 0.85466667 0.69       0.926      0.71666667 0.95266667 0.68933333]
Epoch 44/69
----------
train Loss: 0.0764 Attr Loss: 6.7626 Acc: 0.9882
attribute accuracies
[0.82635146 0.75106157 0.7725788  0.89314878 0.53466438 0.44790136
 0.87791932 0.72697207 0.94786053 0.77470194 0.97243998 0.75171485]
val Loss: 0.1802 Attr Loss: 7.1448 Acc: 0.9500
attribute accuracies
[0.79866667 0.74066667 0.742      0.874      0.498      0.384
 0.85533333 0.684      0.92666667 0.718      0.95333333 0.692     ]
Epoch 45/69
----------
train Loss: 0.0790 Attr Loss: 6.7347 Acc: 0.9879
attribute accuracies
[0.82696391 0.75428711 0.77474277 0.89306712 0.53580761 0.45055528
 0.87783766 0.73236159 0.94786053 0.77511024 0.97248081 0.75236812]
val Loss: 0.1765 Attr Loss: 7.1000 Acc: 0.9520
attribute accuracies
[0.802      0.73933333 0.744      0.876      0.5        0.39266667
 0.854      0.692      0.92533333 0.71533333 0.95333333 0.68866667]
Epoch 46/69
----------
train Loss: 0.0759 Attr Loss: 6.7003 Acc: 0.9893
attribute accuracies
[0.82839294 0.75498122 0.77445697 0.89310795 0.54319778 0.45353585
 0.87791932 0.73411726 0.94786053 0.77547771 0.97252164 0.75918667]
val Loss: 0.1808 Attr Loss: 7.0959 Acc: 0.9527
attribute accuracies
[0.80333333 0.736      0.744      0.87733333 0.50133333 0.39466667
 0.85533333 0.694      0.926      0.72133333 0.95333333 0.69666667]
Epoch 47/69
----------
train Loss: 0.0753 Attr Loss: 6.6700 Acc: 0.9900
attribute accuracies
[0.82876041 0.75759432 0.7756002  0.89298546 0.54303446 0.46137514
 0.87771517 0.73236159 0.9478197  0.7789074  0.97243998 0.76037073]
val Loss: 0.1733 Attr Loss: 7.0710 Acc: 0.9533
attribute accuracies
[0.808      0.74066667 0.74266667 0.876      0.50133333 0.39333333
 0.856      0.684      0.926      0.72933333 0.95266667 0.70266667]
Epoch 48/69
----------
train Loss: 0.0744 Attr Loss: 6.6465 Acc: 0.9907
attribute accuracies
[0.83027111 0.75910501 0.775886   0.89306712 0.54683162 0.45786379
 0.87787849 0.73795525 0.9478197  0.78311285 0.97248081 0.76204475]
val Loss: 0.1806 Attr Loss: 7.0561 Acc: 0.9527
attribute accuracies
[0.80733333 0.73666667 0.74666667 0.87466667 0.50466667 0.39466667
 0.85333333 0.69066667 0.928      0.72333333 0.95266667 0.7       ]
Epoch 49/69
----------
train Loss: 0.0748 Attr Loss: 6.6167 Acc: 0.9904
attribute accuracies
[0.83121019 0.75983995 0.77751919 0.89318961 0.54850563 0.45912951
 0.87804181 0.74183407 0.94794219 0.78727748 0.97252164 0.76543361]
val Loss: 0.1824 Attr Loss: 7.0440 Acc: 0.9513
attribute accuracies
[0.808      0.742      0.74466667 0.87466667 0.508      0.396
 0.85266667 0.68866667 0.92666667 0.72266667 0.95333333 0.70133333]
Epoch 50/69
----------
train Loss: 0.0745 Attr Loss: 6.5769 Acc: 0.9913
attribute accuracies
[0.83080189 0.76343296 0.77988731 0.89318961 0.55544668 0.46333497
 0.87812347 0.74162992 0.94790136 0.78788992 0.97248081 0.76939409]
val Loss: 0.1685 Attr Loss: 7.0205 Acc: 0.9527
attribute accuracies
[0.808      0.73933333 0.74866667 0.87533333 0.506      0.394
 0.85333333 0.68533333 0.92666667 0.71733333 0.95333333 0.69066667]
Epoch 51/69
----------
train Loss: 0.0755 Attr Loss: 6.5578 Acc: 0.9919
attribute accuracies
[0.83239425 0.76420872 0.78033644 0.89335293 0.55654908 0.46480483
 0.87791932 0.7414666  0.9478197  0.79009472 0.97248081 0.77119059]
val Loss: 0.1750 Attr Loss: 7.0080 Acc: 0.9533
attribute accuracies
[0.80533333 0.74666667 0.744      0.87466667 0.518      0.40066667
 0.85266667 0.68933333 0.92533333 0.728      0.95266667 0.69666667]
Epoch 52/69
----------
train Loss: 0.0759 Attr Loss: 6.5307 Acc: 0.9912
attribute accuracies
[0.83627307 0.76576025 0.78135718 0.89306712 0.55618161 0.46811204
 0.87787849 0.74461049 0.94790136 0.79070717 0.97243998 0.7699657 ]
val Loss: 0.1792 Attr Loss: 7.0000 Acc: 0.9527
attribute accuracies
[0.80533333 0.74133333 0.74266667 0.874      0.51933333 0.398
 0.854      0.69733333 0.92533333 0.72733333 0.95266667 0.702     ]
Epoch 53/69
----------
train Loss: 0.0770 Attr Loss: 6.5082 Acc: 0.9916
attribute accuracies
[0.83635473 0.76878164 0.78209211 0.89302629 0.5607137  0.47158256
 0.87791932 0.74661114 0.9478197  0.79421852 0.97248081 0.77457945]
val Loss: 0.1845 Attr Loss: 6.9814 Acc: 0.9533
attribute accuracies
[0.80533333 0.742      0.74133333 0.87533333 0.51333333 0.4
 0.85333333 0.69       0.92666667 0.72666667 0.95333333 0.70066667]
Epoch 54/69
----------
train Loss: 0.0778 Attr Loss: 6.4858 Acc: 0.9912
attribute accuracies
[0.83533399 0.770374   0.78286788 0.89314878 0.56161195 0.47272579
 0.87791932 0.74734607 0.94794219 0.79229953 0.97252164 0.77086396]
val Loss: 0.1833 Attr Loss: 6.9535 Acc: 0.9533
attribute accuracies
[0.806      0.744      0.74266667 0.87533333 0.52533333 0.40466667
 0.85333333 0.69       0.92533333 0.73466667 0.95333333 0.69866667]
Epoch 55/69
----------
train Loss: 0.0763 Attr Loss: 6.4596 Acc: 0.9918
attribute accuracies
[0.83586477 0.77114976 0.78548097 0.89306712 0.56904295 0.4732974
 0.87779683 0.74612118 0.94790136 0.79568839 0.97248081 0.77413033]
val Loss: 0.1838 Attr Loss: 6.9259 Acc: 0.9547
attribute accuracies
[0.81133333 0.746      0.74533333 0.87533333 0.51933333 0.406
 0.854      0.69933333 0.926      0.74466667 0.95333333 0.70533333]
Epoch 56/69
----------
train Loss: 0.0749 Attr Loss: 6.4310 Acc: 0.9925
attribute accuracies
[0.83704883 0.77543688 0.7870325  0.89323044 0.56724645 0.47827862
 0.87791932 0.74934673 0.94786053 0.80091458 0.97248081 0.78058141]
val Loss: 0.1850 Attr Loss: 6.9011 Acc: 0.9540
attribute accuracies
[0.80933333 0.746      0.74733333 0.87333333 0.528      0.41066667
 0.85666667 0.696      0.92666667 0.73266667 0.95333333 0.704     ]
Epoch 57/69
----------
train Loss: 0.0776 Attr Loss: 6.4022 Acc: 0.9917
attribute accuracies
[0.83994774 0.77645762 0.78646089 0.89314878 0.57137024 0.48154499
 0.87787849 0.75436877 0.94794219 0.79919974 0.97248081 0.78107137]
val Loss: 0.1899 Attr Loss: 6.8906 Acc: 0.9507
attribute accuracies
[0.81266667 0.74466667 0.748      0.87533333 0.52266667 0.41933333
 0.85266667 0.69866667 0.926      0.734      0.95266667 0.704     ]
Epoch 58/69
----------
train Loss: 0.0763 Attr Loss: 6.3798 Acc: 0.9920
attribute accuracies
[0.84149927 0.77756002 0.78944145 0.89306712 0.57022701 0.48289237
 0.87791932 0.75465458 0.94790136 0.80226196 0.97243998 0.78580761]
val Loss: 0.1879 Attr Loss: 6.8883 Acc: 0.9533
attribute accuracies
[0.81533333 0.74666667 0.74933333 0.87466667 0.52466667 0.412
 0.852      0.71133333 0.926      0.732      0.95333333 0.70933333]
Epoch 59/69
----------
train Loss: 0.0761 Attr Loss: 6.3509 Acc: 0.9931
attribute accuracies
[0.83945778 0.78168382 0.79038053 0.89314878 0.57524906 0.4855463
 0.87812347 0.75506288 0.94798301 0.8025886  0.97243998 0.78748163]
val Loss: 0.1872 Attr Loss: 6.8704 Acc: 0.9540
attribute accuracies
[0.80866667 0.75533333 0.74733333 0.87533333 0.526      0.412
 0.854      0.70333333 0.92533333 0.73266667 0.95266667 0.714     ]
Epoch 60/69
----------
train Loss: 0.0765 Attr Loss: 6.3303 Acc: 0.9927
attribute accuracies
[0.84109097 0.78176547 0.79123796 0.89306712 0.58072024 0.48734281
 0.87791932 0.75820676 0.94790136 0.80197616 0.97252164 0.78417442]
val Loss: 0.1887 Attr Loss: 6.8444 Acc: 0.9527
attribute accuracies
[0.80933333 0.74533333 0.75466667 0.87533333 0.52266667 0.41466667
 0.85333333 0.708      0.92666667 0.73533333 0.95333333 0.70733333]
Epoch 61/69
----------
train Loss: 0.0766 Attr Loss: 6.3128 Acc: 0.9929
attribute accuracies
[0.84370407 0.78409276 0.79327944 0.89306712 0.57965866 0.49142577
 0.87783766 0.75694104 0.94802384 0.80744733 0.97243998 0.78850237]
val Loss: 0.1905 Attr Loss: 6.8427 Acc: 0.9540
attribute accuracies
[0.808      0.754      0.75133333 0.87466667 0.52333333 0.42266667
 0.85466667 0.706      0.92533333 0.734      0.95266667 0.71133333]
Epoch 62/69
----------
train Loss: 0.0766 Attr Loss: 6.2755 Acc: 0.9935
attribute accuracies
[0.84517393 0.78548097 0.79507594 0.89318961 0.58414993 0.49608035
 0.87796015 0.76045239 0.94794219 0.80895803 0.97243998 0.78629757]
val Loss: 0.1921 Attr Loss: 6.8111 Acc: 0.9547
attribute accuracies
[0.81333333 0.74933333 0.75333333 0.876      0.53533333 0.422
 0.85466667 0.70066667 0.926      0.73333333 0.95333333 0.71      ]
Epoch 63/69
----------
train Loss: 0.0768 Attr Loss: 6.2627 Acc: 0.9930
attribute accuracies
[0.84394904 0.78572595 0.79805651 0.89318961 0.58214927 0.49412053
 0.87796015 0.76212641 0.9478197  0.80765148 0.97252164 0.79046219]
val Loss: 0.1950 Attr Loss: 6.7924 Acc: 0.9547
attribute accuracies
[0.812      0.75266667 0.75133333 0.876      0.534      0.42466667
 0.85533333 0.70133333 0.926      0.746      0.95333333 0.718     ]
Epoch 64/69
----------
train Loss: 0.0771 Attr Loss: 6.2440 Acc: 0.9925
attribute accuracies
[0.84635799 0.78948228 0.79940389 0.89314878 0.58570145 0.49575372
 0.87787849 0.76090152 0.94790136 0.80973379 0.97243998 0.79401437]
val Loss: 0.1908 Attr Loss: 6.7827 Acc: 0.9553
attribute accuracies
[0.81533333 0.752      0.75666667 0.87466667 0.52866667 0.418
 0.85466667 0.70866667 0.928      0.74066667 0.95333333 0.71333333]
Epoch 65/69
----------
train Loss: 0.0754 Attr Loss: 6.2079 Acc: 0.9936
attribute accuracies
[0.84533725 0.79197289 0.80022048 0.89318961 0.59039686 0.49693778
 0.87800098 0.76559693 0.94794219 0.81189776 0.97248081 0.79642332]
val Loss: 0.1968 Attr Loss: 6.7651 Acc: 0.9553
attribute accuracies
[0.816      0.75       0.75866667 0.876      0.53133333 0.42466667
 0.854      0.70266667 0.92533333 0.75066667 0.95266667 0.716     ]
Epoch 66/69
----------
train Loss: 0.0785 Attr Loss: 6.1879 Acc: 0.9933
attribute accuracies
[0.84603136 0.79385105 0.80197616 0.89298546 0.59231586 0.49840764
 0.87791932 0.76396374 0.9478197  0.81536828 0.97243998 0.79715826]
val Loss: 0.1915 Attr Loss: 6.7322 Acc: 0.9567
attribute accuracies
[0.81466667 0.75333333 0.754      0.878      0.534      0.43933333
 0.85333333 0.70733333 0.926      0.75133333 0.954      0.71733333]
Epoch 67/69
----------
train Loss: 0.0745 Attr Loss: 6.1585 Acc: 0.9936
attribute accuracies
[0.84786869 0.79291197 0.80401764 0.89314878 0.5922342  0.50183733
 0.87783766 0.76686265 0.94794219 0.81630737 0.97252164 0.79899559]
val Loss: 0.1976 Attr Loss: 6.7284 Acc: 0.9540
attribute accuracies
[0.81733333 0.75466667 0.75866667 0.87533333 0.534      0.424
 0.85466667 0.708      0.92533333 0.74133333 0.95266667 0.722     ]
Epoch 68/69
----------
train Loss: 0.0769 Attr Loss: 6.1404 Acc: 0.9930
attribute accuracies
[0.85056345 0.79601503 0.80679406 0.89314878 0.59888943 0.50285808
 0.87779683 0.77065981 0.94786053 0.81696064 0.97243998 0.79813817]
val Loss: 0.1974 Attr Loss: 6.6950 Acc: 0.9553
attribute accuracies
[0.816      0.748      0.76066667 0.87466667 0.53466667 0.43666667
 0.85666667 0.71266667 0.92733333 0.75133333 0.95266667 0.72066667]
Epoch 69/69
----------
train Loss: 0.0767 Attr Loss: 6.1073 Acc: 0.9933
attribute accuracies
[0.85019598 0.79687245 0.80683488 0.89323044 0.59876694 0.50547117
 0.87791932 0.76947575 0.94806467 0.82112527 0.97264413 0.80250694]
val Loss: 0.1961 Attr Loss: 6.6868 Acc: 0.9580
attribute accuracies
[0.81666667 0.746      0.76466667 0.876      0.53133333 0.43
 0.85533333 0.72066667 0.92666667 0.74933333 0.954      0.716     ]
Training complete in 140m 7s
